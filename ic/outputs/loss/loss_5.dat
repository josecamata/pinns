# learning_rate: 0.000168
# num_dense_layers: 8
# num_dense_nodes: 30
# activation:tanh 
# batch_size: 32
# final loss: 0.0027699186466634274
# Training Time: 148.46443462371826
# Best Step: 10000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 6.010957956314086914e-01 3.000373207032680511e-02 6.848492659628391266e-03 2.593651413917541504e-03 2.758650854229927063e-02 6.423341631889343262e-01 6.010957956314086914e-01 3.000373207032680511e-02 6.848492659628391266e-03 2.593651413917541504e-03 2.758650854229927063e-02 6.423341631889343262e-01
1.000000000000000000e+03 1.541808061301708221e-02 3.061877796426415443e-04 1.041416107909753919e-04 7.628924504388123751e-05 2.098334953188896179e-04 6.730081886053085327e-02 1.541808061301708221e-02 3.061877796426415443e-04 1.041416107909753919e-04 7.628924504388123751e-05 2.098334953188896179e-04 6.730081886053085327e-02
2.000000000000000000e+03 7.670378312468528748e-03 6.099166421336121857e-05 5.451087054098024964e-05 6.402672443073242903e-05 5.827629865962080657e-05 1.746841589920222759e-03 7.670378312468528748e-03 6.099166421336121857e-05 5.451087054098024964e-05 6.402672443073242903e-05 5.827629865962080657e-05 1.746841589920222759e-03
3.000000000000000000e+03 5.530170630663633347e-03 4.311917291488498449e-05 4.876756793237291276e-05 3.051442399737425148e-05 2.913878415711224079e-05 5.414701299741864204e-04 5.530170630663633347e-03 4.311917291488498449e-05 4.876756793237291276e-05 3.051442399737425148e-05 2.913878415711224079e-05 5.414701299741864204e-04
4.000000000000000000e+03 4.841299261897802353e-03 2.211927494499832392e-05 4.573548358166590333e-05 2.172401764255482703e-05 1.730961048451717943e-05 3.348497266415506601e-04 4.841299261897802353e-03 2.211927494499832392e-05 4.573548358166590333e-05 2.172401764255482703e-05 1.730961048451717943e-05 3.348497266415506601e-04
5.000000000000000000e+03 4.430778324604034424e-03 1.682485162746161222e-05 5.014358976040966809e-05 2.133075759047642350e-05 1.457213784306077287e-05 2.583532186690717936e-04 4.430778324604034424e-03 1.682485162746161222e-05 5.014358976040966809e-05 2.133075759047642350e-05 1.457213784306077287e-05 2.583532186690717936e-04
6.000000000000000000e+03 4.131259862333536148e-03 1.589568091731052846e-05 5.698932363884523511e-05 2.388511893514078110e-05 1.459641043766168877e-05 1.797519362298771739e-04 4.131259862333536148e-03 1.589568091731052846e-05 5.698932363884523511e-05 2.388511893514078110e-05 1.459641043766168877e-05 1.797519362298771739e-04
7.000000000000000000e+03 3.679606132209300995e-03 1.495675587648293003e-05 5.600794247584417462e-05 2.763048360066022724e-05 1.490799331804737449e-05 1.875346788438037038e-04 3.679606132209300995e-03 1.495675587648293003e-05 5.600794247584417462e-05 2.763048360066022724e-05 1.490799331804737449e-05 1.875346788438037038e-04
8.000000000000000000e+03 3.271436318755149841e-03 1.379741752316476777e-05 5.036322909290902317e-05 3.201137951691634953e-05 1.808878732845187187e-05 1.924738025991246104e-04 3.271436318755149841e-03 1.379741752316476777e-05 5.036322909290902317e-05 3.201137951691634953e-05 1.808878732845187187e-05 1.924738025991246104e-04
9.000000000000000000e+03 2.875501755625009537e-03 1.298930055781966075e-05 5.456199505715630949e-05 3.676557389553636312e-05 2.060052065644413233e-05 1.311004452873021364e-04 2.875501755625009537e-03 1.298930055781966075e-05 5.456199505715630949e-05 3.676557389553636312e-05 2.060052065644413233e-05 1.311004452873021364e-04
1.000000000000000000e+04 2.433745190501213074e-03 1.429102576366858557e-05 4.761847958434373140e-05 3.867517443723045290e-05 2.071304879791568965e-05 2.148757776012644172e-04 2.433745190501213074e-03 1.429102576366858557e-05 4.761847958434373140e-05 3.867517443723045290e-05 2.071304879791568965e-05 2.148757776012644172e-04
