# learning_rate: 0.05
# num_dense_layers: 3
# num_dense_nodes: 40
# activation:tanh 
# batch_size: 32
# final loss: 0.047137945890426636
# Training Time: 90.13964414596558

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 6.232334375381469727e-01 2.088480861857533455e-03 1.241117808967828751e-02 1.824604533612728119e-02 3.113954328000545502e-03 4.518094062805175781e-01 6.232334375381469727e-01 2.088480861857533455e-03 1.241117808967828751e-02 1.824604533612728119e-02 3.113954328000545502e-03 4.518094062805175781e-01
1.000000000000000000e+03 1.699891500174999237e-02 4.319706931710243225e-05 7.339304374909261242e-06 1.056464498105924577e-05 1.656454151088837534e-05 3.006136417388916016e-02 1.699891500174999237e-02 4.319706931710243225e-05 7.339304374909261242e-06 1.056464498105924577e-05 1.656454151088837534e-05 3.006136417388916016e-02
2.000000000000000000e+03 1.302900543009855028e-08 3.346597950439900160e-04 3.345996665302664042e-04 3.344293509144335985e-04 3.346172452438622713e-04 1.377474367618560791e-01 1.302900543009855028e-08 3.346597950439900160e-04 3.345996665302664042e-04 3.344293509144335985e-04 3.346172452438622713e-04 1.377474367618560791e-01
3.000000000000000000e+03 5.958310289599921816e-09 3.722720721270889044e-04 3.722533001564443111e-04 3.721094981301575899e-04 3.722372930496931076e-04 1.376506388187408447e-01 5.958310289599921816e-09 3.722720721270889044e-04 3.722533001564443111e-04 3.721094981301575899e-04 3.722372930496931076e-04 1.376506388187408447e-01
4.000000000000000000e+03 8.377686100402570446e-09 3.346850280649960041e-04 3.346796147525310516e-04 3.348496975377202034e-04 3.347364836372435093e-04 1.377471685409545898e-01 8.377686100402570446e-09 3.346850280649960041e-04 3.346796147525310516e-04 3.348496975377202034e-04 3.347364836372435093e-04 1.377471685409545898e-01
5.000000000000000000e+03 9.300900273956358433e-06 3.329387691337615252e-04 3.315873036626726389e-04 3.178089100401848555e-04 3.280236269347369671e-04 1.377301663160324097e-01 9.300900273956358433e-06 3.329387691337615252e-04 3.315873036626726389e-04 3.178089100401848555e-04 3.280236269347369671e-04 1.377301663160324097e-01
6.000000000000000000e+03 1.776487295046536019e-07 3.357106761541217566e-04 3.357016539666801691e-04 3.358549147378653288e-04 3.357113746460527182e-04 1.377429217100143433e-01 1.776487295046536019e-07 3.357106761541217566e-04 3.357016539666801691e-04 3.358549147378653288e-04 3.357113746460527182e-04 1.377429217100143433e-01
7.000000000000000000e+03 1.799907636268471833e-07 3.316257789265364408e-04 3.316079673822969198e-04 3.317326481919735670e-04 3.316222573630511761e-04 1.377595067024230957e-01 1.799907636268471833e-07 3.316257789265364408e-04 3.316079673822969198e-04 3.317326481919735670e-04 3.316222573630511761e-04 1.377595067024230957e-01
8.000000000000000000e+03 1.286905444430885836e-07 2.201484021497890353e-04 2.200575545430183411e-04 2.201101597165688872e-04 2.200924063799902797e-04 1.388490349054336548e-01 1.286905444430885836e-07 2.201484021497890353e-04 2.200575545430183411e-04 2.201101597165688872e-04 2.200924063799902797e-04 1.388490349054336548e-01
9.000000000000000000e+03 1.130308187507805730e-15 3.345934092067182064e-04 3.345934092067182064e-04 3.345935547258704901e-04 3.345935547258704901e-04 1.377471089363098145e-01 1.130308187507805730e-15 3.345934092067182064e-04 3.345934092067182064e-04 3.345935547258704901e-04 3.345935547258704901e-04 1.377471089363098145e-01
1.000000000000000000e+04 1.379974536842799773e-15 3.344858996570110321e-04 3.344858996570110321e-04 3.344860451761633158e-04 3.344860451761633158e-04 1.377475410699844360e-01 1.379974536842799773e-15 3.344858996570110321e-04 3.344858996570110321e-04 3.344860451761633158e-04 3.344860451761633158e-04 1.377475410699844360e-01
