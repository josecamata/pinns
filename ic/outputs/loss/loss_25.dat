# learning_rate: 0.05
# num_dense_layers: 10
# num_dense_nodes: 80
# activation:sin 
# batch_size: 32
# final loss: 0.13908548653125763
# Training Time: 125.03308439254761

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 5.448648929595947266e-01 1.359962625429034233e-03 4.293478559702634811e-03 1.376497745513916016e-02 1.105546485632658005e-03 9.286829829216003418e-01 5.448648929595947266e-01 1.359962625429034233e-03 4.293478559702634811e-03 1.376497745513916016e-02 1.105546485632658005e-03 9.286829829216003418e-01
1.000000000000000000e+03 1.291918791591255625e-14 3.345927107147872448e-04 3.345927107147872448e-04 3.345927107147872448e-04 3.345927398186177015e-04 1.377471089363098145e-01 1.291918791591255625e-14 3.345927107147872448e-04 3.345927107147872448e-04 3.345927107147872448e-04 3.345927398186177015e-04 1.377471089363098145e-01
2.000000000000000000e+03 1.067039280000000000e+08 3.345949517097324133e-04 3.345909062772989273e-04 3.345918084960430861e-04 3.345897130202502012e-04 1.377468705177307129e-01 1.067039280000000000e+08 3.345949517097324133e-04 3.345909062772989273e-04 3.345918084960430861e-04 3.345897130202502012e-04 1.377468705177307129e-01
3.000000000000000000e+03 1.389643059532136448e+19 3.493906185030937195e-02 4.023868963122367859e-02 3.614377975463867188e-02 4.511006549000740051e-02 2.024593114852905273e+00 1.389643059532136448e+19 3.493906185030937195e-02 4.023868963122367859e-02 3.614377975463867188e-02 4.511006549000740051e-02 2.024593114852905273e+00
4.000000000000000000e+03 1.191660377885953229e+20 3.601498529314994812e-02 3.976786136627197266e-02 3.825798258185386658e-02 4.471246525645256042e-02 2.079343557357788086e+00 1.191660377885953229e+20 3.601498529314994812e-02 3.976786136627197266e-02 3.825798258185386658e-02 4.471246525645256042e-02 2.079343557357788086e+00
5.000000000000000000e+03 1.502984126609332634e+19 3.387416526675224304e-02 4.371968656778335571e-02 3.843116760253906250e-02 4.229127988219261169e-02 2.162834167480468750e+00 1.502984126609332634e+19 3.387416526675224304e-02 4.371968656778335571e-02 3.843116760253906250e-02 4.229127988219261169e-02 2.162834167480468750e+00
