# learning_rate: 0.05
# num_dense_layers: 10
# num_dense_nodes: 30
# activation:Swish 
# batch_size: 32
# final loss: 0.13908548653125763
# Training Time: 268.9049823284149
# Best Step: 10000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 1.542032805446069688e-05 6.880935643494012766e-07 6.560729843840817921e-07 4.256176566741487477e-08 7.159822246194380568e-08 1.562539488077163696e-01 1.542032805446069688e-05 6.880935643494012766e-07 6.560729843840817921e-07 4.256176566741487477e-08 7.159822246194380568e-08 1.562539488077163696e-01
1.000000000000000000e+03 2.643321863615710754e-07 3.345871227793395519e-04 3.345871227793395519e-04 3.346460871398448944e-04 3.345871227793395519e-04 1.377471387386322021e-01 2.643321863615710754e-07 3.345871227793395519e-04 3.345871227793395519e-04 3.346460871398448944e-04 3.345871227793395519e-04 1.377471387386322021e-01
2.000000000000000000e+03 2.248251149694624473e-07 3.345874429214745760e-04 3.345874429214745760e-04 3.346411394886672497e-04 3.345874720253050327e-04 1.377471387386322021e-01 2.248251149694624473e-07 3.345874429214745760e-04 3.345874429214745760e-04 3.346411394886672497e-04 3.345874720253050327e-04 1.377471387386322021e-01
3.000000000000000000e+03 1.765023966981971171e-07 3.345888399053364992e-04 3.345888399053364992e-04 3.346352605149149895e-04 3.345888690091669559e-04 1.377471387386322021e-01 1.765023966981971171e-07 3.345888399053364992e-04 3.345888399053364992e-04 3.346352605149149895e-04 3.345888690091669559e-04 1.377471387386322021e-01
4.000000000000000000e+03 1.286259276866985601e-07 3.345895383972674608e-04 3.345895383972674608e-04 3.346280718687921762e-04 3.345895675010979176e-04 1.377471387386322021e-01 1.286259276866985601e-07 3.345895383972674608e-04 3.345895383972674608e-04 3.346280718687921762e-04 3.345895675010979176e-04 1.377471387386322021e-01
5.000000000000000000e+03 8.767912618168338668e-08 3.345902077853679657e-04 3.345902077853679657e-04 3.346211160533130169e-04 3.345902368891984224e-04 1.377471238374710083e-01 8.767912618168338668e-08 3.345902077853679657e-04 3.345902077853679657e-04 3.346211160533130169e-04 3.345902368891984224e-04 1.377471238374710083e-01
6.000000000000000000e+03 5.661427238123906136e-08 3.345912264194339514e-04 3.345912264194339514e-04 3.346149751450866461e-04 3.345912555232644081e-04 1.377471089363098145e-01 5.661427238123906136e-08 3.345912264194339514e-04 3.345912264194339514e-04 3.346149751450866461e-04 3.345912555232644081e-04 1.377471089363098145e-01
7.000000000000000000e+03 3.506526269347887137e-08 3.345912264194339514e-04 3.345912264194339514e-04 3.346092707943171263e-04 3.345912555232644081e-04 1.377471089363098145e-01 3.506526269347887137e-08 3.345912264194339514e-04 3.345912264194339514e-04 3.346092707943171263e-04 3.345912555232644081e-04 1.377471089363098145e-01
8.000000000000000000e+03 2.103730167846151744e-08 3.345916047692298889e-04 3.345916047692298889e-04 3.346050798427313566e-04 3.345916047692298889e-04 1.377471089363098145e-01 2.103730167846151744e-08 3.345916047692298889e-04 3.345916047692298889e-04 3.346050798427313566e-04 3.345916047692298889e-04 1.377471089363098145e-01
9.000000000000000000e+03 1.231192126027735867e-08 3.345933218952268362e-04 3.345933218952268362e-04 3.346031589899212122e-04 3.345933218952268362e-04 1.377471089363098145e-01 1.231192126027735867e-08 3.345933218952268362e-04 3.345933218952268362e-04 3.346031589899212122e-04 3.345933218952268362e-04 1.377471089363098145e-01
1.000000000000000000e+04 7.045091177104723101e-09 3.345953882671892643e-04 3.345953882671892643e-04 3.346023440826684237e-04 3.345954173710197210e-04 1.377470940351486206e-01 7.045091177104723101e-09 3.345953882671892643e-04 3.345953882671892643e-04 3.346023440826684237e-04 3.345954173710197210e-04 1.377470940351486206e-01
