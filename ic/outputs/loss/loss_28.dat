# learning_rate: 0.000283
# num_dense_layers: 10
# num_dense_nodes: 80
# activation:sigmoid 
# batch_size: 32
# final loss: 0.017230261117219925
# Training Time: 260.9094772338867
# Best Step: 10000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 3.847495239073239759e-13 2.206777222454547882e-02 2.206774614751338959e-02 2.206777408719062805e-02 2.206780388951301575e-02 9.670739173889160156e-01 3.847495239073239759e-13 2.206777222454547882e-02 2.206774614751338959e-02 2.206777408719062805e-02 2.206780388951301575e-02 9.670739173889160156e-01
1.000000000000000000e+03 1.773032173514366150e-02 8.708205859875306487e-05 4.723084930446930230e-05 2.948621113318949938e-05 4.567367068375460804e-05 4.435707628726959229e-02 1.773032173514366150e-02 8.708205859875306487e-05 4.723084930446930230e-05 2.948621113318949938e-05 4.567367068375460804e-05 4.435707628726959229e-02
2.000000000000000000e+03 1.925059035420417786e-02 5.525038068299181759e-05 8.463414815196301788e-06 3.463916755208629183e-06 1.206000342790503055e-05 8.459507487714290619e-03 1.925059035420417786e-02 5.525038068299181759e-05 8.463414815196301788e-06 3.463916755208629183e-06 1.206000342790503055e-05 8.459507487714290619e-03
3.000000000000000000e+03 1.809379272162914276e-02 4.895756865153089166e-05 5.140159373695496470e-06 2.481459887349046767e-06 1.627688288863282651e-05 6.230168975889682770e-03 1.809379272162914276e-02 4.895756865153089166e-05 5.140159373695496470e-06 2.481459887349046767e-06 1.627688288863282651e-05 6.230168975889682770e-03
4.000000000000000000e+03 1.407922804355621338e-02 8.221682219300419092e-05 2.145406870113220066e-05 1.742854874464683235e-05 4.161020842730067670e-05 7.188838906586170197e-03 1.407922804355621338e-02 8.221682219300419092e-05 2.145406870113220066e-05 1.742854874464683235e-05 4.161020842730067670e-05 7.188838906586170197e-03
5.000000000000000000e+03 1.767697930335998535e-02 3.988363823737017810e-05 4.049508333991980180e-06 2.222669309048797004e-06 1.614348548173438758e-05 6.581207737326622009e-03 1.767697930335998535e-02 3.988363823737017810e-05 4.049508333991980180e-06 2.222669309048797004e-06 1.614348548173438758e-05 6.581207737326622009e-03
6.000000000000000000e+03 1.766468957066535950e-02 3.702038884512148798e-05 4.914090823149308562e-06 2.604279643492191099e-06 2.130753273377195001e-05 5.362562369555234909e-03 1.766468957066535950e-02 3.702038884512148798e-05 4.914090823149308562e-06 2.604279643492191099e-06 2.130753273377195001e-05 5.362562369555234909e-03
7.000000000000000000e+03 1.609035953879356384e-02 3.061909228563308716e-05 3.236231350456364453e-06 1.610390427231322974e-06 1.841598350438289344e-05 6.258995272219181061e-03 1.609035953879356384e-02 3.061909228563308716e-05 3.236231350456364453e-06 1.610390427231322974e-06 1.841598350438289344e-05 6.258995272219181061e-03
8.000000000000000000e+03 1.541360095143318176e-02 2.686407060537021607e-05 2.701993707887595519e-06 1.385511495755054057e-06 1.654027073527686298e-05 5.831810645759105682e-03 1.541360095143318176e-02 2.686407060537021607e-05 2.701993707887595519e-06 1.385511495755054057e-06 1.654027073527686298e-05 5.831810645759105682e-03
9.000000000000000000e+03 1.441564224660396576e-02 2.323933222214691341e-05 2.836439989550854079e-06 1.490523800384835340e-06 1.352416438749060035e-05 5.200942512601613998e-03 1.441564224660396576e-02 2.323933222214691341e-05 2.836439989550854079e-06 1.490523800384835340e-06 1.352416438749060035e-05 5.200942512601613998e-03
1.000000000000000000e+04 1.275483705103397369e-02 1.976428211492020637e-05 4.181707026873482391e-06 2.497019067959627137e-06 9.411858627572655678e-06 4.439568147063255310e-03 1.275483705103397369e-02 1.976428211492020637e-05 4.181707026873482391e-06 2.497019067959627137e-06 9.411858627572655678e-06 4.439568147063255310e-03
