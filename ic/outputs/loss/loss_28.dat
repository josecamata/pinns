# learning_rate: 0.0001
# num_dense_layers: 8
# num_dense_nodes: 40
# activation:sigmoid 
# batch_size: 32
# final loss: 0.05596568062901497
# Training Time: 117.30972480773926
# Best Step: 10000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 3.766957412665306038e-09 8.852092921733856201e-02 8.851996064186096191e-02 8.852214366197586060e-02 8.852281421422958374e-02 7.990851879119873047e+00 3.766957412665306038e-09 8.852092921733856201e-02 8.851996064186096191e-02 8.852214366197586060e-02 8.852281421422958374e-02 7.990851879119873047e+00
1.000000000000000000e+03 5.787533652323872957e-08 3.611076099332422018e-04 3.607310063671320677e-04 3.602634824346750975e-04 3.606648242566734552e-04 2.753103375434875488e-01 5.787533652323872957e-08 3.611076099332422018e-04 3.607310063671320677e-04 3.602634824346750975e-04 3.606648242566734552e-04 2.753103375434875488e-01
2.000000000000000000e+03 2.120578074027434923e-06 3.622440272010862827e-04 3.595700545702129602e-04 3.571510023903101683e-04 3.595733724068850279e-04 2.751764655113220215e-01 2.120578074027434923e-06 3.622440272010862827e-04 3.595700545702129602e-04 3.571510023903101683e-04 3.595733724068850279e-04 2.751764655113220215e-01
3.000000000000000000e+03 3.754096978809684515e-04 3.730740281753242016e-04 3.342831332702189684e-04 3.227890701964497566e-04 3.444205212872475386e-04 2.727346718311309814e-01 3.754096978809684515e-04 3.730740281753242016e-04 3.342831332702189684e-04 3.227890701964497566e-04 3.444205212872475386e-04 2.727346718311309814e-01
4.000000000000000000e+03 7.674890570342540741e-03 3.475997655186802149e-04 2.599536674097180367e-04 2.222671610070392489e-04 2.514170191716402769e-04 2.573748230934143066e-01 7.674890570342540741e-03 3.475997655186802149e-04 2.599536674097180367e-04 2.222671610070392489e-04 2.514170191716402769e-04 2.573748230934143066e-01
5.000000000000000000e+03 1.377104502171278000e-02 3.534379648044705391e-04 2.097046963172033429e-04 1.696514518698677421e-04 2.418125077383592725e-04 2.419175952672958374e-01 1.377104502171278000e-02 3.534379648044705391e-04 2.097046963172033429e-04 1.696514518698677421e-04 2.418125077383592725e-04 2.419175952672958374e-01
6.000000000000000000e+03 4.947682097554206848e-02 6.195381138240918517e-05 2.828608921845443547e-05 3.627343176049180329e-05 6.363918510032817721e-05 7.999100536108016968e-02 4.947682097554206848e-02 6.195381138240918517e-05 2.828608921845443547e-05 3.627343176049180329e-05 6.363918510032817721e-05 7.999100536108016968e-02
7.000000000000000000e+03 5.463261157274246216e-02 3.806780296145007014e-05 2.464831595716532320e-05 3.225604814360849559e-05 4.455026282812468708e-05 3.921176493167877197e-02 5.463261157274246216e-02 3.806780296145007014e-05 2.464831595716532320e-05 3.225604814360849559e-05 4.455026282812468708e-05 3.921176493167877197e-02
8.000000000000000000e+03 4.705511778593063354e-02 2.623647560540121049e-05 2.325441892025992274e-05 2.829661934811156243e-05 2.615915218484587967e-05 1.676815189421176910e-02 4.705511778593063354e-02 2.623647560540121049e-05 2.325441892025992274e-05 2.829661934811156243e-05 2.615915218484587967e-05 1.676815189421176910e-02
9.000000000000000000e+03 4.436906054615974426e-02 2.423588193778414279e-05 2.426433457003440708e-05 2.765666977211367339e-05 2.435853821225464344e-05 1.420405134558677673e-02 4.436906054615974426e-02 2.423588193778414279e-05 2.426433457003440708e-05 2.765666977211367339e-05 2.435853821225464344e-05 1.420405134558677673e-02
1.000000000000000000e+04 4.291915893554687500e-02 2.269011929456610233e-05 2.424415288260206580e-05 2.795636646624188870e-05 2.332272924832068384e-05 1.294830814003944397e-02 4.291915893554687500e-02 2.269011929456610233e-05 2.424415288260206580e-05 2.795636646624188870e-05 2.332272924832068384e-05 1.294830814003944397e-02
