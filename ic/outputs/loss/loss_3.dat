# learning_rate: 0.0316
# num_dense_layers: 8
# num_dense_nodes: 20
# activation:Swish 
# batch_size: 32
# final loss: 0.00019968203559983522
# Training Time: 218.66156435012817
# Best Step: 8000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 3.060888499021530151e-03 1.001944110612384975e-04 2.123121230397373438e-04 1.351318933302536607e-04 1.200649967358913273e-05 1.442308425903320312e-01 3.060888499021530151e-03 1.001944110612384975e-04 2.123121230397373438e-04 1.351318933302536607e-04 1.200649967358913273e-05 1.442308425903320312e-01
1.000000000000000000e+03 9.247880429029464722e-03 1.042112035065656528e-05 6.330521046038484201e-06 8.991038157546427101e-06 1.049330239766277373e-05 7.790211238898336887e-04 9.247880429029464722e-03 1.042112035065656528e-05 6.330521046038484201e-06 8.991038157546427101e-06 1.049330239766277373e-05 7.790211238898336887e-04
2.000000000000000000e+03 4.570028278976678848e-03 6.320341981336241588e-06 9.756249710335396230e-06 8.623366738902404904e-06 7.926722901174798608e-06 1.296870177611708641e-04 4.570028278976678848e-03 6.320341981336241588e-06 9.756249710335396230e-06 8.623366738902404904e-06 7.926722901174798608e-06 1.296870177611708641e-04
3.000000000000000000e+03 8.990615024231374264e-04 1.230874772772949655e-06 7.126943160074006300e-07 2.183370952479890548e-06 3.225630280212499201e-06 2.057567471638321877e-04 8.990615024231374264e-04 1.230874772772949655e-06 7.126943160074006300e-07 2.183370952479890548e-06 3.225630280212499201e-06 2.057567471638321877e-04
4.000000000000000000e+03 7.916236063465476036e-04 6.380839181474584620e-07 5.775738713964528870e-07 1.422215291313477792e-06 2.248873215648927726e-06 6.139231263659894466e-04 7.916236063465476036e-04 6.380839181474584620e-07 5.775738713964528870e-07 1.422215291313477792e-06 2.248873215648927726e-06 6.139231263659894466e-04
5.000000000000000000e+03 1.113010104745626450e-03 2.243806875412701629e-06 2.037568037849268876e-06 1.258535803572158329e-06 2.364890860917512327e-06 4.237756947986781597e-04 1.113010104745626450e-03 2.243806875412701629e-06 2.037568037849268876e-06 1.258535803572158329e-06 2.364890860917512327e-06 4.237756947986781597e-04
6.000000000000000000e+03 1.256378309335559607e-04 1.021109142129716929e-06 4.667384132517327089e-07 8.229667400883045048e-07 2.005207079491810873e-06 1.131412209360860288e-04 1.256378309335559607e-04 1.021109142129716929e-06 4.667384132517327089e-07 8.229667400883045048e-07 2.005207079491810873e-06 1.131412209360860288e-04
7.000000000000000000e+03 9.514639386907219887e-04 1.850218950494308956e-06 4.209347537198482314e-07 9.091103834180103149e-07 2.683874299691524357e-06 4.685549065470695496e-04 9.514639386907219887e-04 1.850218950494308956e-06 4.209347537198482314e-07 9.091103834180103149e-07 2.683874299691524357e-06 4.685549065470695496e-04
8.000000000000000000e+03 1.198668469442054629e-04 1.166701053989527281e-06 8.849216897033329587e-07 1.068998130904219579e-06 1.601342205503897276e-06 7.509323768317699432e-05 1.198668469442054629e-04 1.166701053989527281e-06 8.849216897033329587e-07 1.068998130904219579e-06 1.601342205503897276e-06 7.509323768317699432e-05
9.000000000000000000e+03 0.000000000000000000e+00 2.310241834493353963e-04 2.310241834493353963e-04 2.310241834493353963e-04 2.310242125531658530e-04 1.386777907609939575e-01 0.000000000000000000e+00 2.310241834493353963e-04 2.310241834493353963e-04 2.310241834493353963e-04 2.310242125531658530e-04 1.386777907609939575e-01
1.000000000000000000e+04 1.592607443352814081e-29 3.345926234032958746e-04 3.345926234032958746e-04 3.345926234032958746e-04 3.345926234032958746e-04 1.377471089363098145e-01 1.592607443352814081e-29 3.345926234032958746e-04 3.345926234032958746e-04 3.345926234032958746e-04 3.345926234032958746e-04 1.377471089363098145e-01
