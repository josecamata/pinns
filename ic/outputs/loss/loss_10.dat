# learning_rate: 0.0007674054502520459
# num_dense_layers: 9
# num_dense_nodes: 59
# activation: ReLU 
# batch_size: 32

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 7.794094737619161606e-03 1.474829041399061680e-04 3.404329472687095404e-04 1.161518666776828468e-04 2.450012061672168784e-06 1.398437768220901489e-01 7.794094737619161606e-03 1.474829041399061680e-04 3.404329472687095404e-04 1.161518666776828468e-04 2.450012061672168784e-06 1.398437768220901489e-01
1.000000000000000000e+03 1.665890403091907501e-02 1.042996700562071055e-05 3.734706069735693745e-06 1.044938380800886080e-05 4.688741319114342332e-05 3.505721315741539001e-02 1.665890403091907501e-02 1.042996700562071055e-05 3.734706069735693745e-06 1.044938380800886080e-05 4.688741319114342332e-05 3.505721315741539001e-02
2.000000000000000000e+03 1.342143863439559937e-02 1.529421979284961708e-06 2.471767857059603557e-07 9.522585060040000826e-06 6.094243872212246060e-05 2.820923179388046265e-02 1.342143863439559937e-02 1.529421979284961708e-06 2.471767857059603557e-07 9.522585060040000826e-06 6.094243872212246060e-05 2.820923179388046265e-02
