# learning_rate: 0.000283
# num_dense_layers: 10
# num_dense_nodes: 60
# activation:tanh 
# batch_size: 32
# final loss: 0.0023687847424298525
# Training Time: 203.64558482170105

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 1.133443117141723633e-01 8.887847070582211018e-04 6.865966715849936008e-04 9.220318170264363289e-04 3.428157651796936989e-04 3.552168607711791992e-01 1.133443117141723633e-01 8.887847070582211018e-04 6.865966715849936008e-04 9.220318170264363289e-04 3.428157651796936989e-04 3.552168607711791992e-01
1.000000000000000000e+03 7.512031123042106628e-03 3.754038698389194906e-05 4.182142947684042156e-05 7.235231896629557014e-05 6.987041706452146173e-05 1.240349607542157173e-03 7.512031123042106628e-03 3.754038698389194906e-05 4.182142947684042156e-05 7.235231896629557014e-05 6.987041706452146173e-05 1.240349607542157173e-03
2.000000000000000000e+03 5.056041292846202850e-03 1.971108213183470070e-05 5.701115151168778539e-05 3.028287392226047814e-05 2.097087417496368289e-05 4.570359014905989170e-04 5.056041292846202850e-03 1.971108213183470070e-05 5.701115151168778539e-05 3.028287392226047814e-05 2.097087417496368289e-05 4.570359014905989170e-04
3.000000000000000000e+03 4.363164305686950684e-03 1.347228408121736720e-05 5.472940028994344175e-05 2.396002855675760657e-05 1.579400304763112217e-05 2.427132858429104090e-04 4.363164305686950684e-03 1.347228408121736720e-05 5.472940028994344175e-05 2.396002855675760657e-05 1.579400304763112217e-05 2.427132858429104090e-04
4.000000000000000000e+03 4.516999237239360809e-03 1.580615753482561558e-05 5.447488729259930551e-05 2.465157376718707383e-05 1.355785843770718202e-05 5.713029531762003899e-04 4.516999237239360809e-03 1.580615753482561558e-05 5.447488729259930551e-05 2.465157376718707383e-05 1.355785843770718202e-05 5.713029531762003899e-04
5.000000000000000000e+03 4.036338068544864655e-03 1.771756433299742639e-05 7.150620513129979372e-05 2.468283128109760582e-05 1.323591732216300443e-05 4.898695624433457851e-04 4.036338068544864655e-03 1.771756433299742639e-05 7.150620513129979372e-05 2.468283128109760582e-05 1.323591732216300443e-05 4.898695624433457851e-04
6.000000000000000000e+03 3.421220928430557251e-03 8.174461072485428303e-06 4.902402361040003598e-05 2.669029709068126976e-05 1.796702417777851224e-05 1.341722236247733235e-04 3.421220928430557251e-03 8.174461072485428303e-06 4.902402361040003598e-05 2.669029709068126976e-05 1.796702417777851224e-05 1.341722236247733235e-04
7.000000000000000000e+03 3.076271619647741318e-03 8.077084203250706196e-06 4.822463597520254552e-05 2.874249184969812632e-05 1.671869904384948313e-05 1.569713640492409468e-04 3.076271619647741318e-03 8.077084203250706196e-06 4.822463597520254552e-05 2.874249184969812632e-05 1.671869904384948313e-05 1.569713640492409468e-04
8.000000000000000000e+03 2.832114696502685547e-03 8.101441380858886987e-06 4.668429028242826462e-05 2.685958497750107199e-05 1.553007496113423258e-05 1.215065567521378398e-04 2.832114696502685547e-03 8.101441380858886987e-06 4.668429028242826462e-05 2.685958497750107199e-05 1.553007496113423258e-05 1.215065567521378398e-04
9.000000000000000000e+03 2.546628471463918686e-03 7.505228040827205405e-06 4.286039984435774386e-05 2.595529622340109199e-05 1.572764631418976933e-05 1.105250630644150078e-04 2.546628471463918686e-03 7.505228040827205405e-06 4.286039984435774386e-05 2.595529622340109199e-05 1.572764631418976933e-05 1.105250630644150078e-04
1.000000000000000000e+04 2.182091120630502701e-03 6.669855338259367272e-06 3.721272514667361975e-05 2.544822382333222777e-05 1.490542945248307660e-05 1.024576631607487798e-04 2.182091120630502701e-03 6.669855338259367272e-06 3.721272514667361975e-05 2.544822382333222777e-05 1.490542945248307660e-05 1.024576631607487798e-04
