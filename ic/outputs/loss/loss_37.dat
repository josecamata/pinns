# learning_rate: 0.0001
# num_dense_layers: 8
# num_dense_nodes: 50
# activation:ReLU 
# batch_size: 32
# final loss: 0.21815095841884613
# Training Time: 87.888601064682
# Best Step: 6000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 5.488750338554382324e-01 1.109319040551781654e-03 2.709581051021814346e-03 6.096425349824130535e-04 2.085168671328574419e-04 5.294317603111267090e-01 5.488750338554382324e-01 1.109319040551781654e-03 2.709581051021814346e-03 6.096425349824130535e-04 2.085168671328574419e-04 5.294317603111267090e-01
1.000000000000000000e+03 2.056682109832763672e-02 3.027314087375998497e-04 1.871037966338917613e-04 2.194402477471157908e-04 3.235975455027073622e-04 2.252217829227447510e-01 2.056682109832763672e-02 3.027314087375998497e-04 1.871037966338917613e-04 2.194402477471157908e-04 3.235975455027073622e-04 2.252217829227447510e-01
2.000000000000000000e+03 2.583831176161766052e-02 2.616154379211366177e-04 1.276865223189815879e-04 1.971818128367885947e-04 2.783063682727515697e-04 2.084312587976455688e-01 2.583831176161766052e-02 2.616154379211366177e-04 1.276865223189815879e-04 1.971818128367885947e-04 2.783063682727515697e-04 2.084312587976455688e-01
3.000000000000000000e+03 3.307069092988967896e-02 1.882156211649999022e-04 1.189315371448174119e-04 2.213456755271181464e-04 2.405378036201000214e-04 1.886070668697357178e-01 3.307069092988967896e-02 1.882156211649999022e-04 1.189315371448174119e-04 2.213456755271181464e-04 2.405378036201000214e-04 1.886070668697357178e-01
4.000000000000000000e+03 2.604906633496284485e-02 2.323656808584928513e-04 1.418118336005136371e-04 2.081419079331681132e-04 2.292648714501410723e-04 2.010434716939926147e-01 2.604906633496284485e-02 2.323656808584928513e-04 1.418118336005136371e-04 2.081419079331681132e-04 2.292648714501410723e-04 2.010434716939926147e-01
5.000000000000000000e+03 3.235594928264617920e-02 1.735808764351531863e-04 9.445379691896960139e-05 1.327225181739777327e-04 1.487498666392639279e-04 1.898771673440933228e-01 3.235594928264617920e-02 1.735808764351531863e-04 9.445379691896960139e-05 1.327225181739777327e-04 1.487498666392639279e-04 1.898771673440933228e-01
6.000000000000000000e+03 3.213611990213394165e-02 2.021482214331626892e-04 1.426465896656736732e-04 1.843993522925302386e-04 1.922290830407291651e-04 1.852934211492538452e-01 3.213611990213394165e-02 2.021482214331626892e-04 1.426465896656736732e-04 1.843993522925302386e-04 1.922290830407291651e-04 1.852934211492538452e-01
7.000000000000000000e+03 3.147143870592117310e-02 2.204704069299623370e-04 9.804948786040768027e-05 2.492574276402592659e-04 3.028642968274652958e-04 1.916057616472244263e-01 3.147143870592117310e-02 2.204704069299623370e-04 9.804948786040768027e-05 2.492574276402592659e-04 3.028642968274652958e-04 1.916057616472244263e-01
8.000000000000000000e+03 2.699281647801399231e-02 2.754461602307856083e-04 1.216209129779599607e-04 2.200343442382290959e-04 2.999418065883219242e-04 1.962542235851287842e-01 2.699281647801399231e-02 2.754461602307856083e-04 1.216209129779599607e-04 2.200343442382290959e-04 2.999418065883219242e-04 1.962542235851287842e-01
9.000000000000000000e+03 2.726626023650169373e-02 2.725362428463995457e-04 1.331492821918800473e-04 2.362474624533206224e-04 3.266099374741315842e-04 2.050621807575225830e-01 2.726626023650169373e-02 2.725362428463995457e-04 1.331492821918800473e-04 2.362474624533206224e-04 3.266099374741315842e-04 2.050621807575225830e-01
1.000000000000000000e+04 2.769991941750049591e-02 2.406333369435742497e-04 1.384034112561494112e-04 2.105136372847482562e-04 2.837145584635436535e-04 1.973413527011871338e-01 2.769991941750049591e-02 2.406333369435742497e-04 1.384034112561494112e-04 2.105136372847482562e-04 2.837145584635436535e-04 1.973413527011871338e-01
