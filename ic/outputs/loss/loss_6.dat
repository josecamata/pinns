# learning_rate: 0.009831365484868246
# num_dense_layers: 9
# num_dense_nodes: 79
# activation: ReLU 
# batch_size: 32

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 5.225630011409521103e-03 9.319329365098383278e-06 2.532372855057474226e-05 1.030066050589084625e-05 2.627611820571473800e-06 1.666818857192993164e-01 5.225630011409521103e-03 9.319329365098383278e-06 2.532372855057474226e-05 1.030066050589084625e-05 2.627611820571473800e-06 1.666818857192993164e-01
1.000000000000000000e+03 2.379290573298931122e-02 8.060621621552854776e-05 5.120821697346400470e-06 1.276688853977248073e-04 1.595275098225101829e-04 3.719207271933555603e-02 2.379290573298931122e-02 8.060621621552854776e-05 5.120821697346400470e-06 1.276688853977248073e-04 1.595275098225101829e-04 3.719207271933555603e-02
2.000000000000000000e+03 3.124495036900043488e-03 1.926715194713324308e-04 7.329348591156303883e-05 6.564173236256465316e-05 1.881190837593749166e-04 1.347948461771011353e-01 3.124495036900043488e-03 1.926715194713324308e-04 7.329348591156303883e-05 6.564173236256465316e-05 1.881190837593749166e-04 1.347948461771011353e-01
