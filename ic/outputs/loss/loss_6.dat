# learning_rate: 0.01
# num_dense_layers: 9
# num_dense_nodes: 80
# activation:ReLU 
# batch_size: 32
# final loss: 0.10651066899299622
# Training Time: 1.2270622253417969

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 1.383009273558855057e-02 2.464251338096801192e-05 1.146562426583841443e-04 1.990096498047932982e-04 1.151200467575108632e-05 1.451665014028549194e-01 1.383009273558855057e-02 2.464251338096801192e-05 1.146562426583841443e-04 1.990096498047932982e-04 1.151200467575108632e-05 1.451665014028549194e-01
1.000000000000000000e+02 8.421686477959156036e-03 1.041929717757739127e-04 1.249658726010238752e-05 1.164867626357590780e-05 7.335923146456480026e-05 9.788728505373001099e-02 8.421686477959156036e-03 1.041929717757739127e-04 1.249658726010238752e-05 1.164867626357590780e-05 7.335923146456480026e-05 9.788728505373001099e-02
