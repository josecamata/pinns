# learning_rate: 0.05
# num_dense_layers: 5
# num_dense_nodes: 70
# activation:tanh 
# batch_size: 32
# final loss: 0.13907968997955322
# Training Time: 130.6615481376648
# Best Step: 6000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 6.263067722320556641e-01 1.003805734217166901e-02 2.692669397220015526e-03 3.256004303693771362e-03 1.945062191225588322e-03 5.181793570518493652e-01 6.263067722320556641e-01 1.003805734217166901e-02 2.692669397220015526e-03 3.256004303693771362e-03 1.945062191225588322e-03 5.181793570518493652e-01
1.000000000000000000e+03 2.723606895571606401e-09 3.345907025504857302e-04 3.345797013025730848e-04 3.345780714880675077e-04 3.346252779010683298e-04 1.377477198839187622e-01 2.723606895571606401e-09 3.345907025504857302e-04 3.345797013025730848e-04 3.345780714880675077e-04 3.346252779010683298e-04 1.377477198839187622e-01
2.000000000000000000e+03 1.249129244484947776e-09 3.369498008396476507e-04 3.369443875271826982e-04 3.369435144122689962e-04 3.369585319887846708e-04 1.377379894256591797e-01 1.249129244484947776e-09 3.369498008396476507e-04 3.369443875271826982e-04 3.369435144122689962e-04 3.369585319887846708e-04 1.377379894256591797e-01
3.000000000000000000e+03 1.525528148249577498e-09 3.344208525959402323e-04 3.344187571201473475e-04 3.344179131090641022e-04 3.344212600495666265e-04 1.377477496862411499e-01 1.525528148249577498e-09 3.344208525959402323e-04 3.344187571201473475e-04 3.344179131090641022e-04 3.344212600495666265e-04 1.377477496862411499e-01
4.000000000000000000e+03 1.309898465251535526e-07 3.384088340681046247e-04 3.384517913218587637e-04 3.384474839549511671e-04 3.381756541784852743e-04 1.377275735139846802e-01 1.309898465251535526e-07 3.384088340681046247e-04 3.384517913218587637e-04 3.384474839549511671e-04 3.381756541784852743e-04 1.377275735139846802e-01
5.000000000000000000e+03 5.794600476533018352e-12 3.343302523717284203e-04 3.343250136822462082e-04 3.343253047205507755e-04 3.343296702951192856e-04 1.377480179071426392e-01 5.794600476533018352e-12 3.343302523717284203e-04 3.343250136822462082e-04 3.343253047205507755e-04 3.343296702951192856e-04 1.377480179071426392e-01
6.000000000000000000e+03 5.399516833648476677e-09 3.353094798512756824e-04 3.351374471094459295e-04 3.351384366396814585e-04 3.352776111569255590e-04 1.377388238906860352e-01 5.399516833648476677e-09 3.353094798512756824e-04 3.351374471094459295e-04 3.351384366396814585e-04 3.352776111569255590e-04 1.377388238906860352e-01
7.000000000000000000e+03 4.873676332298182423e-13 3.346310404594987631e-04 3.346322628203779459e-04 3.346320008859038353e-04 3.346312441863119602e-04 1.377470195293426514e-01 4.873676332298182423e-13 3.346310404594987631e-04 3.346322628203779459e-04 3.346320008859038353e-04 3.346312441863119602e-04 1.377470195293426514e-01
8.000000000000000000e+03 1.164877114039064576e-13 4.357845173217356205e-04 4.357839643489569426e-04 4.357840807642787695e-04 4.357849829830229282e-04 1.377028077840805054e-01 1.164877114039064576e-13 4.357845173217356205e-04 4.357839643489569426e-04 4.357840807642787695e-04 4.357849829830229282e-04 1.377028077840805054e-01
9.000000000000000000e+03 1.137551018009011483e-13 9.047425701282918453e-04 9.047411731444299221e-04 9.047410567291080952e-04 9.047441999427974224e-04 1.429690122604370117e-01 1.137551018009011483e-13 9.047425701282918453e-04 9.047411731444299221e-04 9.047410567291080952e-04 9.047441999427974224e-04 1.429690122604370117e-01
1.000000000000000000e+04 6.659539049770971109e-14 3.626146062742918730e-04 3.626136749517172575e-04 3.626138495746999979e-04 3.626149555202573538e-04 1.376654356718063354e-01 6.659539049770971109e-14 3.626146062742918730e-04 3.626136749517172575e-04 3.626138495746999979e-04 3.626149555202573538e-04 1.376654356718063354e-01
