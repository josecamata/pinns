# learning_rate: 0.00389
# num_dense_layers: 10
# num_dense_nodes: 80
# activation:tanh 
# batch_size: 32
# final loss: 0.08437718451023102
# Training Time: 251.2836675643921

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 8.709858655929565430e-01 1.863899989984929562e-03 6.828291807323694229e-03 3.471786854788661003e-03 7.623200304806232452e-03 3.594924211502075195e-01 8.709858655929565430e-01 1.863899989984929562e-03 6.828291807323694229e-03 3.471786854788661003e-03 7.623200304806232452e-03 3.594924211502075195e-01
1.000000000000000000e+03 1.404970698058605194e-02 4.108148277737200260e-04 1.085565872926963493e-05 8.671586692798882723e-05 2.731452696025371552e-04 6.954594701528549194e-02 1.404970698058605194e-02 4.108148277737200260e-04 1.085565872926963493e-05 8.671586692798882723e-05 2.731452696025371552e-04 6.954594701528549194e-02
2.000000000000000000e+03 9.489703923463821411e-03 1.204483094625174999e-03 4.135084454901516438e-04 9.569988469593226910e-05 7.143635884858667850e-04 1.145379170775413513e-01 9.489703923463821411e-03 1.204483094625174999e-03 4.135084454901516438e-04 9.569988469593226910e-05 7.143635884858667850e-04 1.145379170775413513e-01
3.000000000000000000e+03 4.405940671858843416e-06 3.363385330885648727e-04 3.319402458146214485e-04 3.305322898086160421e-04 3.341095871292054653e-04 1.374841332435607910e-01 4.405940671858843416e-06 3.363385330885648727e-04 3.319402458146214485e-04 3.305322898086160421e-04 3.341095871292054653e-04 1.374841332435607910e-01
4.000000000000000000e+03 8.246298782710326236e-11 3.345823788549751043e-04 3.345746372360736132e-04 3.345674776937812567e-04 3.345861914567649364e-04 1.377468705177307129e-01 8.246298782710326236e-11 3.345823788549751043e-04 3.345746372360736132e-04 3.345674776937812567e-04 3.345861914567649364e-04 1.377468705177307129e-01
5.000000000000000000e+03 1.513892067261934926e-10 3.345701843500137329e-04 3.345578443259000778e-04 3.345463483128696680e-04 3.345760924275964499e-04 1.377463936805725098e-01 1.513892067261934926e-10 3.345701843500137329e-04 3.345578443259000778e-04 3.345463483128696680e-04 3.345760924275964499e-04 1.377463936805725098e-01
6.000000000000000000e+03 2.994748893314636007e-09 3.344700089655816555e-04 3.343667776789516211e-04 3.342850832268595695e-04 3.345059813000261784e-04 1.377401202917098999e-01 2.994748893314636007e-09 3.344700089655816555e-04 3.343667776789516211e-04 3.342850832268595695e-04 3.345059813000261784e-04 1.377401202917098999e-01
7.000000000000000000e+03 8.975279547351888709e-11 3.345963777974247932e-04 3.345927107147872448e-04 3.345940494909882545e-04 3.345971636008471251e-04 1.377471089363098145e-01 8.975279547351888709e-11 3.345963777974247932e-04 3.345927107147872448e-04 3.345940494909882545e-04 3.345971636008471251e-04 1.377471089363098145e-01
8.000000000000000000e+03 1.082960873755034470e-10 3.346001903992146254e-04 3.345899749547243118e-04 3.345872682984918356e-04 3.345980949234217405e-04 1.377468407154083252e-01 1.082960873755034470e-10 3.346001903992146254e-04 3.345899749547243118e-04 3.345872682984918356e-04 3.345980949234217405e-04 1.377468407154083252e-01
9.000000000000000000e+03 8.292502101658882907e-11 3.389943740330636501e-04 3.390169586054980755e-04 3.390210622455924749e-04 3.389962948858737946e-04 1.377319395542144775e-01 8.292502101658882907e-11 3.389943740330636501e-04 3.390169586054980755e-04 3.390210622455924749e-04 3.389962948858737946e-04 1.377319395542144775e-01
1.000000000000000000e+04 1.116714776205895987e-10 3.345975710544735193e-04 3.345978329889476299e-04 3.345977456774562597e-04 3.345959994476288557e-04 1.377470940351486206e-01 1.116714776205895987e-10 3.345975710544735193e-04 3.345978329889476299e-04 3.345977456774562597e-04 3.345959994476288557e-04 1.377470940351486206e-01
