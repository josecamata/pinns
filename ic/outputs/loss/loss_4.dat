# learning_rate: 0.0007823493243213815
# num_dense_layers: 8
# num_dense_nodes: 26
# activation: ReLU 
# batch_size: 32

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 2.376260422170162201e-02 1.952367456397041678e-04 9.045650222105905414e-05 5.797262929263524711e-05 1.520126970717683434e-04 1.774507910013198853e-01 2.376260422170162201e-02 1.952367456397041678e-04 9.045650222105905414e-05 5.797262929263524711e-05 1.520126970717683434e-04 1.774507910013198853e-01
1.000000000000000000e+03 2.121878042817115784e-02 6.509601371362805367e-05 2.275299812026787549e-05 9.748490992933511734e-05 1.752798998495563865e-04 3.875404968857765198e-02 2.121878042817115784e-02 6.509601371362805367e-05 2.275299812026787549e-05 9.748490992933511734e-05 1.752798998495563865e-04 3.875404968857765198e-02
2.000000000000000000e+03 2.076012268662452698e-02 1.605519209988415241e-04 9.599251643521711230e-05 4.866522431257180870e-05 2.068974281428381801e-04 3.986512869596481323e-02 2.076012268662452698e-02 1.605519209988415241e-04 9.599251643521711230e-05 4.866522431257180870e-05 2.068974281428381801e-04 3.986512869596481323e-02
