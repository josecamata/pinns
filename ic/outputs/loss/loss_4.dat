# learning_rate: 0.000806
# num_dense_layers: 5
# num_dense_nodes: 50
# activation:ReLU 
# batch_size: 32
# final loss: 0.056099265813827515
# Training Time: 87.51103806495667
# Best Step: 2000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 1.128340512514114380e-01 1.887958846054971218e-03 1.948200049810111523e-03 3.539097087923437357e-05 8.601957815699279308e-04 2.532777786254882812e-01 1.128340512514114380e-01 1.887958846054971218e-03 1.948200049810111523e-03 3.539097087923437357e-05 8.601957815699279308e-04 2.532777786254882812e-01
1.000000000000000000e+03 2.401472628116607666e-02 1.477507030358538032e-04 2.418031544948462397e-05 8.073054050328209996e-05 3.327903104946017265e-04 4.299397766590118408e-02 2.401472628116607666e-02 1.477507030358538032e-04 2.418031544948462397e-05 8.073054050328209996e-05 3.327903104946017265e-04 4.299397766590118408e-02
2.000000000000000000e+03 2.402361482381820679e-02 1.378797605866566300e-04 6.752886838512495160e-05 1.751632516970857978e-04 3.914930566679686308e-04 3.130358457565307617e-02 2.402361482381820679e-02 1.378797605866566300e-04 6.752886838512495160e-05 1.751632516970857978e-04 3.914930566679686308e-04 3.130358457565307617e-02
3.000000000000000000e+03 2.198082394897937775e-02 1.699206186458468437e-04 3.143056164844892919e-05 1.619285321794450283e-04 2.939535479526966810e-04 3.906548768281936646e-02 2.198082394897937775e-02 1.699206186458468437e-04 3.143056164844892919e-05 1.619285321794450283e-04 2.939535479526966810e-04 3.906548768281936646e-02
4.000000000000000000e+03 1.989563740789890289e-02 2.743639925029128790e-04 4.009051554021425545e-05 1.535657647764310241e-04 3.237158234696835279e-04 4.685478657484054565e-02 1.989563740789890289e-02 2.743639925029128790e-04 4.009051554021425545e-05 1.535657647764310241e-04 3.237158234696835279e-04 4.685478657484054565e-02
5.000000000000000000e+03 2.634119614958763123e-02 1.998432999243959785e-04 6.621387001359835267e-05 2.031946060014888644e-04 3.130938566755503416e-04 4.785165563225746155e-02 2.634119614958763123e-02 1.998432999243959785e-04 6.621387001359835267e-05 2.031946060014888644e-04 3.130938566755503416e-04 4.785165563225746155e-02
6.000000000000000000e+03 1.954826526343822479e-02 1.895074819913133979e-04 1.682253241597209126e-05 3.393932638573460281e-05 2.504040312487632036e-04 5.863193795084953308e-02 1.954826526343822479e-02 1.895074819913133979e-04 1.682253241597209126e-05 3.393932638573460281e-05 2.504040312487632036e-04 5.863193795084953308e-02
7.000000000000000000e+03 1.663364656269550323e-02 2.500112459529191256e-04 1.168848370980413165e-06 4.319827348808757961e-05 3.412610094528645277e-04 6.908388435840606689e-02 1.663364656269550323e-02 2.500112459529191256e-04 1.168848370980413165e-06 4.319827348808757961e-05 3.412610094528645277e-04 6.908388435840606689e-02
8.000000000000000000e+03 1.636902242898941040e-02 1.359892921755090356e-04 3.165312591590918601e-05 7.109405851224437356e-05 1.444192312192171812e-04 6.643680483102798462e-02 1.636902242898941040e-02 1.359892921755090356e-04 3.165312591590918601e-05 7.109405851224437356e-05 1.444192312192171812e-04 6.643680483102798462e-02
9.000000000000000000e+03 1.905301772058010101e-02 2.568187192082405090e-04 9.749994205776602030e-06 9.949041850632056594e-05 1.771867973729968071e-04 5.369462072849273682e-02 1.905301772058010101e-02 2.568187192082405090e-04 9.749994205776602030e-06 9.949041850632056594e-05 1.771867973729968071e-04 5.369462072849273682e-02
1.000000000000000000e+04 1.646036468446254730e-02 3.227089764550328255e-04 5.929576218477450311e-06 9.961629257304593921e-05 3.381403512321412563e-04 6.987853348255157471e-02 1.646036468446254730e-02 3.227089764550328255e-04 5.929576218477450311e-06 9.961629257304593921e-05 3.381403512321412563e-04 6.987853348255157471e-02
