# learning_rate: 0.0001
# num_dense_layers: 7
# num_dense_nodes: 60
# activation:ReLU 
# batch_size: 32
# final loss: 0.04159273952245712
# Training Time: 105.81809210777283
# Best Step: 4000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 1.160109117627143860e-01 1.494225859642028809e-02 1.578974165022373199e-02 7.599481847137212753e-03 4.787845071405172348e-03 3.324235677719116211e-01 1.160109117627143860e-01 1.494225859642028809e-02 1.578974165022373199e-02 7.599481847137212753e-03 4.787845071405172348e-03 3.324235677719116211e-01
1.000000000000000000e+03 1.470073871314525604e-02 3.570300468709319830e-04 2.810524711094330996e-05 6.909750663908198476e-05 2.499788824934512377e-04 6.536514312028884888e-02 1.470073871314525604e-02 3.570300468709319830e-04 2.810524711094330996e-05 6.909750663908198476e-05 2.499788824934512377e-04 6.536514312028884888e-02
2.000000000000000000e+03 2.068793214857578278e-02 1.156196049123536795e-05 1.988627991522662342e-05 3.336325244163163006e-05 6.551710976054891944e-05 2.283472940325737000e-02 2.068793214857578278e-02 1.156196049123536795e-05 1.988627991522662342e-05 3.336325244163163006e-05 6.551710976054891944e-05 2.283472940325737000e-02
3.000000000000000000e+03 2.053252235054969788e-02 1.313565007876604795e-05 2.581139051471836865e-05 5.015363785787485540e-05 7.236410601763054729e-05 2.264238707721233368e-02 2.053252235054969788e-02 1.313565007876604795e-05 2.581139051471836865e-05 5.015363785787485540e-05 7.236410601763054729e-05 2.264238707721233368e-02
4.000000000000000000e+03 1.940082758665084839e-02 2.094492629112210125e-05 2.431967732263728976e-05 4.004631409770809114e-05 9.648145351093262434e-05 2.201011776924133301e-02 1.940082758665084839e-02 2.094492629112210125e-05 2.431967732263728976e-05 4.004631409770809114e-05 9.648145351093262434e-05 2.201011776924133301e-02
5.000000000000000000e+03 1.967431977391242981e-02 3.596016540541313589e-05 3.333141648909077048e-05 4.912293661618605256e-05 1.238904515048488975e-04 2.335654757916927338e-02 1.967431977391242981e-02 3.596016540541313589e-05 3.333141648909077048e-05 4.912293661618605256e-05 1.238904515048488975e-04 2.335654757916927338e-02
6.000000000000000000e+03 2.042191289365291595e-02 4.000102853751741350e-05 2.368089371884707361e-05 6.602013309020549059e-05 1.707835035631433129e-04 2.275649458169937134e-02 2.042191289365291595e-02 4.000102853751741350e-05 2.368089371884707361e-05 6.602013309020549059e-05 1.707835035631433129e-04 2.275649458169937134e-02
7.000000000000000000e+03 1.888866350054740906e-02 3.431503500905819237e-05 3.351709210619446822e-06 2.805565964081324637e-05 1.170370960608124733e-04 2.811315283179283142e-02 1.888866350054740906e-02 3.431503500905819237e-05 3.351709210619446822e-06 2.805565964081324637e-05 1.170370960608124733e-04 2.811315283179283142e-02
8.000000000000000000e+03 1.918984204530715942e-02 4.432335481396876276e-05 1.246952069777762517e-05 6.103104169596917927e-05 1.344465126749128103e-04 2.691100910305976868e-02 1.918984204530715942e-02 4.432335481396876276e-05 1.246952069777762517e-05 6.103104169596917927e-05 1.344465126749128103e-04 2.691100910305976868e-02
9.000000000000000000e+03 2.260518446564674377e-02 5.988390694255940616e-05 2.791568113025277853e-05 8.017447544261813164e-05 1.529075525468215346e-04 3.166250139474868774e-02 2.260518446564674377e-02 5.988390694255940616e-05 2.791568113025277853e-05 8.017447544261813164e-05 1.529075525468215346e-04 3.166250139474868774e-02
1.000000000000000000e+04 2.245550602674484253e-02 5.275357398204505444e-05 4.787739726452855393e-06 3.272435424150899053e-05 1.395602594129741192e-04 3.626006469130516052e-02 2.245550602674484253e-02 5.275357398204505444e-05 4.787739726452855393e-06 3.272435424150899053e-05 1.395602594129741192e-04 3.626006469130516052e-02
