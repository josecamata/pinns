# learning_rate: 0.0187
# num_dense_layers: 8
# num_dense_nodes: 50
# activation:Swish 
# batch_size: 32
# final loss: 0.00047693014494143426
# Training Time: 253.72972655296326

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 4.644753062166273594e-04 1.680252921687497292e-06 2.264577960886526853e-05 1.506199532741447911e-05 5.662977855536155403e-07 1.609329134225845337e-01 4.644753062166273594e-04 1.680252921687497292e-06 2.264577960886526853e-05 1.506199532741447911e-05 5.662977855536155403e-07 1.609329134225845337e-01
1.000000000000000000e+03 1.095094718039035797e-03 3.364173608133569360e-06 9.024656719702761620e-06 4.981635356671176851e-06 5.402837359724799171e-06 3.260653757024556398e-04 1.095094718039035797e-03 3.364173608133569360e-06 9.024656719702761620e-06 4.981635356671176851e-06 5.402837359724799171e-06 3.260653757024556398e-04
2.000000000000000000e+03 1.608634367585182190e-03 2.999316166096832603e-06 1.055982556863455102e-05 2.696854153327876702e-06 3.931066203222144395e-06 7.981783710420131683e-04 1.608634367585182190e-03 2.999316166096832603e-06 1.055982556863455102e-05 2.696854153327876702e-06 3.931066203222144395e-06 7.981783710420131683e-04
3.000000000000000000e+03 8.913719793781638145e-04 3.637402869571815245e-06 3.536654958224971779e-06 3.764625944313593209e-06 5.604667876468738541e-06 5.781352519989013672e-04 8.913719793781638145e-04 3.637402869571815245e-06 3.536654958224971779e-06 3.764625944313593209e-06 5.604667876468738541e-06 5.781352519989013672e-04
4.000000000000000000e+03 3.075132553931325674e-04 8.752250550969620235e-07 9.364576953885261901e-07 7.156896231208520476e-07 2.311461685167159885e-06 1.645780575927346945e-04 3.075132553931325674e-04 8.752250550969620235e-07 9.364576953885261901e-07 7.156896231208520476e-07 2.311461685167159885e-06 1.645780575927346945e-04
5.000000000000000000e+03 7.507026940584182739e-02 7.798384758643805981e-04 9.705765987746417522e-04 7.924292585812509060e-04 5.229814560152590275e-04 1.265173256397247314e-01 7.507026940584182739e-02 7.798384758643805981e-04 9.705765987746417522e-04 7.924292585812509060e-04 5.229814560152590275e-04 1.265173256397247314e-01
6.000000000000000000e+03 2.407075837254524231e-02 2.292516001034528017e-04 3.011696098838001490e-04 2.571184595581144094e-04 1.756759447744116187e-04 1.279604136943817139e-01 2.407075837254524231e-02 2.292516001034528017e-04 3.011696098838001490e-04 2.571184595581144094e-04 1.756759447744116187e-04 1.279604136943817139e-01
7.000000000000000000e+03 1.767872087657451630e-02 3.469576477073132992e-04 4.648835456464439631e-04 3.956376749556511641e-04 2.625270863063633442e-04 1.260391622781753540e-01 1.767872087657451630e-02 3.469576477073132992e-04 4.648835456464439631e-04 3.956376749556511641e-04 2.625270863063633442e-04 1.260391622781753540e-01
8.000000000000000000e+03 3.393382998183369637e-03 2.936025557573884726e-04 3.870712243951857090e-04 3.323794808238744736e-04 2.404552215011790395e-04 1.306572854518890381e-01 3.393382998183369637e-03 2.936025557573884726e-04 3.870712243951857090e-04 3.323794808238744736e-04 2.404552215011790395e-04 1.306572854518890381e-01
9.000000000000000000e+03 3.007113700732588768e-03 2.840164233930408955e-04 3.712113830260932446e-04 3.181379579473286867e-04 2.343154046684503555e-04 1.308455914258956909e-01 3.007113700732588768e-03 2.840164233930408955e-04 3.712113830260932446e-04 3.181379579473286867e-04 2.343154046684503555e-04 1.308455914258956909e-01
1.000000000000000000e+04 3.074253676459193230e-03 2.908166788984090090e-04 3.780040133278816938e-04 3.230517904739826918e-04 2.383629180258139968e-04 1.304781734943389893e-01 3.074253676459193230e-03 2.908166788984090090e-04 3.780040133278816938e-04 3.230517904739826918e-04 2.383629180258139968e-04 1.304781734943389893e-01
