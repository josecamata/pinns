# learning_rate: 0.00389
# num_dense_layers: 3
# num_dense_nodes: 60
# activation:sigmoid 
# batch_size: 32
# final loss: 0.0054864357225596905
# Training Time: 92.32150030136108

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 6.579357432201504707e-04 6.939747184514999390e-02 6.714572757482528687e-02 6.638163328170776367e-02 6.879601627588272095e-02 4.125270843505859375e+00 6.579357432201504707e-04 6.939747184514999390e-02 6.714572757482528687e-02 6.638163328170776367e-02 6.879601627588272095e-02 4.125270843505859375e+00
1.000000000000000000e+03 9.680859744548797607e-03 2.975751704070717096e-04 7.523431122535839677e-05 6.692689930787310004e-05 1.793908450054004788e-04 5.951631441712379456e-02 9.680859744548797607e-03 2.975751704070717096e-04 7.523431122535839677e-05 6.692689930787310004e-05 1.793908450054004788e-04 5.951631441712379456e-02
2.000000000000000000e+03 1.076004933565855026e-02 3.671637095976620913e-04 1.173658165498636663e-04 7.037529576336964965e-05 2.771253639366477728e-04 1.775631494820117950e-02 1.076004933565855026e-02 3.671637095976620913e-04 1.173658165498636663e-04 7.037529576336964965e-05 2.771253639366477728e-04 1.775631494820117950e-02
3.000000000000000000e+03 9.363331831991672516e-03 2.709671098273247480e-04 5.916682493989355862e-05 8.510780753567814827e-05 2.536204992793500423e-04 8.841176517307758331e-03 9.363331831991672516e-03 2.709671098273247480e-04 5.916682493989355862e-05 8.510780753567814827e-05 2.536204992793500423e-04 8.841176517307758331e-03
4.000000000000000000e+03 8.206004276871681213e-03 2.246335207019001245e-04 5.514394069905392826e-05 1.009215484373271465e-04 2.362212399020791054e-04 6.217580288648605347e-03 8.206004276871681213e-03 2.246335207019001245e-04 5.514394069905392826e-05 1.009215484373271465e-04 2.362212399020791054e-04 6.217580288648605347e-03
5.000000000000000000e+03 7.472668774425983429e-03 1.675504609011113644e-04 5.196210258873179555e-05 1.129181400756351650e-04 1.981820532819256186e-04 4.514529835432767868e-03 7.472668774425983429e-03 1.675504609011113644e-04 5.196210258873179555e-05 1.129181400756351650e-04 1.981820532819256186e-04 4.514529835432767868e-03
6.000000000000000000e+03 6.815190427005290985e-03 1.289594511035829782e-04 5.172610326553694904e-05 8.080655243247747421e-05 1.358692679787054658e-04 3.291960339993238449e-03 6.815190427005290985e-03 1.289594511035829782e-04 5.172610326553694904e-05 8.080655243247747421e-05 1.358692679787054658e-04 3.291960339993238449e-03
7.000000000000000000e+03 6.281152367591857910e-03 9.882143058348447084e-05 5.873062764294445515e-05 6.411402137018740177e-05 1.033932712743990123e-04 2.406582701951265335e-03 6.281152367591857910e-03 9.882143058348447084e-05 5.873062764294445515e-05 6.411402137018740177e-05 1.033932712743990123e-04 2.406582701951265335e-03
8.000000000000000000e+03 5.796303972601890564e-03 7.618458039360120893e-05 6.529126403620466590e-05 5.531227725441567600e-05 7.570236630272120237e-05 1.529225730337202549e-03 5.796303972601890564e-03 7.618458039360120893e-05 6.529126403620466590e-05 5.531227725441567600e-05 7.570236630272120237e-05 1.529225730337202549e-03
9.000000000000000000e+03 5.301481578499078751e-03 5.186904672882519662e-05 6.170439155539497733e-05 3.907126301783137023e-05 4.151162283960729837e-05 8.506997255608439445e-04 5.301481578499078751e-03 5.186904672882519662e-05 6.170439155539497733e-05 3.907126301783137023e-05 4.151162283960729837e-05 8.506997255608439445e-04
1.000000000000000000e+04 4.825696814805269241e-03 3.402627044124528766e-05 5.664095078827813268e-05 2.976923678943421692e-05 2.435315582260955125e-05 5.159490974619984627e-04 4.825696814805269241e-03 3.402627044124528766e-05 5.664095078827813268e-05 2.976923678943421692e-05 2.435315582260955125e-05 5.159490974619984627e-04
