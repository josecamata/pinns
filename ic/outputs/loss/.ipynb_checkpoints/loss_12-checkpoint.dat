# learning_rate: 0.001
# num_dense_layers: 3
# num_dense_nodes: 30
# activation:sin 
# batch_size: 32
# final loss: 0.002006220631301403
# Training Time: 90.58076930046082

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 2.840460300445556641e+00 1.109908055514097214e-02 4.006924852728843689e-02 3.752641752362251282e-02 6.328474264591932297e-03 9.011350870132446289e-01 2.840460300445556641e+00 1.109908055514097214e-02 4.006924852728843689e-02 3.752641752362251282e-02 6.328474264591932297e-03 9.011350870132446289e-01
1.000000000000000000e+03 1.462283544242382050e-02 1.642558490857481956e-04 5.009963206248357892e-05 1.127220239141024649e-04 2.795131003949791193e-04 3.342400863766670227e-02 1.462283544242382050e-02 1.642558490857481956e-04 5.009963206248357892e-05 1.127220239141024649e-04 2.795131003949791193e-04 3.342400863766670227e-02
2.000000000000000000e+03 9.257943369448184967e-03 5.228099325904622674e-05 5.470391624839976430e-05 6.876364204799756408e-05 8.532098581781610847e-05 9.371221065521240234e-03 9.257943369448184967e-03 5.228099325904622674e-05 5.470391624839976430e-05 6.876364204799756408e-05 8.532098581781610847e-05 9.371221065521240234e-03
3.000000000000000000e+03 5.806426517665386200e-03 3.683305476442910731e-05 2.988977394124958664e-05 3.517961886245757341e-05 3.799446494667790830e-05 1.771191367879509926e-03 5.806426517665386200e-03 3.683305476442910731e-05 2.988977394124958664e-05 3.517961886245757341e-05 3.799446494667790830e-05 1.771191367879509926e-03
4.000000000000000000e+03 3.966401796787977219e-03 3.001670665980782360e-05 3.028353057743515819e-05 1.959816836460959166e-05 2.496188972145318985e-05 7.402203045785427094e-04 3.966401796787977219e-03 3.001670665980782360e-05 3.028353057743515819e-05 1.959816836460959166e-05 2.496188972145318985e-05 7.402203045785427094e-04
5.000000000000000000e+03 2.913124859333038330e-03 1.787577457434963435e-05 2.178404247388243675e-05 1.431549299013568088e-05 1.711164077278226614e-05 4.543078830465674400e-04 2.913124859333038330e-03 1.787577457434963435e-05 2.178404247388243675e-05 1.431549299013568088e-05 1.711164077278226614e-05 4.543078830465674400e-04
6.000000000000000000e+03 2.347546629607677460e-03 1.641364360693842173e-05 2.089185545628424734e-05 1.302174405282130465e-05 1.411291759723098949e-05 3.287508152425289154e-04 2.347546629607677460e-03 1.641364360693842173e-05 2.089185545628424734e-05 1.302174405282130465e-05 1.411291759723098949e-05 3.287508152425289154e-04
7.000000000000000000e+03 1.848695101216435432e-03 1.310949573962716386e-05 1.900734605442266911e-05 1.094159688364015892e-05 1.044410237227566540e-05 2.325874665984883904e-04 1.848695101216435432e-03 1.310949573962716386e-05 1.900734605442266911e-05 1.094159688364015892e-05 1.044410237227566540e-05 2.325874665984883904e-04
8.000000000000000000e+03 2.190003171563148499e-03 1.269332551601110026e-05 1.827903179218992591e-05 1.387631982652237639e-05 1.502009308751439676e-05 3.576973977033048868e-04 2.190003171563148499e-03 1.269332551601110026e-05 1.827903179218992591e-05 1.387631982652237639e-05 1.502009308751439676e-05 3.576973977033048868e-04
9.000000000000000000e+03 1.687270239926874638e-03 9.913625945046078414e-06 1.275020076718647033e-05 1.050367427524179220e-05 8.421560778515413404e-06 2.773612795863300562e-04 1.687270239926874638e-03 9.913625945046078414e-06 1.275020076718647033e-05 1.050367427524179220e-05 8.421560778515413404e-06 2.773612795863300562e-04
1.000000000000000000e+04 1.633835956454277039e-03 6.920814030308974907e-06 1.173149303212994710e-05 1.113214875658741221e-05 1.109891854866873473e-05 3.363862633705139160e-04 1.633835956454277039e-03 6.920814030308974907e-06 1.173149303212994710e-05 1.113214875658741221e-05 1.109891854866873473e-05 3.363862633705139160e-04
