# learning_rate: 0.05
# num_dense_layers: 10
# num_dense_nodes: 50
# activation:Swish 
# batch_size: 32
# final loss: 0.006192987784743309
# Training Time: 308.98281383514404

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 1.349585800198838115e-04 1.706390321487560868e-05 7.919341442175209522e-06 5.616901717075961642e-07 3.638128646343830042e-06 1.521564424037933350e-01 1.349585800198838115e-04 1.706390321487560868e-05 7.919341442175209522e-06 5.616901717075961642e-07 3.638128646343830042e-06 1.521564424037933350e-01
1.000000000000000000e+03 1.289446745067834854e-02 8.981750397651921958e-06 6.272039172472432256e-06 5.039922598371049389e-06 1.171317853732034564e-05 3.412732388824224472e-03 1.289446745067834854e-02 8.981750397651921958e-06 6.272039172472432256e-06 5.039922598371049389e-06 1.171317853732034564e-05 3.412732388824224472e-03
2.000000000000000000e+03 8.187474682927131653e-03 2.587421295174863189e-05 1.822192098188679665e-05 3.191857467754743993e-05 2.737099202931858599e-05 1.335220178589224815e-03 8.187474682927131653e-03 2.587421295174863189e-05 1.822192098188679665e-05 3.191857467754743993e-05 2.737099202931858599e-05 1.335220178589224815e-03
3.000000000000000000e+03 5.734418053179979324e-03 8.588248419982846826e-06 2.836794010363519192e-05 3.428896889090538025e-05 1.180480558105045930e-05 3.755194484256207943e-04 5.734418053179979324e-03 8.588248419982846826e-06 2.836794010363519192e-05 3.428896889090538025e-05 1.180480558105045930e-05 3.755194484256207943e-04
4.000000000000000000e+03 4.952712450176477432e-03 4.774967692355858162e-06 2.039289938693400472e-05 3.037859642063267529e-05 9.553762538416776806e-06 1.224744017235934734e-03 4.952712450176477432e-03 4.774967692355858162e-06 2.039289938693400472e-05 3.037859642063267529e-05 9.553762538416776806e-06 1.224744017235934734e-03
5.000000000000000000e+03 0.000000000000000000e+00 1.879350244998931885e-01 1.879350244998931885e-01 1.879350244998931885e-01 1.879350244998931885e-01 1.041032314300537109e+01 0.000000000000000000e+00 1.879350244998931885e-01 1.879350244998931885e-01 1.879350244998931885e-01 1.879350244998931885e-01 1.041032314300537109e+01
6.000000000000000000e+03 0.000000000000000000e+00 3.348383179400116205e-04 3.348383179400116205e-04 3.348383179400116205e-04 3.348383470438420773e-04 1.377461552619934082e-01 0.000000000000000000e+00 3.348383179400116205e-04 3.348383179400116205e-04 3.348383179400116205e-04 3.348383470438420773e-04 1.377461552619934082e-01
7.000000000000000000e+03 0.000000000000000000e+00 3.345735312905162573e-04 3.345735312905162573e-04 3.345735312905162573e-04 3.345735312905162573e-04 1.377471983432769775e-01 0.000000000000000000e+00 3.345735312905162573e-04 3.345735312905162573e-04 3.345735312905162573e-04 3.345735312905162573e-04 1.377471983432769775e-01
8.000000000000000000e+03 0.000000000000000000e+00 3.344852593727409840e-04 3.344852593727409840e-04 3.344852593727409840e-04 3.344852884765714407e-04 1.377475410699844360e-01 0.000000000000000000e+00 3.344852593727409840e-04 3.344852593727409840e-04 3.344852593727409840e-04 3.344852884765714407e-04 1.377475410699844360e-01
9.000000000000000000e+03 0.000000000000000000e+00 3.345735312905162573e-04 3.345735312905162573e-04 3.345735312905162573e-04 3.345735312905162573e-04 1.377471983432769775e-01 0.000000000000000000e+00 3.345735312905162573e-04 3.345735312905162573e-04 3.345735312905162573e-04 3.345735312905162573e-04 1.377471983432769775e-01
1.000000000000000000e+04 0.000000000000000000e+00 6.366413086652755737e-02 6.366413086652755737e-02 6.366413086652755737e-02 6.366413086652755737e-02 2.841900825500488281e+00 0.000000000000000000e+00 6.366413086652755737e-02 6.366413086652755737e-02 6.366413086652755737e-02 6.366413086652755737e-02 2.841900825500488281e+00
