# learning_rate: 0.0084
# num_dense_layers: 10
# num_dense_nodes: 80
# activation:sin 
# batch_size: 32
# final loss: 0.00015355864888988435
# Training Time: 259.27426314353943
# Best Step: 5000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 2.179034650325775146e-01 1.457878854125738144e-03 2.059413120150566101e-03 1.843554317019879818e-03 1.803595660021528602e-04 2.159149199724197388e-01 2.179034650325775146e-01 1.457878854125738144e-03 2.059413120150566101e-03 1.843554317019879818e-03 1.803595660021528602e-04 2.159149199724197388e-01
1.000000000000000000e+03 5.552282091230154037e-03 2.198720176238566637e-05 1.265611808776156977e-05 4.690780770033597946e-06 1.312332369707291946e-05 2.531230857130140066e-04 5.552282091230154037e-03 2.198720176238566637e-05 1.265611808776156977e-05 4.690780770033597946e-06 1.312332369707291946e-05 2.531230857130140066e-04
2.000000000000000000e+03 1.545601844554767013e-04 3.279621523688547313e-06 1.975737632164964452e-06 2.617697418827447109e-06 3.939441739930771291e-06 2.085131563944742084e-05 1.545601844554767013e-04 3.279621523688547313e-06 1.975737632164964452e-06 2.617697418827447109e-06 3.939441739930771291e-06 2.085131563944742084e-05
3.000000000000000000e+03 2.080856938846409321e-04 2.908209353336133063e-05 3.350279803271405399e-05 3.797606041189283133e-05 2.924957698269281536e-05 4.035890568047761917e-03 2.080856938846409321e-04 2.908209353336133063e-05 3.350279803271405399e-05 3.797606041189283133e-05 2.924957698269281536e-05 4.035890568047761917e-03
4.000000000000000000e+03 7.961035589687526226e-05 3.344299329910427332e-06 3.382442173460731283e-06 3.564201733752270229e-06 3.483005002635763958e-06 1.895076711662113667e-04 7.961035589687526226e-05 3.344299329910427332e-06 3.382442173460731283e-06 3.564201733752270229e-06 3.483005002635763958e-06 1.895076711662113667e-04
5.000000000000000000e+03 5.763437002315185964e-05 2.002692099267733283e-06 2.107329237333033234e-06 2.291589908054447733e-06 2.949754389192094095e-06 8.657291618874296546e-05 5.763437002315185964e-05 2.002692099267733283e-06 2.107329237333033234e-06 2.291589908054447733e-06 2.949754389192094095e-06 8.657291618874296546e-05
6.000000000000000000e+03 2.045513498166728894e-12 3.345929144416004419e-04 3.345929144416004419e-04 3.345929144416004419e-04 3.345929435454308987e-04 1.377471089363098145e-01 2.045513498166728894e-12 3.345929144416004419e-04 3.345929144416004419e-04 3.345929144416004419e-04 3.345929435454308987e-04 1.377471089363098145e-01
7.000000000000000000e+03 7.424530506134033203e+00 3.345276345498859882e-04 3.344844735693186522e-04 3.344874712638556957e-04 3.345134900882840157e-04 1.377465128898620605e-01 7.424530506134033203e+00 3.345276345498859882e-04 3.344844735693186522e-04 3.344874712638556957e-04 3.345134900882840157e-04 1.377465128898620605e-01
8.000000000000000000e+03 1.324837350935581526e-09 3.345927107147872448e-04 3.345927107147872448e-04 3.345927107147872448e-04 3.345927398186177015e-04 1.377471089363098145e-01 1.324837350935581526e-09 3.345927107147872448e-04 3.345927107147872448e-04 3.345927107147872448e-04 3.345927398186177015e-04 1.377471089363098145e-01
9.000000000000000000e+03 9.327627645966396486e-13 3.345927107147872448e-04 3.345927107147872448e-04 3.345927107147872448e-04 3.345927398186177015e-04 1.377471089363098145e-01 9.327627645966396486e-13 3.345927107147872448e-04 3.345927107147872448e-04 3.345927107147872448e-04 3.345927398186177015e-04 1.377471089363098145e-01
1.000000000000000000e+04 5.390755087137222290e-02 3.345851728226989508e-04 3.345864824950695038e-04 3.345834265928715467e-04 3.345859877299517393e-04 1.377469897270202637e-01 5.390755087137222290e-02 3.345851728226989508e-04 3.345864824950695038e-04 3.345834265928715467e-04 3.345859877299517393e-04 1.377469897270202637e-01
