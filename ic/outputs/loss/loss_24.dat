# learning_rate: 0.0187
# num_dense_layers: 10
# num_dense_nodes: 40
# activation:sin 
# batch_size: 32
# final loss: 0.0003613476292230189
# Training Time: 184.52090907096863
# Best Step: 4000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 6.245897293090820312e+00 1.324006821960210800e-02 4.006090760231018066e-02 1.771805994212627411e-02 1.251979358494281769e-02 1.630898833274841309e+00 6.245897293090820312e+00 1.324006821960210800e-02 4.006090760231018066e-02 1.771805994212627411e-02 1.251979358494281769e-02 1.630898833274841309e+00
1.000000000000000000e+03 7.214345969259738922e-04 1.521771650914161000e-06 5.621122909360565245e-07 1.811966825471245102e-07 1.033286366691754665e-06 2.443685079924762249e-04 7.214345969259738922e-04 1.521771650914161000e-06 5.621122909360565245e-07 1.811966825471245102e-07 1.033286366691754665e-06 2.443685079924762249e-04
2.000000000000000000e+03 2.192290994571521878e-04 4.920293577015399933e-06 4.990203706256579608e-06 4.567131327348761261e-06 5.558188149734633043e-06 2.511463826522231102e-04 2.192290994571521878e-04 4.920293577015399933e-06 4.990203706256579608e-06 4.567131327348761261e-06 5.558188149734633043e-06 2.511463826522231102e-04
3.000000000000000000e+03 1.678280241321772337e-04 2.141477125405799598e-06 1.884172206700895913e-06 1.752154275891371071e-06 2.303075007148436271e-06 2.078159886877983809e-04 1.678280241321772337e-04 2.141477125405799598e-06 1.884172206700895913e-06 1.752154275891371071e-06 2.303075007148436271e-06 2.078159886877983809e-04
4.000000000000000000e+03 1.342121540801599622e-04 1.967069920283393003e-06 1.787804876585141756e-06 1.952997763510211371e-06 2.473737140462617390e-06 2.189538790844380856e-04 1.342121540801599622e-04 1.967069920283393003e-06 1.787804876585141756e-06 1.952997763510211371e-06 2.473737140462617390e-06 2.189538790844380856e-04
5.000000000000000000e+03 2.129839413100853562e-04 1.443016913071915042e-06 1.854556444413901772e-06 1.564062813486088999e-06 2.129297627107007429e-06 2.950901689473539591e-04 2.129839413100853562e-04 1.443016913071915042e-06 1.854556444413901772e-06 1.564062813486088999e-06 2.129297627107007429e-06 2.950901689473539591e-04
6.000000000000000000e+03 6.547325440000000000e+08 3.129178367089480162e-04 3.130146942567080259e-04 3.206724068149924278e-04 3.153240832034498453e-04 1.379582732915878296e-01 6.547325440000000000e+08 3.129178367089480162e-04 3.130146942567080259e-04 3.206724068149924278e-04 3.153240832034498453e-04 1.379582732915878296e-01
7.000000000000000000e+03 1.833644218721900560e-15 3.345926525071263313e-04 3.345926525071263313e-04 3.345926525071263313e-04 3.345927107147872448e-04 1.377471089363098145e-01 1.833644218721900560e-15 3.345926525071263313e-04 3.345926525071263313e-04 3.345926525071263313e-04 3.345927107147872448e-04 1.377471089363098145e-01
8.000000000000000000e+03 8.243035316467285156e+00 3.345819131936877966e-04 3.345836303196847439e-04 3.345806326251477003e-04 3.345810982864350080e-04 1.377471089363098145e-01 8.243035316467285156e+00 3.345819131936877966e-04 3.345836303196847439e-04 3.345806326251477003e-04 3.345810982864350080e-04 1.377471089363098145e-01
9.000000000000000000e+03 1.119286260897744967e-10 3.345927107147872448e-04 3.345927107147872448e-04 3.345927107147872448e-04 3.345927398186177015e-04 1.377471089363098145e-01 1.119286260897744967e-10 3.345927107147872448e-04 3.345927107147872448e-04 3.345927107147872448e-04 3.345927398186177015e-04 1.377471089363098145e-01
1.000000000000000000e+04 9.086865931749343872e-02 3.345922741573303938e-04 3.345922741573303938e-04 3.345922741573303938e-04 3.345923905726522207e-04 1.377471089363098145e-01 9.086865931749343872e-02 3.345922741573303938e-04 3.345922741573303938e-04 3.345922741573303938e-04 3.345923905726522207e-04 1.377471089363098145e-01
