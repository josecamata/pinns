# learning_rate: 0.00658
# num_dense_layers: 4
# num_dense_nodes: 70
# activation:ReLU 
# batch_size: 32
# final loss: 0.07036282867193222
# Training Time: 83.38764381408691

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 2.613412141799926758e-01 1.153249572962522507e-02 4.909699317067861557e-03 2.462072006892412901e-04 2.649407833814620972e-03 7.654691338539123535e-01 2.613412141799926758e-01 1.153249572962522507e-02 4.909699317067861557e-03 2.462072006892412901e-04 2.649407833814620972e-03 7.654691338539123535e-01
1.000000000000000000e+03 2.386174350976943970e-02 1.308394421357661486e-04 8.514129149261862040e-06 7.882588397478684783e-05 1.894736633403226733e-04 4.761233925819396973e-02 2.386174350976943970e-02 1.308394421357661486e-04 8.514129149261862040e-06 7.882588397478684783e-05 1.894736633403226733e-04 4.761233925819396973e-02
2.000000000000000000e+03 1.878523267805576324e-02 1.205297521664761007e-04 7.415894742734963074e-06 2.336553734494373202e-05 5.011544635635800660e-05 5.137617141008377075e-02 1.878523267805576324e-02 1.205297521664761007e-04 7.415894742734963074e-06 2.336553734494373202e-05 5.011544635635800660e-05 5.137617141008377075e-02
3.000000000000000000e+03 1.668989285826683044e-02 1.661863207118585706e-04 1.736971717036794871e-05 5.091784987598657608e-05 1.335318374913185835e-04 5.692663788795471191e-02 1.668989285826683044e-02 1.661863207118585706e-04 1.736971717036794871e-05 5.091784987598657608e-05 1.335318374913185835e-04 5.692663788795471191e-02
4.000000000000000000e+03 2.034271135926246643e-02 1.804260391509160399e-04 1.971253186638932675e-05 8.995269308798015118e-05 2.865606511477380991e-04 6.008851528167724609e-02 2.034271135926246643e-02 1.804260391509160399e-04 1.971253186638932675e-05 8.995269308798015118e-05 2.865606511477380991e-04 6.008851528167724609e-02
5.000000000000000000e+03 2.254344895482063293e-02 1.414584839949384332e-04 1.961677526196581312e-06 5.125504321767948568e-05 2.353016025153920054e-04 5.043538287281990051e-02 2.254344895482063293e-02 1.414584839949384332e-04 1.961677526196581312e-06 5.125504321767948568e-05 2.353016025153920054e-04 5.043538287281990051e-02
6.000000000000000000e+03 1.379432901740074158e-02 1.853442518040537834e-04 8.238977898145094514e-06 9.586926807969575748e-07 7.403096242342144251e-05 7.780973613262176514e-02 1.379432901740074158e-02 1.853442518040537834e-04 8.238977898145094514e-06 9.586926807969575748e-07 7.403096242342144251e-05 7.780973613262176514e-02
7.000000000000000000e+03 2.654317393898963928e-02 1.101624729926697910e-04 1.044505625031888485e-04 4.195558431092649698e-04 7.991309394128620625e-04 8.008375018835067749e-02 2.654317393898963928e-02 1.101624729926697910e-04 1.044505625031888485e-04 4.195558431092649698e-04 7.991309394128620625e-04 8.008375018835067749e-02
8.000000000000000000e+03 3.516153991222381592e-02 1.047026235028170049e-04 1.174524459202075377e-05 5.541198333958163857e-05 6.673826283076778054e-05 4.632963985204696655e-02 3.516153991222381592e-02 1.047026235028170049e-04 1.174524459202075377e-05 5.541198333958163857e-05 6.673826283076778054e-05 4.632963985204696655e-02
9.000000000000000000e+03 2.210974507033824921e-02 1.237411779584363103e-04 5.874754151591332629e-06 6.639162165811285377e-05 2.498180547263473272e-04 5.181040242314338684e-02 2.210974507033824921e-02 1.237411779584363103e-04 5.874754151591332629e-06 6.639162165811285377e-05 2.498180547263473272e-04 5.181040242314338684e-02
1.000000000000000000e+04 2.196417748928070068e-02 2.706950472202152014e-04 2.237612716271542013e-05 1.100526787922717631e-04 2.517244720365852118e-04 5.327075719833374023e-02 2.196417748928070068e-02 2.706950472202152014e-04 2.237612716271542013e-05 1.100526787922717631e-04 2.517244720365852118e-04 5.327075719833374023e-02
