# learning_rate: 0.001
# num_dense_layers: 5
# num_dense_nodes: 60
# activation:tanh 
# batch_size: 32
# final loss: 0.029307104647159576
# Training Time: 80.50617837905884
# Best Step: 10000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 1.719900512695312500e+01 1.394497603178024292e-02 7.296544965356588364e-03 1.206388603895902634e-02 1.535215298645198345e-03 4.679152071475982666e-01 1.245239639282226562e+01 1.394497603178024292e-02 7.296544965356588364e-03 1.206388603895902634e-02 1.535215531475841999e-03 4.679152071475982666e-01
1.000000000000000000e+03 1.407554931938648224e-02 1.369247765978798270e-04 8.614362741354852915e-05 1.286579208681359887e-04 1.543910620966926217e-04 2.043961882591247559e-01 1.103494130074977875e-02 1.369247620459645987e-04 8.614361286163330078e-05 1.286579063162207603e-04 1.543910912005230784e-04 2.043961882591247559e-01
2.000000000000000000e+03 2.485091425478458405e-02 2.726164238993078470e-04 1.643207942834123969e-04 8.739860641071572900e-05 1.603020500624552369e-04 1.238432899117469788e-01 3.308011963963508606e-02 2.726163074839860201e-04 1.643208379391580820e-04 8.739859913475811481e-05 1.603020500624552369e-04 1.238433122634887695e-01
3.000000000000000000e+03 3.657478839159011841e-02 9.548325760988518596e-05 7.972262392286211252e-05 9.084355406230315566e-05 9.473722457187250257e-05 2.605708129703998566e-02 6.819773465394973755e-02 9.548322850605472922e-05 7.972268940648064017e-05 9.084351768251508474e-05 9.473723912378773093e-05 2.605708129703998566e-02
4.000000000000000000e+03 3.306725621223449707e-02 6.281818059505894780e-05 1.082322778529487550e-04 7.065937097650021315e-05 5.481830521603114903e-05 1.046759076416492462e-02 6.516604870557785034e-02 6.281816604314371943e-05 1.082322560250759125e-04 7.065935642458498478e-05 5.481831612996757030e-05 1.046759914606809616e-02
5.000000000000000000e+03 3.136659041047096252e-02 2.798883906507398933e-05 9.290247544413432479e-05 7.254278170876204967e-05 4.508010169956833124e-05 7.851911708712577820e-03 6.159880384802818298e-02 2.798889545374549925e-05 9.290247544413432479e-05 7.254280353663489223e-05 4.508013444137759507e-05 7.851913571357727051e-03
6.000000000000000000e+03 2.484149858355522156e-02 2.477550879120826721e-05 9.147190576186403632e-05 5.810376751469448209e-05 3.039040348085109144e-05 4.928836598992347717e-03 5.441404506564140320e-02 2.477546877344138920e-05 9.147196396952494979e-05 5.810376751469448209e-05 3.039039984287228435e-05 4.928840324282646179e-03
7.000000000000000000e+03 2.134032361209392548e-02 2.202300493081565946e-05 7.119500514818355441e-05 5.304764999891631305e-05 2.905862129409797490e-05 3.824810497462749481e-03 5.015650019049644470e-02 2.202306859544478357e-05 7.119496876839548349e-05 5.304767546476796269e-05 2.905862129409797490e-05 3.824809333309531212e-03
8.000000000000000000e+03 1.774157211184501648e-02 2.029379356827121228e-05 5.462435001390986145e-05 5.689870522473938763e-05 2.666382715688087046e-05 2.949154470115900040e-03 4.441320523619651794e-02 2.029374263656791300e-05 5.462433909997344017e-05 5.689870522473938763e-05 2.666380896698683500e-05 2.949157496914267540e-03
9.000000000000000000e+03 1.335984095931053162e-02 2.185235098295379430e-05 4.342246029409579933e-05 6.926849164301529527e-05 2.521760507079306990e-05 2.222718205302953720e-03 3.608427569270133972e-02 2.185234734497498721e-05 4.342246029409579933e-05 6.926848436705768108e-05 2.521760507079306990e-05 2.222717739641666412e-03
1.000000000000000000e+04 9.646507911384105682e-03 2.715259324759244919e-05 4.220841219648718834e-05 7.843259663786739111e-05 2.496586785127874464e-05 1.426656497642397881e-03 2.770769037306308746e-02 2.715264963626395911e-05 4.220845221425406635e-05 7.843259663786739111e-05 2.496590605005621910e-05 1.426656730473041534e-03
