# learning_rate: 0.0003046368229675614
# num_dense_layers: 4
# num_dense_nodes: 120
# activation:sin 
# batch_size: 32
# final loss: 0.011333787813782692
# Training Time: 86.49422359466553
# Best Step: 9000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 1.398370552062988281e+01 5.899123847484588623e-03 6.163237150758504868e-03 2.497256500646471977e-03 4.324565455317497253e-02 1.829897403717041016e+00 8.909200668334960938e+00 5.899123847484588623e-03 6.163237150758504868e-03 2.497256500646471977e-03 4.324565455317497253e-02 1.829897403717041016e+00
1.000000000000000000e+03 1.769872754812240601e-02 1.859742769738659263e-04 1.355104614049196243e-04 1.128107469412498176e-04 1.730288495309650898e-04 1.648144274950027466e-01 1.639019511640071869e-02 1.859742769738659263e-04 1.355104614049196243e-04 1.128107469412498176e-04 1.730288495309650898e-04 1.648144274950027466e-01
2.000000000000000000e+03 2.166648022830486298e-02 2.430487656965851784e-04 1.387009251629933715e-04 1.426826784154400229e-04 1.866741367848590016e-04 1.091169714927673340e-01 2.604816108942031860e-02 2.430487656965851784e-04 1.387009251629933715e-04 1.426826784154400229e-04 1.866741367848590016e-04 1.091169714927673340e-01
3.000000000000000000e+03 2.600308507680892944e-02 8.186131890397518873e-05 1.093775863409973681e-04 1.577302900841459632e-04 6.859334826003760099e-05 3.657786548137664795e-02 4.236439242959022522e-02 8.186131890397518873e-05 1.093775863409973681e-04 1.577302900841459632e-04 6.859334826003760099e-05 3.657786548137664795e-02
4.000000000000000000e+03 2.218550257384777069e-02 6.992220733081921935e-05 1.075470572686754167e-04 1.175251236418262124e-04 5.537858305615372956e-05 1.309534069150686264e-02 4.010283946990966797e-02 6.992220733081921935e-05 1.075470572686754167e-04 1.175251236418262124e-04 5.537858305615372956e-05 1.309534069150686264e-02
5.000000000000000000e+03 1.635512895882129669e-02 7.521368388552218676e-05 8.473527850583195686e-05 8.038747182581573725e-05 4.745882688439451158e-05 6.755981594324111938e-03 3.278637304902076721e-02 7.521368388552218676e-05 8.473527850583195686e-05 8.038747182581573725e-05 4.745882688439451158e-05 6.755981594324111938e-03
6.000000000000000000e+03 1.234348863363265991e-02 5.452545156003907323e-05 5.781206346000544727e-05 4.071453804499469697e-05 3.162043503834865987e-05 3.869246691465377808e-03 2.602939866483211517e-02 5.452545156003907323e-05 5.781206346000544727e-05 4.071453804499469697e-05 3.162043503834865987e-05 3.869246691465377808e-03
7.000000000000000000e+03 1.037422940135002136e-02 3.798088437179103494e-05 5.398676148615777493e-05 3.196893885615281761e-05 2.196679633925668895e-05 2.567431889474391937e-03 2.050853520631790161e-02 3.798088437179103494e-05 5.398676148615777493e-05 3.196893885615281761e-05 2.196679633925668895e-05 2.567431889474391937e-03
8.000000000000000000e+03 5.973461549729108810e-03 2.282290734001435339e-05 4.224170697852969170e-05 2.755587411229498684e-05 1.519316265330417082e-05 1.528198830783367157e-03 1.389691606163978577e-02 2.282290734001435339e-05 4.224170697852969170e-05 2.755587411229498684e-05 1.519316265330417082e-05 1.528198830783367157e-03
9.000000000000000000e+03 4.379062913358211517e-03 1.215814063471043482e-05 2.858404150174465030e-05 2.378400859015528113e-05 1.091667672881158069e-05 1.010753680020570755e-03 1.024759002029895782e-02 1.215814063471043482e-05 2.858404150174465030e-05 2.378400859015528113e-05 1.091667672881158069e-05 1.010753680020570755e-03
1.000000000000000000e+04 7.773624267429113388e-03 1.089449324354063720e-05 2.767236765066627413e-05 2.889605275413487107e-05 9.344887985207606107e-06 1.344371587038040161e-03 1.154634822160005569e-02 1.089449324354063720e-05 2.767236765066627413e-05 2.889605275413487107e-05 9.344887985207606107e-06 1.344371587038040161e-03
