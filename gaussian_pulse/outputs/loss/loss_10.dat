# learning_rate: 0.005
# num_dense_layers: 7
# num_dense_nodes: 80
# activation:sin 
# batch_size: 32
# final loss: 0.00046081937034614384
# Training Time: 184.40235424041748
# Best Step: 7000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 1.072383308410644531e+01 7.996738888323307037e-03 7.118341512978076935e-03 5.703960545361042023e-03 1.683080196380615234e-02 7.858859896659851074e-01 1.072383308410644531e+01 7.996738888323307037e-03 7.118341512978076935e-03 5.703960545361042023e-03 1.683080196380615234e-02 7.858859896659851074e-01
1.000000000000000000e+03 3.439226001501083374e-02 4.371530667413026094e-05 4.340881787356920540e-05 5.209181836107745767e-05 1.947986675077117980e-05 3.694936633110046387e-02 3.439226001501083374e-02 4.371530667413026094e-05 4.340881787356920540e-05 5.209181836107745767e-05 1.947986675077117980e-05 3.694936633110046387e-02
2.000000000000000000e+03 1.051194779574871063e-02 2.006121212616562843e-05 1.879533374449238181e-05 1.054681797540979460e-05 8.650261406728532165e-06 3.070165403187274933e-03 1.051194779574871063e-02 2.006121212616562843e-05 1.879533374449238181e-05 1.054681797540979460e-05 8.650261406728532165e-06 3.070165403187274933e-03
3.000000000000000000e+03 1.880608731880784035e-03 1.897631955216638744e-05 2.086998756567481905e-05 1.541989877296146005e-05 1.563493424328044057e-05 5.900771822780370712e-03 1.880608731880784035e-03 1.897631955216638744e-05 2.086998756567481905e-05 1.541989877296146005e-05 1.563493424328044057e-05 5.900771822780370712e-03
4.000000000000000000e+03 2.147311810404062271e-03 3.783480860874988139e-05 3.806807944783940911e-05 3.614434899645857513e-05 4.086181434104219079e-05 1.037536188960075378e-02 2.147311810404062271e-03 3.783480860874988139e-05 3.806807944783940911e-05 3.614434899645857513e-05 4.086181434104219079e-05 1.037536188960075378e-02
5.000000000000000000e+03 1.520026708021759987e-03 3.169058572893845849e-06 4.355727924121310934e-06 4.474208708415972069e-06 1.911870413096039556e-06 1.827454107115045190e-04 1.520026708021759987e-03 3.169058572893845849e-06 4.355727924121310934e-06 4.474208708415972069e-06 1.911870413096039556e-06 1.827454107115045190e-04
6.000000000000000000e+03 5.465174326673150063e-04 5.579572189162718132e-06 6.227897301869234070e-06 6.027257313689915463e-06 5.399301699071656913e-06 1.175184850580990314e-03 5.465174326673150063e-04 5.579572189162718132e-06 6.227897301869234070e-06 6.027257313689915463e-06 5.399301699071656913e-06 1.175184850580990314e-03
7.000000000000000000e+03 1.786527864169329405e-04 3.722736892086686566e-06 4.283849648345494643e-06 4.427597559697460383e-06 2.982082378366612829e-06 2.667503140401095152e-04 1.786527864169329405e-04 3.722736892086686566e-06 4.283849648345494643e-06 4.427597559697460383e-06 2.982082378366612829e-06 2.667503140401095152e-04
8.000000000000000000e+03 7.316215820312500000e+02 8.395523577928543091e-02 9.716525673866271973e-02 1.265517473220825195e-01 1.187834143638610840e-01 1.344101524353027344e+01 7.316215820312500000e+02 8.395523577928543091e-02 9.716525673866271973e-02 1.265517473220825195e-01 1.187834143638610840e-01 1.344101524353027344e+01
9.000000000000000000e+03 1.443274231860414147e-04 3.598388866521418095e-04 3.597598697524517775e-04 3.604785015340894461e-04 3.607095277402549982e-04 2.750514149665832520e-01 1.443274231860414147e-04 3.598388866521418095e-04 3.597598697524517775e-04 3.604785015340894461e-04 3.607095277402549982e-04 2.750514149665832520e-01
1.000000000000000000e+04 1.497058256063610315e-04 3.598213661462068558e-04 3.597422037273645401e-04 3.604701778385788202e-04 3.607032995205372572e-04 2.750407159328460693e-01 1.497058256063610315e-04 3.598213661462068558e-04 3.597422037273645401e-04 3.604701778385788202e-04 3.607032995205372572e-04 2.750407159328460693e-01
