# learning_rate: 0.036845522198561895
# num_dense_layers: 8
# num_dense_nodes: 92
# activation:tanh 
# batch_size: 32
# final loss: 0.2767811119556427
# Training Time: 121.1245698928833
# Best Step: 1000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 1.951368570327758789e+00 3.051958919968456030e-04 3.156876657158136368e-03 5.338661372661590576e-03 2.914415439590811729e-03 3.997429609298706055e-01 1.593659281730651855e+00 3.051957464776933193e-04 3.156876657158136368e-03 5.338661372661590576e-03 2.914415439590811729e-03 3.997429013252258301e-01
1.000000000000000000e+03 2.096664254228595460e-15 3.608264669310301542e-04 3.608264669310301542e-04 3.608264669310301542e-04 3.608265251386910677e-04 2.753378152847290039e-01 1.222485700959807711e-15 3.608264669310301542e-04 3.608264669310301542e-04 3.608264669310301542e-04 3.608265251386910677e-04 2.753378152847290039e-01
2.000000000000000000e+03 2.117060595840242199e-15 3.608254191931337118e-04 3.608254191931337118e-04 3.608254191931337118e-04 3.608254191931337118e-04 2.753378152847290039e-01 1.234368514418601476e-15 3.608254191931337118e-04 3.608254191931337118e-04 3.608254191931337118e-04 3.608254191931337118e-04 2.753378152847290039e-01
3.000000000000000000e+03 2.176350149290964646e-15 3.608003898989409208e-04 3.608003898989409208e-04 3.608003898989409208e-04 3.608003898989409208e-04 2.753379344940185547e-01 1.268917823666801913e-15 3.608003898989409208e-04 3.608003898989409208e-04 3.608003898989409208e-04 3.608003898989409208e-04 2.753379344940185547e-01
4.000000000000000000e+03 3.329726961479886026e-15 3.609161649364978075e-04 3.609161649364978075e-04 3.609161649364978075e-04 3.609162231441587210e-04 2.753374576568603516e-01 1.941350175437678814e-15 3.609161649364978075e-04 3.609161649364978075e-04 3.609161649364978075e-04 3.609162231441587210e-04 2.753374576568603516e-01
5.000000000000000000e+03 2.088513722045288318e-14 7.162826601415872574e-03 7.162826601415872574e-03 7.162826601415872574e-03 7.162826601415872574e-03 6.961989402770996094e-01 1.217541167306034414e-14 7.162826601415872574e-03 7.162826601415872574e-03 7.162826601415872574e-03 7.162826601415872574e-03 6.961989402770996094e-01
6.000000000000000000e+03 2.967425135434330515e-15 1.522750681033357978e-04 1.522751554148271680e-04 1.522751845186576247e-04 1.522751845186576247e-04 3.782903552055358887e-01 1.729696017797497602e-15 1.522750681033357978e-04 1.522751554148271680e-04 1.522751845186576247e-04 1.522751845186576247e-04 3.782903552055358887e-01
7.000000000000000000e+03 2.715314884288271002e-15 3.653195453807711601e-04 3.653195453807711601e-04 3.653195453807711601e-04 3.653195453807711601e-04 2.753213047981262207e-01 1.582599323265250144e-15 3.653195453807711601e-04 3.653195453807711601e-04 3.653195453807711601e-04 3.653195453807711601e-04 2.753213047981262207e-01
8.000000000000000000e+03 4.274695763919859892e-15 2.996661642100661993e-04 2.996661642100661993e-04 2.996661642100661993e-04 2.996661933138966560e-04 2.758775949478149414e-01 2.490986678537442101e-15 2.996661642100661993e-04 2.996661642100661993e-04 2.996661642100661993e-04 2.996661933138966560e-04 2.758775949478149414e-01
9.000000000000000000e+03 9.943263651885476083e-16 1.669741468504071236e-03 1.669741468504071236e-03 1.669741468504071236e-03 1.669741468504071236e-03 3.198316991329193115e-01 5.792433751007348801e-16 1.669741468504071236e-03 1.669741468504071236e-03 1.669741468504071236e-03 1.669741468504071236e-03 3.198316991329193115e-01
1.000000000000000000e+04 1.878099218299237455e-14 1.213063951581716537e-02 1.213063951581716537e-02 1.213063951581716537e-02 1.213063951581716537e-02 1.092206001281738281e+00 1.093809050766673258e-14 1.213063951581716537e-02 1.213063951581716537e-02 1.213063951581716537e-02 1.213063951581716537e-02 1.092206001281738281e+00
