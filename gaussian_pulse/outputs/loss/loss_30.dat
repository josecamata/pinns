# learning_rate: 0.05
# num_dense_layers: 8
# num_dense_nodes: 60
# activation:sigmoid 
# batch_size: 32
# final loss: 0.2767811119556427
# Training Time: 166.27745699882507
# Best Step: 1000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 5.353332888091699715e-09 9.335789218312129378e-05 9.330696047982200980e-05 9.323107224190607667e-05 9.328992746304720640e-05 3.618229627609252930e-01 5.353332888091699715e-09 9.335789218312129378e-05 9.330696047982200980e-05 9.323107224190607667e-05 9.328992746304720640e-05 3.618229627609252930e-01
1.000000000000000000e+03 9.761877285248831649e-22 3.608257102314382792e-04 3.608257102314382792e-04 3.608257102314382792e-04 3.608257684390991926e-04 2.753378152847290039e-01 9.761877285248831649e-22 3.608257102314382792e-04 3.608257102314382792e-04 3.608257102314382792e-04 3.608257684390991926e-04 2.753378152847290039e-01
2.000000000000000000e+03 9.768445656690063882e-22 3.608256811276078224e-04 3.608256811276078224e-04 3.608256811276078224e-04 3.608256811276078224e-04 2.753378152847290039e-01 9.768445656690063882e-22 3.608256811276078224e-04 3.608256811276078224e-04 3.608256811276078224e-04 3.608256811276078224e-04 2.753378152847290039e-01
3.000000000000000000e+03 9.781074499367310851e-22 3.608268452808260918e-04 3.608268452808260918e-04 3.608268452808260918e-04 3.608268743846565485e-04 2.753378152847290039e-01 9.781074499367310851e-22 3.608268452808260918e-04 3.608268452808260918e-04 3.608268452808260918e-04 3.608268743846565485e-04 2.753378152847290039e-01
4.000000000000000000e+03 8.222454987299650250e-22 3.609172417782247066e-04 3.609172417782247066e-04 3.609172417782247066e-04 3.609172708820551634e-04 2.753374576568603516e-01 8.222454987299650250e-22 3.609172417782247066e-04 3.609172417782247066e-04 3.609172417782247066e-04 3.609172708820551634e-04 2.753374576568603516e-01
5.000000000000000000e+03 7.124945247826079213e-22 3.608188417274504900e-04 3.608188417274504900e-04 3.608188417274504900e-04 3.608188708312809467e-04 2.753378450870513916e-01 7.124945247826079213e-22 3.608188417274504900e-04 3.608188417274504900e-04 3.608188417274504900e-04 3.608188708312809467e-04 2.753378450870513916e-01
6.000000000000000000e+03 5.344113337524011909e-22 3.609573468565940857e-04 3.609573468565940857e-04 3.609573468565940857e-04 3.609574050642549992e-04 2.753372788429260254e-01 5.344113337524011909e-22 3.609573468565940857e-04 3.609573468565940857e-04 3.609573468565940857e-04 3.609574050642549992e-04 2.753372788429260254e-01
7.000000000000000000e+03 4.549460047557015676e-22 3.608244005590677261e-04 3.608244005590677261e-04 3.608244005590677261e-04 3.608244587667286396e-04 2.753378152847290039e-01 4.549460047557015676e-22 3.608244005590677261e-04 3.608244005590677261e-04 3.608244005590677261e-04 3.608244587667286396e-04 2.753378152847290039e-01
8.000000000000000000e+03 2.967121949315383540e-22 3.604668308980762959e-04 3.604668308980762959e-04 3.604668308980762959e-04 3.604668600019067526e-04 2.753393054008483887e-01 2.967121949315383540e-22 3.604668308980762959e-04 3.604668308980762959e-04 3.604668308980762959e-04 3.604668600019067526e-04 2.753393054008483887e-01
9.000000000000000000e+03 2.277027439170001095e-22 3.608256229199469090e-04 3.608256229199469090e-04 3.608256229199469090e-04 3.608256520237773657e-04 2.753378152847290039e-01 2.277027439170001095e-22 3.608256229199469090e-04 3.608256229199469090e-04 3.608256229199469090e-04 3.608256520237773657e-04 2.753378152847290039e-01
1.000000000000000000e+04 1.694064026485977115e-22 3.608261176850646734e-04 3.608261176850646734e-04 3.608261176850646734e-04 3.608261176850646734e-04 2.753378152847290039e-01 1.694064026485977115e-22 3.608261176850646734e-04 3.608261176850646734e-04 3.608261176850646734e-04 3.608261176850646734e-04 2.753378152847290039e-01
