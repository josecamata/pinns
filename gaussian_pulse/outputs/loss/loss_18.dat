# learning_rate: 0.000483981354748045
# num_dense_layers: 1
# num_dense_nodes: 18
# activation:tanh 
# batch_size: 32
# final loss: 0.19864614307880402
# Training Time: 40.7584285736084
# Best Step: 10000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 5.641650009155273438e+01 1.063376665115356445e-01 2.694789133965969086e-02 2.354188263416290283e-02 1.958175003528594971e-01 4.953731536865234375e+00 3.888251495361328125e+01 1.063376665115356445e-01 2.694789133965969086e-02 2.354188263416290283e-02 1.958175003528594971e-01 4.953731536865234375e+00
1.000000000000000000e+03 2.105906903743743896e-01 9.579450124874711037e-04 6.946888170205056667e-04 9.705635602585971355e-04 1.268328982405364513e-03 2.906197905540466309e-01 1.928861588239669800e-01 9.579450706951320171e-04 6.946884677745401859e-04 9.705635020509362221e-04 1.268328982405364513e-03 2.906197607517242432e-01
2.000000000000000000e+03 6.288921833038330078e-02 8.987795445136725903e-04 5.556251271627843380e-04 9.204405359923839569e-04 1.278956420719623566e-03 2.661065459251403809e-01 4.930246993899345398e-02 8.987794863060116768e-04 5.556251271627843380e-04 9.204405359923839569e-04 1.278956420719623566e-03 2.661065459251403809e-01
3.000000000000000000e+03 3.535771742463111877e-02 5.933670327067375183e-04 3.301430260762572289e-04 6.314176716841757298e-04 9.022617014124989510e-04 2.455068826675415039e-01 2.706345357000827789e-02 5.933665088377892971e-04 3.301428805571049452e-04 6.314174970611929893e-04 9.022617596201598644e-04 2.455068826675415039e-01
4.000000000000000000e+03 2.376997284591197968e-02 3.646669792942702770e-04 2.124428719980642200e-04 4.330667143221944571e-04 5.931838531978428364e-04 2.321891635656356812e-01 1.695838570594787598e-02 3.646672994364053011e-04 2.124430175172165036e-04 4.330670635681599379e-04 5.931840278208255768e-04 2.321891635656356812e-01
5.000000000000000000e+03 1.853920891880989075e-02 2.602919121272861958e-04 1.447534596081823111e-04 2.824091061484068632e-04 4.087470006197690964e-04 2.263873964548110962e-01 1.255668606609106064e-02 2.602920867502689362e-04 1.447535323677584529e-04 2.824092807713896036e-04 4.087470879312604666e-04 2.263874411582946777e-01
6.000000000000000000e+03 1.691803894937038422e-02 1.946105912793427706e-04 1.038009795593097806e-04 2.072544739348813891e-04 3.071777464356273413e-04 2.193962037563323975e-01 1.208077557384967804e-02 1.946108095580711961e-04 1.038009795593097806e-04 2.072545757982879877e-04 3.071778628509491682e-04 2.193962633609771729e-01
7.000000000000000000e+03 1.840228587388992310e-02 1.497748162364587188e-04 8.864734991220757365e-05 1.574402995174750686e-04 2.129335480276495218e-04 2.097819447517395020e-01 1.459031645208597183e-02 1.497747725807130337e-04 8.864734991220757365e-05 1.574402849655598402e-04 2.129335043719038367e-04 2.097819596529006958e-01
8.000000000000000000e+03 1.919053681194782257e-02 1.225985033670440316e-04 1.010082414723001420e-04 1.289122010348364711e-04 1.332912361249327660e-04 2.021442949771881104e-01 1.576260663568973541e-02 1.225985324708744884e-04 1.010081759886816144e-04 1.289121137233451009e-04 1.332912070211023092e-04 2.021443098783493042e-01
9.000000000000000000e+03 1.821101084351539612e-02 1.401306217303499579e-04 1.334754924755543470e-04 1.343822368653491139e-04 9.924095502356067300e-05 1.935126185417175293e-01 1.558062899857759476e-02 1.401307090418413281e-04 1.334754924755543470e-04 1.343822659691795707e-04 9.924096957547590137e-05 1.935125887393951416e-01
1.000000000000000000e+04 1.698173210024833679e-02 2.218257141066715121e-04 1.936665939865633845e-04 1.391421537846326828e-04 1.329638907918706536e-04 1.819932460784912109e-01 1.596529781818389893e-02 2.218257432105019689e-04 1.936664193635806441e-04 1.391421537846326828e-04 1.329638907918706536e-04 1.819932460784912109e-01
