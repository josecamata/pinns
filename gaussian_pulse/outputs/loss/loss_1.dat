# learning_rate: 0.005047165763123033
# num_dense_layers: 7
# num_dense_nodes: 57
# activation:sigmoid 
# batch_size: 32
# final loss: 0.04828821122646332
# Training Time: 102.53258895874023
# Best Step: 8000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 3.494714206908611231e-08 2.410306828096508980e-03 2.410068875178694725e-03 2.411388326436281204e-03 2.411533379927277565e-03 3.613594472408294678e-01 3.153768446395588398e-08 2.410306828096508980e-03 2.410068642348051071e-03 2.411388326436281204e-03 2.411533612757921219e-03 3.613594472408294678e-01
1.000000000000000000e+03 3.283199667930603027e-02 3.511266913847066462e-05 3.214539538021199405e-05 3.951492180931381881e-05 3.983634087489917874e-05 3.136716783046722412e-02 6.033196672797203064e-02 3.511266913847066462e-05 3.214539901819080114e-05 3.951492908527143300e-05 3.983632268500514328e-05 3.136716783046722412e-02
2.000000000000000000e+03 3.962336853146553040e-02 5.204228364164009690e-05 7.389246457023546100e-05 8.701663318788632751e-05 7.507552800234407187e-05 8.678639307618141174e-03 7.821244001388549805e-02 5.204228364164009690e-05 7.389243546640500426e-05 8.701663318788632751e-05 7.507552800234407187e-05 8.678657002747058868e-03
3.000000000000000000e+03 2.965270541608333588e-02 2.189148835896048695e-05 5.323542791302315891e-05 5.332950604497455060e-05 3.206909968866966665e-05 1.301321759819984436e-02 5.887011811137199402e-02 2.189148472098167986e-05 5.323549339664168656e-05 5.332951695891097188e-05 3.206910332664847374e-05 1.301322039216756821e-02
4.000000000000000000e+03 3.367347270250320435e-02 3.630610081017948687e-05 9.085959754884243011e-05 7.832657865947112441e-05 4.502643059822730720e-05 4.237684886902570724e-03 7.082968950271606445e-02 3.630610081017948687e-05 9.085960482480004430e-05 7.832657865947112441e-05 4.502641604631207883e-05 4.237690474838018417e-03
5.000000000000000000e+03 3.706984966993331909e-02 3.556014416972175241e-05 1.300774601986631751e-04 8.753317524679005146e-05 3.738636223715730011e-05 3.394725732505321503e-03 8.173791319131851196e-02 3.556014416972175241e-05 1.300774893024936318e-04 8.753316069487482309e-05 3.738638406503014266e-05 3.394725266844034195e-03
6.000000000000000000e+03 2.358759939670562744e-02 1.675515886745415628e-05 5.933560532866977155e-05 4.558053842629306018e-05 1.759694168868009001e-05 3.956628497689962387e-03 5.518167093396186829e-02 1.675516250543296337e-05 5.933556894888170063e-05 4.558052387437783182e-05 1.759694714564830065e-05 3.956621978431940079e-03
7.000000000000000000e+03 2.764734067022800446e-02 1.929377867782022804e-05 4.784329576068557799e-05 5.424622213467955589e-05 2.050396324193570763e-05 5.509268958121538162e-03 5.611723661422729492e-02 1.929380050569307059e-05 4.784327393281273544e-05 5.424622941063717008e-05 2.050397233688272536e-05 5.509261973202228546e-03
8.000000000000000000e+03 1.778117194771766663e-02 1.212475763168185949e-05 4.726070619653910398e-05 3.072409526794217527e-05 9.265088010579347610e-06 7.724913768470287323e-03 4.046393185853958130e-02 1.212476036016596481e-05 4.726073166239075363e-05 3.072409526794217527e-05 9.265088010579347610e-06 7.724906317889690399e-03
9.000000000000000000e+03 3.366556391119956970e-02 4.182663906249217689e-05 8.424046245636418462e-05 5.367811536416411400e-05 2.953423245344310999e-05 6.431663408875465393e-03 6.754166632890701294e-02 4.182663542451336980e-05 8.424044790444895625e-05 5.367812264012172818e-05 2.953423063445370644e-05 6.431679241359233856e-03
1.000000000000000000e+04 2.847845852375030518e-02 8.039742533583194017e-05 1.820137549657374620e-04 1.290064683416858315e-04 7.004944927757605910e-05 7.599135395139455795e-03 5.550611391663551331e-02 8.039742533583194017e-05 1.820137549657374620e-04 1.290064392378553748e-04 7.004943472566083074e-05 7.599133998155593872e-03
