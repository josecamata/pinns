# learning_rate: 0.0006123921945515385
# num_dense_layers: 7
# num_dense_nodes: 10
# activation:sin 
# batch_size: 32
# final loss: 0.0150165855884552
# Training Time: 103.75394129753113
# Best Step: 10000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 4.268144989013671875e+01 2.343093417584896088e-02 1.425363309681415558e-02 1.533969771116971970e-02 1.440609153360128403e-02 2.544872999191284180e+00 3.219765472412109375e+01 2.343093417584896088e-02 1.425363309681415558e-02 1.533969771116971970e-02 1.440608967095613480e-02 2.544872999191284180e+00
1.000000000000000000e+03 2.924707159399986267e-02 2.937012759502977133e-04 2.090597990900278091e-04 2.129484200850129128e-04 2.711432462092489004e-04 2.354552596807479858e-01 1.982467062771320343e-02 2.937013341579586267e-04 2.090597845381125808e-04 2.129483764292672276e-04 2.711432462092489004e-04 2.354552596807479858e-01
2.000000000000000000e+03 3.241999447345733643e-02 1.647551835048943758e-04 1.440164924133569002e-04 1.245768653461709619e-04 1.492018636781722307e-04 1.974250078201293945e-01 2.221699990332126617e-02 1.647552271606400609e-04 1.440165069652721286e-04 1.245768798980861902e-04 1.492018345743417740e-04 1.974250078201293945e-01
3.000000000000000000e+03 3.683545067906379700e-02 1.138029256253503263e-04 1.008600156637839973e-04 8.541556599084287882e-05 1.043790034600533545e-04 1.775570362806320190e-01 2.485181391239166260e-02 1.138029401772655547e-04 1.008600011118687689e-04 8.541554416297003627e-05 1.043789598043076694e-04 1.775570213794708252e-01
4.000000000000000000e+03 4.331250861287117004e-02 7.179468229878693819e-05 5.895434878766536713e-05 5.639623850584030151e-05 7.342588651226833463e-05 1.457607150077819824e-01 4.168814793229103088e-02 7.179463864304125309e-05 5.895432695979252458e-05 5.639624578179791570e-05 7.342587923631072044e-05 1.457607150077819824e-01
5.000000000000000000e+03 5.575829371809959412e-02 4.608097879099659622e-05 4.416839510668069124e-05 3.661869777715764940e-05 4.907090260530821979e-05 3.693926706910133362e-02 1.060293838381767273e-01 4.608097879099659622e-05 4.416844967636279762e-05 3.661871232907287776e-05 4.907090260530821979e-05 3.693925961852073669e-02
6.000000000000000000e+03 4.471718892455101013e-02 4.599418389261700213e-05 3.229339563404209912e-05 4.550889207166619599e-05 5.445860006147995591e-05 1.387189514935016632e-02 9.069789946079254150e-02 4.599419480655342340e-05 3.229345020372420549e-05 4.550894664134830236e-05 5.445860369945876300e-05 1.387190539389848709e-02
7.000000000000000000e+03 3.805576264858245850e-02 5.666932702297344804e-05 3.444858521106652915e-05 5.199906809139065444e-05 7.213892240542918444e-05 9.185557253658771515e-03 7.763984054327011108e-02 5.666927245329134166e-05 3.444851972744800150e-05 5.199910447117872536e-05 7.213891512947157025e-05 9.185550734400749207e-03
8.000000000000000000e+03 3.472008928656578064e-02 6.159175245556980371e-05 3.674325853353366256e-05 5.823152605444192886e-05 8.104220614768564701e-05 7.245918735861778259e-03 7.180016487836837769e-02 6.159170152386650443e-05 3.674321123980917037e-05 5.823149695061147213e-05 8.104216976789757609e-05 7.245915476232767105e-03
9.000000000000000000e+03 3.049877472221851349e-02 5.431801037047989666e-05 4.174526839051395655e-05 6.093806587159633636e-05 6.563630449818447232e-05 5.795473232865333557e-03 6.438194215297698975e-02 5.431802856037393212e-05 4.174526839051395655e-05 6.093807678553275764e-05 6.563636998180299997e-05 5.795475095510482788e-03
1.000000000000000000e+04 5.034434143453836441e-03 3.974133051087846979e-06 3.217113089704071172e-06 4.774727131007239223e-06 3.708441681737895124e-06 1.119781518355011940e-03 1.388113014400005341e-02 3.974145784013671800e-06 3.217129915356053971e-06 4.774730314238695428e-06 3.708443500727298670e-06 1.119781285524368286e-03
