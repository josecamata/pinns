# learning_rate: 0.0005
# num_dense_layers: 7
# num_dense_nodes: 60
# activation:tanh 
# batch_size: 32
# final loss: 0.002465448807924986
# Training Time: 142.46751832962036
# Best Step: 10000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 2.962637424468994141e+00 6.611070036888122559e-02 4.366678744554519653e-02 1.222228910773992538e-02 4.133031889796257019e-02 4.500114440917968750e+00 2.962637424468994141e+00 6.611070036888122559e-02 4.366678744554519653e-02 1.222228910773992538e-02 4.133031889796257019e-02 4.500114440917968750e+00
1.000000000000000000e+03 2.952078916132450104e-02 1.351292448816820979e-04 1.304708712268620729e-04 9.979638707591220737e-05 9.504344052402302623e-05 1.010189950466156006e-01 2.952078916132450104e-02 1.351292448816820979e-04 1.304708712268620729e-04 9.979638707591220737e-05 9.504344052402302623e-05 1.010189950466156006e-01
2.000000000000000000e+03 3.561040386557579041e-02 4.948332934873178601e-05 1.030048515531234443e-04 7.131464371923357248e-05 4.710325083578936756e-05 1.749239303171634674e-02 3.561040386557579041e-02 4.948332934873178601e-05 1.030048515531234443e-04 7.131464371923357248e-05 4.710325083578936756e-05 1.749239303171634674e-02
3.000000000000000000e+03 3.097247704863548279e-02 3.048131475225090981e-05 8.597892883699387312e-05 6.469787331297993660e-05 3.473185279290191829e-05 8.489585481584072113e-03 3.097247704863548279e-02 3.048131475225090981e-05 8.597892883699387312e-05 6.469787331297993660e-05 3.473185279290191829e-05 8.489585481584072113e-03
4.000000000000000000e+03 2.660745568573474884e-02 2.271499215567018837e-05 7.254659431055188179e-05 5.247055742074735463e-05 2.494520231266506016e-05 5.608048290014266968e-03 2.660745568573474884e-02 2.271499215567018837e-05 7.254659431055188179e-05 5.247055742074735463e-05 2.494520231266506016e-05 5.608048290014266968e-03
5.000000000000000000e+03 2.147420682013034821e-02 2.594528268673457205e-05 5.859243901795707643e-05 4.997760333935730159e-05 2.423070691293105483e-05 4.090032540261745453e-03 2.147420682013034821e-02 2.594528268673457205e-05 5.859243901795707643e-05 4.997760333935730159e-05 2.423070691293105483e-05 4.090032540261745453e-03
6.000000000000000000e+03 1.628872193396091461e-02 2.734313420660328120e-05 4.316061313147656620e-05 5.076177694718353450e-05 2.160298390663228929e-05 2.845144132152199745e-03 1.628872193396091461e-02 2.734313420660328120e-05 4.316061313147656620e-05 5.076177694718353450e-05 2.160298390663228929e-05 2.845144132152199745e-03
7.000000000000000000e+03 1.055571530014276505e-02 2.845966082531958818e-05 3.633026426541619003e-05 4.570871169562451541e-05 1.446246005798457190e-05 1.722875516861677170e-03 1.055571530014276505e-02 2.845966082531958818e-05 3.633026426541619003e-05 4.570871169562451541e-05 1.446246005798457190e-05 1.722875516861677170e-03
8.000000000000000000e+03 1.543150003999471664e-02 4.916765828966163099e-05 7.624108548043295741e-05 4.356554927653633058e-05 1.452368633181322366e-05 2.169135026633739471e-03 1.543150003999471664e-02 4.916765828966163099e-05 7.624108548043295741e-05 4.356554927653633058e-05 1.452368633181322366e-05 2.169135026633739471e-03
9.000000000000000000e+03 5.948837380856275558e-03 3.465081317699514329e-05 5.132871592650189996e-05 4.391567563288845122e-05 1.447183331038104370e-05 8.086581947281956673e-04 5.948837380856275558e-03 3.465081317699514329e-05 5.132871592650189996e-05 4.391567563288845122e-05 1.447183331038104370e-05 8.086581947281956673e-04
1.000000000000000000e+04 2.035675104707479477e-03 2.916893026849720627e-05 4.450140477274544537e-05 3.381258648005314171e-05 9.701597264211159199e-06 3.125892253592610359e-04 2.035675104707479477e-03 2.916893026849720627e-05 4.450140477274544537e-05 3.381258648005314171e-05 9.701597264211159199e-06 3.125892253592610359e-04
