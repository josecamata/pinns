# learning_rate: 0.0001
# num_dense_layers: 10
# num_dense_nodes: 10
# activation:sigmoid 
# batch_size: 32
# final loss: 0.2580324113368988
# Training Time: 138.71346735954285
# Best Step: 10000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 2.165821992236582894e-12 7.822459936141967773e-02 7.822459191083908081e-02 7.822459191083908081e-02 7.822462171316146851e-02 9.241821289062500000e+00 7.786859265029866251e-13 7.822459936141967773e-02 7.822459191083908081e-02 7.822459191083908081e-02 7.822462171316146851e-02 9.241821289062500000e+00
1.000000000000000000e+03 2.498024139971355417e-12 1.346522010862827301e-03 1.346516655758023262e-03 1.346520148217678070e-03 1.346526201814413071e-03 5.939422845840454102e-01 2.330051733154259175e-12 1.346522127278149128e-03 1.346516422927379608e-03 1.346520031802356243e-03 1.346526318229734898e-03 5.939422845840454102e-01
2.000000000000000000e+03 2.399491542959264478e-11 2.963119186460971832e-04 2.963104343507438898e-04 2.962995204143226147e-04 2.963016158901154995e-04 2.759256064891815186e-01 1.897747584078679495e-11 2.963119186460971832e-04 2.963104052469134331e-04 2.962995204143226147e-04 2.963015867862850428e-04 2.759256064891815186e-01
3.000000000000000000e+03 1.118076742301354898e-10 3.606944519560784101e-04 3.606835089158266783e-04 3.606617974583059549e-04 3.606736136134713888e-04 2.753373384475708008e-01 9.232219155830279078e-11 3.606944519560784101e-04 3.606834507081657648e-04 3.606617392506450415e-04 3.606735845096409321e-04 2.753373384475708008e-01
4.000000000000000000e+03 6.192543700045405330e-10 3.608215774875134230e-04 3.607832768466323614e-04 3.607503313105553389e-04 3.607884573284536600e-04 2.753351926803588867e-01 4.421095989304291152e-10 3.608215774875134230e-04 3.607833350542932749e-04 3.607503313105553389e-04 3.607884573284536600e-04 2.753351926803588867e-01
5.000000000000000000e+03 5.807947456304418665e-09 3.608767583500593901e-04 3.607368271332234144e-04 3.606882528401911259e-04 3.608149418141692877e-04 2.753292620182037354e-01 3.645485913139623335e-09 3.608767583500593901e-04 3.607368271332234144e-04 3.606881655286997557e-04 3.608149418141692877e-04 2.753292620182037354e-01
6.000000000000000000e+03 8.418346197913706419e-08 3.609776904340833426e-04 3.604787343647330999e-04 3.603942168410867453e-04 3.608253609854727983e-04 2.753066718578338623e-01 4.769102446289252839e-08 3.609776613302528858e-04 3.604787343647330999e-04 3.603942168410867453e-04 3.608253609854727983e-04 2.753067016601562500e-01
7.000000000000000000e+03 2.676963731573778205e-06 3.614498127717524767e-04 3.591607091948390007e-04 3.589858242776244879e-04 3.609174164012074471e-04 2.751769423484802246e-01 1.327289623986871447e-06 3.614498127717524767e-04 3.591607965063303709e-04 3.589858242776244879e-04 3.609174455050379038e-04 2.751769423484802246e-01
8.000000000000000000e+03 1.943467214005067945e-04 3.603314398787915707e-04 3.475037810858339071e-04 3.466593625489622355e-04 3.573450085241347551e-04 2.738777101039886475e-01 7.033077417872846127e-05 3.603313816711306572e-04 3.475037810858339071e-04 3.466593334451317787e-04 3.573450376279652119e-04 2.738777101039886475e-01
9.000000000000000000e+03 3.394871251657605171e-03 3.306956205051392317e-04 2.979622804559767246e-04 2.902994747273623943e-04 3.011798544321209192e-04 2.641976475715637207e-01 1.155287260189652443e-03 3.306956205051392317e-04 2.979622222483158112e-04 2.902994747273623943e-04 3.011798544321209192e-04 2.641976475715637207e-01
1.000000000000000000e+04 1.005597785115242004e-02 3.213773889001458883e-04 2.617739082779735327e-04 2.390876179561018944e-04 2.501517010387033224e-04 2.532773315906524658e-01 3.682676935568451881e-03 3.213773597963154316e-04 2.617739082779735327e-04 2.390876034041866660e-04 2.501517010387033224e-04 2.532773315906524658e-01
