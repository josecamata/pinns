# learning_rate: 0.009147858057700764
# num_dense_layers: 1
# num_dense_nodes: 120
# activation:sin 
# batch_size: 32
# final loss: 0.13828282058238983
# Training Time: 40.2669403553009
# Best Step: 10000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 2.525209808349609375e+01 1.089654564857482910e-01 1.068783178925514221e-01 1.333215041086077690e-03 2.605809271335601807e-02 7.263217449188232422e+00 1.654407119750976562e+01 1.089654564857482910e-01 1.068783178925514221e-01 1.333215041086077690e-03 2.605809271335601807e-02 7.263217449188232422e+00
1.000000000000000000e+03 1.675148457288742065e-01 3.055548004340380430e-04 6.023684400133788586e-04 7.536939228884875774e-04 2.861396060325205326e-04 2.331868410110473633e-01 1.028535217046737671e-01 3.055548004340380430e-04 6.023684400133788586e-04 7.536939228884875774e-04 2.861396060325205326e-04 2.331868410110473633e-01
2.000000000000000000e+03 1.698191836476325989e-02 2.871072792913764715e-04 2.375247713644057512e-04 1.978606451302766800e-04 2.540700952522456646e-04 1.966138780117034912e-01 1.431055739521980286e-02 2.871072792913764715e-04 2.375247713644057512e-04 1.978606451302766800e-04 2.540700952522456646e-04 1.966138780117034912e-01
3.000000000000000000e+03 1.461851317435503006e-02 4.146948631387203932e-04 3.394848026800900698e-04 3.500642487779259682e-04 4.634123470168560743e-04 1.813325285911560059e-01 9.896611794829368591e-03 4.146948631387203932e-04 3.394848026800900698e-04 3.500642487779259682e-04 4.634123470168560743e-04 1.813325285911560059e-01
4.000000000000000000e+03 1.498803030699491501e-02 4.190398030914366245e-04 3.476860874798148870e-04 3.797835670411586761e-04 4.693632072303444147e-04 1.744084954261779785e-01 8.828931488096714020e-03 4.190398030914366245e-04 3.476860874798148870e-04 3.797835670411586761e-04 4.693632072303444147e-04 1.744084954261779785e-01
5.000000000000000000e+03 1.463687792420387268e-02 3.480261366348713636e-04 2.668913220986723900e-04 3.048948128707706928e-04 3.960099129471927881e-04 1.656169295310974121e-01 8.861850947141647339e-03 3.480261366348713636e-04 2.668913220986723900e-04 3.048948128707706928e-04 3.960099129471927881e-04 1.656169295310974121e-01
6.000000000000000000e+03 1.122841704636812210e-02 3.923243493773043156e-04 2.369354770053178072e-04 2.232512488262727857e-04 2.943529689218848944e-04 1.490630060434341431e-01 9.128446690738201141e-03 3.923243493773043156e-04 2.369354770053178072e-04 2.232512488262727857e-04 2.943529689218848944e-04 1.490630060434341431e-01
7.000000000000000000e+03 1.019661687314510345e-02 4.552962200250476599e-04 2.972411457449197769e-04 2.675265714060515165e-04 3.275094495620578527e-04 1.426406353712081909e-01 9.087977930903434753e-03 4.552962200250476599e-04 2.972411457449197769e-04 2.675265714060515165e-04 3.275094495620578527e-04 1.426406353712081909e-01
8.000000000000000000e+03 1.356561109423637390e-02 4.797928559128195047e-04 4.043976950924843550e-04 3.654694301076233387e-04 3.624274104367941618e-04 1.403634399175643921e-01 1.398780476301908493e-02 4.797928559128195047e-04 4.043976950924843550e-04 3.654694301076233387e-04 3.624274104367941618e-04 1.403634399175643921e-01
9.000000000000000000e+03 1.264307647943496704e-02 4.981192760169506073e-04 4.104290565010160208e-04 4.570142482407391071e-04 4.574789782054722309e-04 1.313757300376892090e-01 1.024448312819004059e-02 4.981192760169506073e-04 4.104290565010160208e-04 4.570142482407391071e-04 4.574789782054722309e-04 1.313757300376892090e-01
1.000000000000000000e+04 1.105657964944839478e-02 4.409311513882130384e-04 3.349310427438467741e-04 4.106383421458303928e-04 4.317632992751896381e-04 1.269611865282058716e-01 9.703365154564380646e-03 4.409311513882130384e-04 3.349310427438467741e-04 4.106383421458303928e-04 4.317632992751896381e-04 1.269611865282058716e-01
