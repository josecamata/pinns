# learning_rate: 0.049999999999999996
# num_dense_layers: 1
# num_dense_nodes: 120
# activation:sin 
# batch_size: 32
# final loss: 0.13602004945278168
# Training Time: 40.21501111984253
# Best Step: 7000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 2.392534179687500000e+02 1.815322190523147583e-01 1.806225627660751343e-01 4.229008257389068604e-01 2.175219058990478516e-01 1.958054733276367188e+01 1.715581207275390625e+02 1.815322190523147583e-01 1.806225627660751343e-01 4.229008257389068604e-01 2.175219058990478516e-01 1.958054733276367188e+01
1.000000000000000000e+03 1.542370580136775970e-02 4.526058328337967396e-04 3.131898411083966494e-04 4.711716028396040201e-04 6.404680898413062096e-04 1.662646830081939697e-01 1.123453769832849503e-02 4.526058328337967396e-04 3.131898411083966494e-04 4.711716028396040201e-04 6.404680898413062096e-04 1.662646830081939697e-01
2.000000000000000000e+03 1.156465243548154831e-02 2.910416806116700172e-04 2.641442406456917524e-04 2.886966394726186991e-04 2.503310970496386290e-04 1.381402313709259033e-01 8.423060178756713867e-03 2.910416806116700172e-04 2.641442406456917524e-04 2.886966394726186991e-04 2.503310970496386290e-04 1.381402313709259033e-01
3.000000000000000000e+03 1.220350712537765503e-02 2.598702267277985811e-04 2.474758366588503122e-04 2.736824681051075459e-04 2.507994067855179310e-04 1.316226869821548462e-01 9.677624329924583435e-03 2.598702267277985811e-04 2.474758366588503122e-04 2.736824681051075459e-04 2.507994067855179310e-04 1.316226869821548462e-01
4.000000000000000000e+03 4.535604268312454224e-02 2.826502313837409019e-04 2.290357224410399795e-04 2.564495371188968420e-04 2.751312858890742064e-04 1.251478046178817749e-01 2.910892292857170105e-02 2.826502313837409019e-04 2.290357224410399795e-04 2.564495371188968420e-04 2.751312858890742064e-04 1.251478046178817749e-01
5.000000000000000000e+03 2.469524554908275604e-02 2.358364145038649440e-04 1.993366604438051581e-04 2.477398957125842571e-04 2.340175997233018279e-04 1.267782002687454224e-01 1.734996028244495392e-02 2.358364145038649440e-04 1.993366604438051581e-04 2.477398957125842571e-04 2.340175997233018279e-04 1.267782002687454224e-01
6.000000000000000000e+03 6.918360292911529541e-02 2.331884170416742563e-04 2.232682745670899749e-04 2.647328365128487349e-04 2.854881749954074621e-04 1.255590617656707764e-01 4.770755767822265625e-02 2.331884170416742563e-04 2.232682745670899749e-04 2.647328365128487349e-04 2.854881749954074621e-04 1.255590617656707764e-01
7.000000000000000000e+03 1.361799333244562149e-02 1.773693220457062125e-04 1.636060042073950171e-04 2.430903550703078508e-04 2.413514303043484688e-04 1.254207044839859009e-01 9.773934260010719299e-03 1.773693220457062125e-04 1.636060042073950171e-04 2.430903550703078508e-04 2.413514303043484688e-04 1.254207044839859009e-01
8.000000000000000000e+03 2.220473997294902802e-02 1.881847128970548511e-04 1.755655976012349129e-04 2.349912247154861689e-04 2.502287679817527533e-04 1.253643035888671875e-01 1.800127886235713959e-02 1.881847128970548511e-04 1.755655976012349129e-04 2.349912247154861689e-04 2.502287679817527533e-04 1.253643035888671875e-01
9.000000000000000000e+03 3.549962863326072693e-02 2.846648858394473791e-04 4.442441859282553196e-04 6.993057904765009880e-04 5.282256752252578735e-04 1.561798751354217529e-01 4.142000526189804077e-02 2.846648858394473791e-04 4.442441859282553196e-04 6.993057904765009880e-04 5.282256752252578735e-04 1.561798751354217529e-01
1.000000000000000000e+04 3.051403909921646118e-02 3.889155341312289238e-04 6.819296395406126976e-04 8.431648020632565022e-04 5.439491360448300838e-04 1.424173861742019653e-01 3.551169857382774353e-02 3.889155341312289238e-04 6.819296395406126976e-04 8.431648020632565022e-04 5.439491360448300838e-04 1.424173861742019653e-01
