# learning_rate: 0.00025727412750822223
# num_dense_layers: 10
# num_dense_nodes: 10
# activation:sin 
# batch_size: 32
# final loss: 0.006110970862209797
# Training Time: 134.19761490821838
# Best Step: 9000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 3.083362340927124023e+00 6.252768216654658318e-04 2.323981607332825661e-03 7.040396449156105518e-04 5.117318942211568356e-04 4.309107363224029541e-01 3.041857957839965820e+00 6.252768216654658318e-04 2.323981607332825661e-03 7.040395867079496384e-04 5.117318942211568356e-04 4.309107363224029541e-01
1.000000000000000000e+03 1.593782939016819000e-02 3.174659505020827055e-04 3.356948727741837502e-04 3.471541276667267084e-04 3.265204431954771280e-04 2.371003031730651855e-01 1.038939878344535828e-02 3.174658631905913353e-04 3.356948436703532934e-04 3.471541567705571651e-04 3.265203849878162146e-04 2.371003478765487671e-01
2.000000000000000000e+03 4.078992083668708801e-02 1.286273618461564183e-04 1.194498618133366108e-04 1.344158081337809563e-04 1.577121147420257330e-04 1.598399281501770020e-01 3.930620849132537842e-02 1.286273763980716467e-04 1.194498545373789966e-04 1.344159099971875548e-04 1.577121438458561897e-04 1.598399281501770020e-01
3.000000000000000000e+03 5.686585605144500732e-02 2.993078487634193152e-05 2.630307608342263848e-05 3.035341615031939000e-05 2.960272649943362921e-05 4.247210547327995300e-02 1.029388979077339172e-01 2.993077214341610670e-05 2.630307244544383138e-05 3.035341615031939000e-05 2.960269011964555830e-05 4.247210547327995300e-02
4.000000000000000000e+03 4.387735202908515930e-02 1.641442941036075354e-05 1.329189581156242639e-05 1.080532638297881931e-05 1.486300516262417659e-05 1.463006623089313507e-02 8.848087489604949951e-02 1.641442031541373581e-05 1.329187489318428561e-05 1.080533456843113527e-05 1.486300152464536950e-05 1.463005878031253815e-02
5.000000000000000000e+03 1.522910874336957932e-02 3.303099219920113683e-06 1.310330617343424819e-06 1.525677021163573954e-06 1.622761260478000622e-06 2.750781364738941193e-03 3.340485692024230957e-02 3.303088078610016964e-06 1.310328798354021274e-06 1.525676680103060789e-06 1.622764102648943663e-06 2.750779502093791962e-03
6.000000000000000000e+03 6.135222036391496658e-03 2.452139369779615663e-06 6.191091870277887210e-07 8.749506719141209032e-07 4.637665824702708051e-07 7.953456370159983635e-04 1.437927875667810440e-02 2.452133685437729582e-06 6.191123134158260655e-07 8.749490802983928006e-07 4.637647634808672592e-07 7.953456370159983635e-04
7.000000000000000000e+03 3.711544210091233253e-03 2.384439540037419647e-06 5.043335136178939138e-07 8.778702067502308637e-07 5.439581514110614080e-07 5.048791645094752312e-04 9.571933187544345856e-03 2.384436811553314328e-06 5.043339115218259394e-07 8.778717415225401055e-07 5.439601409307215363e-07 5.048796301707625389e-04
8.000000000000000000e+03 2.760671777650713921e-03 2.294805653946241364e-06 5.143180601407948416e-07 1.002396970761765260e-06 6.607378963963128626e-07 3.854521783068776131e-04 7.342063356190919876e-03 2.294809746672399342e-06 5.143159569342969917e-07 1.002390604298852850e-06 6.607384079870826099e-07 3.854537790175527334e-04
9.000000000000000000e+03 2.224501920863986015e-03 2.195866272813873366e-06 5.312319331096659880e-07 1.078582954505691305e-06 7.376356165877950843e-07 3.215793112758547068e-04 5.965770687907934189e-03 2.195860133724636398e-06 5.312355142450542189e-07 1.078583636626717634e-06 7.376346502496744506e-07 3.215815522707998753e-04
1.000000000000000000e+04 2.401540055871009827e-03 2.208443220297340304e-06 5.981996196169347968e-07 1.247288992090034299e-06 7.982720831023470964e-07 2.660463214851915836e-04 5.840071942657232285e-03 2.208456180596840568e-06 5.982008701721497346e-07 1.247288651029521134e-06 7.982750389601278584e-07 2.660463214851915836e-04
