# learning_rate: 0.020293758525246456
# num_dense_layers: 1
# num_dense_nodes: 120
# activation:Swish 
# batch_size: 32
# final loss: 0.15423457324504852
# Training Time: 44.11627697944641
# Best Step: 9000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 2.494479942321777344e+01 7.096179574728012085e-02 2.791318297386169434e-01 1.338951438665390015e-01 1.112222392112016678e-02 3.539697647094726562e+00 1.965964508056640625e+01 7.096179574728012085e-02 2.791318297386169434e-01 1.338951438665390015e-01 1.112222392112016678e-02 3.539697647094726562e+00
1.000000000000000000e+03 1.711443997919559479e-02 2.764462551567703485e-04 1.514548348495736718e-04 1.036177200148813426e-04 2.283109788550063968e-04 1.827377080917358398e-01 1.716169342398643494e-02 2.764462551567703485e-04 1.514548348495736718e-04 1.036177200148813426e-04 2.283109788550063968e-04 1.827377080917358398e-01
2.000000000000000000e+03 2.314499951899051666e-02 3.320392861496657133e-04 1.865308586275205016e-04 8.789681305643171072e-05 2.151737717213109136e-04 1.618184000253677368e-01 2.041117101907730103e-02 3.320392861496657133e-04 1.865308586275205016e-04 8.789681305643171072e-05 2.151737717213109136e-04 1.618184000253677368e-01
3.000000000000000000e+03 1.275400519371032715e-01 3.070639795623719692e-04 2.180213778046891093e-04 1.316865673288702965e-04 2.253998100059106946e-04 1.586715728044509888e-01 5.003309249877929688e-02 3.070639795623719692e-04 2.180213778046891093e-04 1.316865673288702965e-04 2.253998100059106946e-04 1.586715728044509888e-01
4.000000000000000000e+03 2.115851454436779022e-02 1.909535640152171254e-04 1.370990794384852052e-04 9.283817053074017167e-05 1.796942378859966993e-04 1.511748731136322021e-01 2.459430508315563202e-02 1.909535640152171254e-04 1.370990794384852052e-04 9.283817053074017167e-05 1.796942378859966993e-04 1.511748731136322021e-01
5.000000000000000000e+03 2.265014685690402985e-02 2.963215520139783621e-04 1.651428610784932971e-04 1.225079176947474480e-04 2.489294565748423338e-04 1.347891241312026978e-01 2.760922163724899292e-02 2.963215520139783621e-04 1.651428610784932971e-04 1.225079176947474480e-04 2.489294565748423338e-04 1.347891241312026978e-01
6.000000000000000000e+03 2.082959748804569244e-02 2.062570129055529833e-04 1.382508344249799848e-04 1.130294040194712579e-04 2.018435916397720575e-04 1.377611160278320312e-01 2.552164904773235321e-02 2.062570129055529833e-04 1.382508344249799848e-04 1.130294040194712579e-04 2.018435916397720575e-04 1.377611160278320312e-01
7.000000000000000000e+03 2.456669509410858154e-02 3.073763800784945488e-04 1.644038711674511433e-04 1.248063199454918504e-04 2.527458709664642811e-04 1.294924467802047729e-01 2.662686258554458618e-02 3.073763800784945488e-04 1.644038711674511433e-04 1.248063199454918504e-04 2.527458709664642811e-04 1.294924467802047729e-01
8.000000000000000000e+03 2.239817194640636444e-02 2.642022445797920227e-04 1.562539837323129177e-04 1.237031392520293593e-04 2.245304931420832872e-04 1.282943934202194214e-01 2.605728246271610260e-02 2.642022445797920227e-04 1.562539837323129177e-04 1.237031392520293593e-04 2.245304931420832872e-04 1.282943934202194214e-01
9.000000000000000000e+03 2.144969254732131958e-02 2.521445276215672493e-04 1.573588233441114426e-04 1.122644898714497685e-04 2.173233369830995798e-04 1.283896118402481079e-01 2.510586567223072052e-02 2.521445276215672493e-04 1.573588233441114426e-04 1.122644898714497685e-04 2.173233369830995798e-04 1.283896118402481079e-01
1.000000000000000000e+04 4.127290844917297363e-02 2.307015238329768181e-04 1.172632546513341367e-04 1.789075759006664157e-04 2.844057744368910789e-04 1.291475892066955566e-01 3.444574400782585144e-02 2.307015238329768181e-04 1.172632546513341367e-04 1.789075759006664157e-04 2.844057744368910789e-04 1.291475892066955566e-01
