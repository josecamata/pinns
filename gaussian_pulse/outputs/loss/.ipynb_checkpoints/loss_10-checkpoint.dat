# learning_rate: 0.002278388085457619
# num_dense_layers: 8
# num_dense_nodes: 114
# activation:sin 
# batch_size: 32
# final loss: 0.0015012522926554084
# Training Time: 157.8619520664215
# Best Step: 5000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 8.210040092468261719e+00 4.050409048795700073e-02 6.032648961991071701e-03 7.034678943455219269e-03 2.687753550708293915e-02 1.163010835647583008e+00 4.392972946166992188e+00 4.050409048795700073e-02 6.032648961991071701e-03 7.034678943455219269e-03 2.687753550708293915e-02 1.163010835647583008e+00
1.000000000000000000e+03 2.127374894917011261e-02 2.382322782068513334e-05 6.703306280542165041e-05 4.437979077920317650e-05 3.052208558074198663e-05 1.884440332651138306e-01 1.472523901611566544e-02 2.382322782068513334e-05 6.703306280542165041e-05 4.437979077920317650e-05 3.052208558074198663e-05 1.884440332651138306e-01
2.000000000000000000e+03 1.540064718574285507e-02 2.723801117099355906e-05 2.726317870838101953e-05 1.716307997412513942e-05 6.919217412360012531e-06 4.100845661014318466e-03 3.399940952658653259e-02 2.723801117099355906e-05 2.726317870838101953e-05 1.716307997412513942e-05 6.919217412360012531e-06 4.100845661014318466e-03
3.000000000000000000e+03 3.532304195687174797e-03 2.665814690772094764e-06 2.473725317031494342e-06 3.540878196872654371e-06 2.060746055576601066e-06 3.436378901824355125e-04 5.827432498335838318e-03 2.665814690772094764e-06 2.473725317031494342e-06 3.540878196872654371e-06 2.060746055576601066e-06 3.436378901824355125e-04
4.000000000000000000e+03 5.712088313885033131e-04 3.177295411660452373e-06 3.879157702613156289e-06 4.234344942233292386e-06 2.062577550532296300e-06 9.214138844981789589e-05 1.491517876274883747e-03 3.177295411660452373e-06 3.879157702613156289e-06 4.234344942233292386e-06 2.062577550532296300e-06 9.214138844981789589e-05
5.000000000000000000e+03 5.447784787975251675e-04 4.671876013162545860e-06 4.899617579212645069e-06 4.760500360134756193e-06 2.736924216151237488e-06 7.887165702413767576e-05 1.405311864800751209e-03 4.671876013162545860e-06 4.899617579212645069e-06 4.760500360134756193e-06 2.736924216151237488e-06 7.887165702413767576e-05
6.000000000000000000e+03 1.224456122145056725e-03 3.986785486631561071e-06 5.625029643852030858e-06 4.760759566124761477e-06 2.071541302939294837e-06 1.426284143235534430e-04 1.819915836676955223e-03 3.986785486631561071e-06 5.625029643852030858e-06 4.760759566124761477e-06 2.071541302939294837e-06 1.426284143235534430e-04
7.000000000000000000e+03 1.012139837257564068e-03 8.664451343065593392e-06 1.007814444164978340e-05 9.042846613738220185e-06 5.464480182126862928e-06 6.070212693884968758e-04 1.600701711140573025e-03 8.664451343065593392e-06 1.007814444164978340e-05 9.042846613738220185e-06 5.464480182126862928e-06 6.070212693884968758e-04
8.000000000000000000e+03 1.846171944634988904e-04 1.621508999960497022e-05 1.749359216773882508e-05 1.702354893495794386e-05 1.186254939966602251e-05 1.660559209994971752e-03 4.291298100724816322e-04 1.621508999960497022e-05 1.749359216773882508e-05 1.702354893495794386e-05 1.186254939966602251e-05 1.660559209994971752e-03
9.000000000000000000e+03 7.482708897441625595e-04 2.608715703900088556e-06 3.660719585241167806e-06 4.257958153175422922e-06 1.740762741064827424e-06 1.020008421619422734e-04 1.440321793779730797e-03 2.608715703900088556e-06 3.660719585241167806e-06 4.257958153175422922e-06 1.740762741064827424e-06 1.020008421619422734e-04
1.000000000000000000e+04 1.148683259089011699e-05 3.604909579735249281e-04 3.603742516133934259e-04 3.605445090215653181e-04 3.604716039262712002e-04 2.753162682056427002e-01 2.121582474501337856e-05 3.604909579735249281e-04 3.603742516133934259e-04 3.605445090215653181e-04 3.604716039262712002e-04 2.753162682056427002e-01
