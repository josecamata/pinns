# learning_rate: 0.024830829756906935
# num_dense_layers: 1
# num_dense_nodes: 10
# activation:sin 
# batch_size: 32
# final loss: 0.1896691471338272
# Training Time: 40.398892641067505
# Best Step: 8000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 2.228342285156250000e+02 2.584709040820598602e-02 1.094738990068435669e-01 7.397829741239547729e-02 8.298808336257934570e-02 5.631038665771484375e+00 1.322549133300781250e+02 2.584708295762538910e-02 1.094738841056823730e-01 7.397829741239547729e-02 8.298808336257934570e-02 5.631038665771484375e+00
1.000000000000000000e+03 1.329051144421100616e-02 6.301668327068910003e-05 4.827275552088394761e-05 7.358616858255118132e-05 6.744497659383341670e-05 2.291944026947021484e-01 9.532952681183815002e-03 6.301675603026524186e-05 4.827282464248128235e-05 7.358616858255118132e-05 6.744498386979103088e-05 2.291943877935409546e-01
2.000000000000000000e+03 1.308936811983585358e-02 1.206465167342685163e-04 8.824543328955769539e-05 4.693227674579247832e-05 7.674927473999559879e-05 2.182439714670181274e-01 8.201859891414642334e-03 1.206464585266076028e-04 8.824544784147292376e-05 4.693228038377128541e-05 7.674927473999559879e-05 2.182439267635345459e-01
3.000000000000000000e+03 1.765676401555538177e-02 1.371279795421287417e-04 8.718911703908815980e-05 4.972518217982724309e-05 1.068140190909616649e-04 2.057284414768218994e-01 1.070777885615825653e-02 1.371279940940439701e-04 8.718902245163917542e-05 4.972518581780605018e-05 1.068140190909616649e-04 2.057284861803054810e-01
4.000000000000000000e+03 1.957972906529903412e-02 1.611555053386837244e-04 1.161450418294407427e-04 8.541586430510506034e-05 1.328155340161174536e-04 1.978912800550460815e-01 1.706086471676826477e-02 1.611555780982598662e-04 1.161450200015679002e-04 8.541586430510506034e-05 1.328155194642022252e-04 1.978912800550460815e-01
5.000000000000000000e+03 1.876142062246799469e-02 2.419179509161040187e-04 2.819783112499862909e-04 1.987551368074491620e-04 2.119036653311923146e-04 1.834890395402908325e-01 1.704235002398490906e-02 2.419179363641887903e-04 2.819783694576472044e-04 1.987551368074491620e-04 2.119036944350227714e-04 1.834890544414520264e-01
6.000000000000000000e+03 1.855843886733055115e-02 2.890755713451653719e-04 3.203848318662494421e-04 2.487657184246927500e-04 2.814343606587499380e-04 1.819402724504470825e-01 1.673703454434871674e-02 2.890754258260130882e-04 3.203848318662494421e-04 2.487657475285232067e-04 2.814343606587499380e-04 1.819402724504470825e-01
7.000000000000000000e+03 1.411740947514772415e-02 3.591106797102838755e-04 4.761994059663265944e-04 4.239896370563656092e-04 4.328521026764065027e-04 1.819396317005157471e-01 1.136953756213188171e-02 3.591106797102838755e-04 4.761992604471743107e-04 4.239896370563656092e-04 4.328521026764065027e-04 1.819396317005157471e-01
8.000000000000000000e+03 1.308843772858381271e-02 4.004885850008577108e-04 4.673540533985942602e-04 4.142012621741741896e-04 4.505732213146984577e-04 1.791526079177856445e-01 8.783911354839801788e-03 4.004887014161795378e-04 4.673540533985942602e-04 4.142012621741741896e-04 4.505732213146984577e-04 1.791526228189468384e-01
9.000000000000000000e+03 1.389971561729907990e-02 3.742515400517731905e-04 4.508270940277725458e-04 3.771859628614038229e-04 4.250641504768282175e-04 1.797889024019241333e-01 8.269337937235832214e-03 3.742515691556036472e-04 4.508270067162811756e-04 3.771859337575733662e-04 4.250641504768282175e-04 1.797889024019241333e-01
1.000000000000000000e+04 1.350034028291702271e-02 3.555805596988648176e-04 4.243872535880655050e-04 3.712884208653122187e-04 4.032307479064911604e-04 1.791720837354660034e-01 9.091175161302089691e-03 3.555807634256780148e-04 4.243872535880655050e-04 3.712884208653122187e-04 4.032307479064911604e-04 1.791720837354660034e-01
