# learning_rate: 0.0010044355257577005
# num_dense_layers: 8
# num_dense_nodes: 120
# activation:sigmoid 
# batch_size: 32
# final loss: 0.04640199616551399
# Training Time: 155.3693904876709
# Best Step: 10000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 4.603629033539391457e-09 3.430431708693504333e-02 3.430566564202308655e-02 3.430479392409324646e-02 3.430329635739326477e-02 4.476534843444824219e+00 3.204983167748309825e-09 3.430431708693504333e-02 3.430566564202308655e-02 3.430479392409324646e-02 3.430329635739326477e-02 4.476534843444824219e+00
1.000000000000000000e+03 3.395576402544975281e-02 2.297003629792016000e-05 3.867878695018589497e-05 3.994826329289935529e-05 3.534997085807844996e-05 2.561865746974945068e-02 6.567912548780441284e-02 2.297003629792016000e-05 3.867878695018589497e-05 3.994826329289935529e-05 3.534997085807844996e-05 2.561865746974945068e-02
2.000000000000000000e+03 2.161490172147750854e-02 8.954246368375606835e-06 4.124093175050802529e-05 3.417683183215558529e-05 1.388497094012564048e-05 3.235143423080444336e-02 4.267187789082527161e-02 8.954246368375606835e-06 4.124093175050802529e-05 3.417683183215558529e-05 1.388497094012564048e-05 3.235143423080444336e-02
3.000000000000000000e+03 2.886329963803291321e-02 5.831957241753116250e-05 1.040153802023269236e-04 1.126809293054975569e-04 7.436256419168785214e-05 4.966540727764368057e-03 6.775130331516265869e-02 5.831957241753116250e-05 1.040153802023269236e-04 1.126809293054975569e-04 7.436256419168785214e-05 4.966540727764368057e-03
4.000000000000000000e+03 1.925705000758171082e-02 5.045163106842665002e-06 1.506326680100755766e-05 1.992817306017968804e-05 9.579140169080346823e-06 1.918628998100757599e-02 4.313329234719276428e-02 5.045163106842665002e-06 1.506326680100755766e-05 1.992817306017968804e-05 9.579140169080346823e-06 1.918628998100757599e-02
5.000000000000000000e+03 2.251400798559188843e-02 1.623712341825012118e-05 4.155044371145777404e-05 4.688316403189674020e-05 2.796785520331468433e-05 4.066792782396078110e-03 5.376504734158515930e-02 1.623712341825012118e-05 4.155044371145777404e-05 4.688316403189674020e-05 2.796785520331468433e-05 4.066792782396078110e-03
6.000000000000000000e+03 2.077165059745311737e-02 2.051314004347659647e-05 4.281012297724373639e-05 4.519405410974286497e-05 2.991640394611749798e-05 2.532726619392633438e-03 5.468822270631790161e-02 2.051314004347659647e-05 4.281012297724373639e-05 4.519405410974286497e-05 2.991640394611749798e-05 2.532726619392633438e-03
7.000000000000000000e+03 1.873005181550979614e-02 2.342889638384804130e-05 3.782147541642189026e-05 4.414115392137318850e-05 3.253246177337132394e-05 2.744428347796201706e-03 4.740297421813011169e-02 2.342889638384804130e-05 3.782147541642189026e-05 4.414115392137318850e-05 3.253246177337132394e-05 2.744428347796201706e-03
8.000000000000000000e+03 1.688616722822189331e-02 6.979647423577262089e-06 1.021063599182525650e-05 1.318994600296719000e-05 1.003115539788268507e-05 2.800932619720697403e-03 4.356064647436141968e-02 6.979647423577262089e-06 1.021063599182525650e-05 1.318994600296719000e-05 1.003115539788268507e-05 2.800932619720697403e-03
9.000000000000000000e+03 1.938205398619174957e-02 2.132246845576446503e-05 5.823590981890447438e-05 3.504439882817678154e-05 1.654397783568128943e-05 2.860594075173139572e-03 4.426884278655052185e-02 2.132246845576446503e-05 5.823590981890447438e-05 3.504439882817678154e-05 1.654397783568128943e-05 2.860594075173139572e-03
1.000000000000000000e+04 1.640981622040271759e-02 1.918034286063630134e-05 3.848192500299774110e-05 3.530250614858232439e-05 2.179442344640847296e-05 2.353421878069639206e-03 4.434217512607574463e-02 1.918034286063630134e-05 3.848192500299774110e-05 3.530250614858232439e-05 2.179442344640847296e-05 2.353421878069639206e-03
