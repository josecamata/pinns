# learning_rate: 0.0038524146632357738
# num_dense_layers: 1
# num_dense_nodes: 120
# activation:Swish 
# batch_size: 32
# final loss: 0.1496661752462387
# Training Time: 44.285216331481934
# Best Step: 10000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 6.411401367187500000e+01 9.313069581985473633e-01 7.809023857116699219e-01 1.095511913299560547e-01 1.764096021652221680e-01 2.716181564331054688e+01 5.053160095214843750e+01 9.313069581985473633e-01 7.809023857116699219e-01 1.095511913299560547e-01 1.764096021652221680e-01 2.716181564331054688e+01
1.000000000000000000e+03 9.668523445725440979e-03 1.578135124873369932e-04 1.409793185302987695e-04 7.677006942685693502e-05 9.330162720289081335e-05 2.199163883924484253e-01 6.278821732848882675e-03 1.578135124873369932e-04 1.409793185302987695e-04 7.677006942685693502e-05 9.330162720289081335e-05 2.199163883924484253e-01
2.000000000000000000e+03 1.500795036554336548e-02 3.201352083124220371e-04 2.147905615856871009e-04 8.435701602138578892e-05 1.545867999084293842e-04 1.994895786046981812e-01 1.438627764582633972e-02 3.201352083124220371e-04 2.147905615856871009e-04 8.435701602138578892e-05 1.545867999084293842e-04 1.994895786046981812e-01
3.000000000000000000e+03 1.646146923303604126e-02 3.601543721742928028e-04 2.280232583871111274e-04 1.220354097313247621e-04 2.237817971035838127e-04 1.838468313217163086e-01 1.562240254133939743e-02 3.601543721742928028e-04 2.280232583871111274e-04 1.220354097313247621e-04 2.237817971035838127e-04 1.838468313217163086e-01
4.000000000000000000e+03 1.916239596903324127e-02 3.635706088971346617e-04 2.013707271544262767e-04 1.179923056042753160e-04 2.580029831733554602e-04 1.666297763586044312e-01 1.951749436557292938e-02 3.635706088971346617e-04 2.013707271544262767e-04 1.179923056042753160e-04 2.580029831733554602e-04 1.666297763586044312e-01
5.000000000000000000e+03 2.123241499066352844e-02 3.637676127254962921e-04 2.009493618970736861e-04 1.270589855266734958e-04 2.812753373291343451e-04 1.552940905094146729e-01 2.339244447648525238e-02 3.637676127254962921e-04 2.009493618970736861e-04 1.270589855266734958e-04 2.812753373291343451e-04 1.552940905094146729e-01
6.000000000000000000e+03 2.115105092525482178e-02 3.316514776088297367e-04 1.892886211862787604e-04 1.282459561480209231e-04 2.715662412811070681e-04 1.488288640975952148e-01 2.471142821013927460e-02 3.316514776088297367e-04 1.892886211862787604e-04 1.282459561480209231e-04 2.715662412811070681e-04 1.488288640975952148e-01
7.000000000000000000e+03 2.093254402279853821e-02 3.032966051250696182e-04 1.773244002833962440e-04 1.303455646848306060e-04 2.619423612486571074e-04 1.419918388128280640e-01 2.564243972301483154e-02 3.032966051250696182e-04 1.773244002833962440e-04 1.303455646848306060e-04 2.619423612486571074e-04 1.419918388128280640e-01
8.000000000000000000e+03 2.114762179553508759e-02 2.887208247557282448e-04 1.652622740948572755e-04 1.276087859878316522e-04 2.533913066145032644e-04 1.357507109642028809e-01 2.552692033350467682e-02 2.887208247557282448e-04 1.652622740948572755e-04 1.276087859878316522e-04 2.533913066145032644e-04 1.357507109642028809e-01
9.000000000000000000e+03 2.036165259778499603e-02 2.627185021992772818e-04 1.512225135229527950e-04 1.501189544796943665e-04 2.705328515730798244e-04 1.297764778137207031e-01 2.420085109770298004e-02 2.627185021992772818e-04 1.512225135229527950e-04 1.501189544796943665e-04 2.705328515730798244e-04 1.297764778137207031e-01
1.000000000000000000e+04 2.069777622818946838e-02 2.524653682485222816e-04 1.750614464981481433e-04 2.065997832687571645e-04 3.147640090901404619e-04 1.243276745080947876e-01 2.438961155712604523e-02 2.524653682485222816e-04 1.750614464981481433e-04 2.065997832687571645e-04 3.147640090901404619e-04 1.243276745080947876e-01
