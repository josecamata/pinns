# learning_rate: 0.0005
# num_dense_layers: 8
# num_dense_nodes: 60
# activation:ReLU 
# batch_size: 32
# final loss: 0.21711352467536926
# Training Time: 111.5671877861023
# Best Step: 3000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 3.446535468101501465e-01 4.221121780574321747e-03 3.074068343266844749e-03 5.205975030548870564e-04 1.264123129658401012e-03 7.455191612243652344e-01 3.446535468101501465e-01 4.221121780574321747e-03 3.074068343266844749e-03 5.205975030548870564e-04 1.264123129658401012e-03 7.455191612243652344e-01
1.000000000000000000e+03 2.884733863174915314e-02 1.575013011461123824e-04 1.372769620502367616e-04 2.132755325874313712e-04 2.180793089792132378e-04 1.904049664735794067e-01 2.884733863174915314e-02 1.575013011461123824e-04 1.372769620502367616e-04 2.132755325874313712e-04 2.180793089792132378e-04 1.904049664735794067e-01
2.000000000000000000e+03 1.954296603798866272e-02 2.418081712676212192e-04 1.535919436719268560e-04 2.140197175322100520e-04 3.012977831531316042e-04 2.186052501201629639e-01 1.954296603798866272e-02 2.418081712676212192e-04 1.535919436719268560e-04 2.140197175322100520e-04 3.012977831531316042e-04 2.186052501201629639e-01
3.000000000000000000e+03 3.310232609510421753e-02 1.830893597798421979e-04 6.481444142991676927e-05 1.384104107273742557e-04 2.444851852487772703e-04 1.833803951740264893e-01 3.310232609510421753e-02 1.830893597798421979e-04 6.481444142991676927e-05 1.384104107273742557e-04 2.444851852487772703e-04 1.833803951740264893e-01
4.000000000000000000e+03 2.880162745714187622e-02 1.522920792922377586e-04 1.141635002568364143e-04 2.023370034294202924e-04 2.494360378477722406e-04 2.130591571331024170e-01 2.880162745714187622e-02 1.522920792922377586e-04 1.141635002568364143e-04 2.023370034294202924e-04 2.494360378477722406e-04 2.130591571331024170e-01
5.000000000000000000e+03 2.626283653080463409e-02 2.007941948249936104e-04 1.043925803969614208e-04 1.915987813845276833e-04 2.971146896015852690e-04 2.062535583972930908e-01 2.626283653080463409e-02 2.007941948249936104e-04 1.043925803969614208e-04 1.915987813845276833e-04 2.971146896015852690e-04 2.062535583972930908e-01
6.000000000000000000e+03 2.232554741203784943e-02 2.460382238496094942e-04 1.360031310468912125e-04 1.892090513138100505e-04 3.241581143811345100e-04 2.182707190513610840e-01 2.232554741203784943e-02 2.460382238496094942e-04 1.360031310468912125e-04 1.892090513138100505e-04 3.241581143811345100e-04 2.182707190513610840e-01
7.000000000000000000e+03 1.705182343721389771e-02 1.733331591822206974e-04 7.135787018341943622e-05 9.096197754843160510e-05 2.308733819518238306e-04 2.289814651012420654e-01 1.705182343721389771e-02 1.733331591822206974e-04 7.135787018341943622e-05 9.096197754843160510e-05 2.308733819518238306e-04 2.289814651012420654e-01
8.000000000000000000e+03 1.643061451613903046e-02 2.088072942569851875e-04 1.242803846253082156e-04 1.242809084942564368e-04 2.863995032384991646e-04 2.342692017555236816e-01 1.643061451613903046e-02 2.088072942569851875e-04 1.242803846253082156e-04 1.242809084942564368e-04 2.863995032384991646e-04 2.342692017555236816e-01
9.000000000000000000e+03 1.976755820214748383e-02 2.006514259846881032e-04 1.325970661127939820e-04 1.029829727485775948e-04 2.430758177069947124e-04 2.259413301944732666e-01 1.976755820214748383e-02 2.006514259846881032e-04 1.325970661127939820e-04 1.029829727485775948e-04 2.430758177069947124e-04 2.259413301944732666e-01
1.000000000000000000e+04 1.465622615069150925e-02 2.680202014744281769e-04 1.666694151936098933e-04 1.849105901783332229e-04 3.537671000231057405e-04 2.403838038444519043e-01 1.465622615069150925e-02 2.680202014744281769e-04 1.666694151936098933e-04 1.849105901783332229e-04 3.537671000231057405e-04 2.403838038444519043e-01
