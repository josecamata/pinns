# learning_rate: 0.0001
# num_dense_layers: 9
# num_dense_nodes: 24
# activation:tanh 
# batch_size: 32
# final loss: 0.07945765554904938
# Training Time: 117.35612463951111
# Best Step: 10000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 2.341280746459960938e+01 9.286493994295597076e-03 1.040805224329233170e-02 2.540751360356807709e-02 1.249455194920301437e-02 1.492380499839782715e+00 1.314153480529785156e+01 9.286494925618171692e-03 1.040805224329233170e-02 2.540751360356807709e-02 1.249455194920301437e-02 1.492380499839782715e+00
1.000000000000000000e+03 1.485784910619258881e-02 4.467486578505486250e-04 2.747332036960870028e-04 3.283725527580827475e-04 4.224042058922350407e-04 2.570919394493103027e-01 1.126336026936769485e-02 4.467487742658704519e-04 2.747332036960870028e-04 3.283725527580827475e-04 4.224042058922350407e-04 2.570919394493103027e-01
2.000000000000000000e+03 9.048021398484706879e-03 4.533590399660170078e-04 2.835488994605839252e-04 2.986399340443313122e-04 3.952792030759155750e-04 2.548241913318634033e-01 5.841998849064111710e-03 4.533591272775083780e-04 2.835488994605839252e-04 2.986399340443313122e-04 3.952792030759155750e-04 2.548241615295410156e-01
3.000000000000000000e+03 8.831869810819625854e-03 4.624986613634973764e-04 2.773347077891230583e-04 2.902746200561523438e-04 4.048671980854123831e-04 2.501796185970306396e-01 5.505293142050504684e-03 4.624986613634973764e-04 2.773347077891230583e-04 2.902746200561523438e-04 4.048671980854123831e-04 2.501796483993530273e-01
4.000000000000000000e+03 1.188113540410995483e-02 4.932523588649928570e-04 2.695091825444251299e-04 3.167065442539751530e-04 4.749528307002037764e-04 2.367739677429199219e-01 7.917706854641437531e-03 4.932523588649928570e-04 2.695092989597469568e-04 3.167065151501446962e-04 4.749528307002037764e-04 2.367739677429199219e-01
5.000000000000000000e+03 1.795022934675216675e-02 3.874636313412338495e-04 2.281873021274805069e-04 3.178366168867796659e-04 4.571216122712939978e-04 2.108000367879867554e-01 1.417784113436937332e-02 3.874635440297424793e-04 2.281874039908871055e-04 3.178366168867796659e-04 4.571216122712939978e-04 2.108000367879867554e-01
6.000000000000000000e+03 3.017179295420646667e-02 1.665288436925038695e-04 1.777411089278757572e-04 2.153467212338000536e-04 2.149554202333092690e-04 1.533273011445999146e-01 3.440251573920249939e-02 1.665288436925038695e-04 1.777409779606387019e-04 2.153466921299695969e-04 2.149554202333092690e-04 1.533273011445999146e-01
7.000000000000000000e+03 4.503044858574867249e-02 4.350555173004977405e-05 7.311406807275488973e-05 1.071153019438497722e-04 7.180023385444656014e-05 4.164294153451919556e-02 7.862378656864166260e-02 4.350555536802858114e-05 7.311400258913636208e-05 1.071153019438497722e-04 7.180023385444656014e-05 4.164294153451919556e-02
8.000000000000000000e+03 3.939081728458404541e-02 2.875775680877268314e-05 5.493551725521683693e-05 5.930145925958640873e-05 3.852164081763476133e-05 1.542702503502368927e-02 7.686524838209152222e-02 2.875775135180447251e-05 5.493549542734399438e-05 5.930146653554402292e-05 3.852163717965595424e-05 1.542702317237854004e-02
9.000000000000000000e+03 3.582874312996864319e-02 3.349555481690913439e-05 5.781279105576686561e-05 5.662758121616207063e-05 3.552728230715729296e-05 1.005211751908063889e-02 7.378497719764709473e-02 3.349555481690913439e-05 5.781274740002118051e-05 5.662758485414087772e-05 3.552728230715729296e-05 1.005211938172578812e-02
1.000000000000000000e+04 3.399441391229629517e-02 3.179943450959399343e-05 5.940181654295884073e-05 5.228791997069492936e-05 3.049255792575422674e-05 8.330372162163257599e-03 7.095330208539962769e-02 3.179936902597546577e-05 5.940184928476810455e-05 5.228791269473731518e-05 3.049256156373303384e-05 8.330371230840682983e-03
