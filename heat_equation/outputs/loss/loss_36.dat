# learning_rate: 0.002296041679318042
# num_dense_layers: 7
# num_dense_nodes: 120
# activation:sin 
# batch_size: 32
# final loss: 0.4958178400993347
# Training Time: 140.716570854187
# Best Step: 6000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 1.408474147319793701e-01 5.404874038696289062e+01 2.953840047121047974e-02 1.218736797454766929e-04 1.029339991509914398e-02 2.402082784101366997e-03 1.400748789310455322e-01 5.404874038696289062e+01 2.953840047121047974e-02 1.218736797454766929e-04 1.029339991509914398e-02 2.402082784101366997e-03
1.000000000000000000e+03 5.430503934621810913e-02 1.663153469562530518e-01 3.693205118179321289e-01 1.981463128686300479e-06 2.939414680004119873e-01 2.647470533847808838e-01 5.276424810290336609e-02 1.663153469562530518e-01 3.693205118179321289e-01 1.981463128686300479e-06 2.939414680004119873e-01 2.647470533847808838e-01
2.000000000000000000e+03 7.228230684995651245e-02 9.778916090726852417e-02 4.077398777008056641e-01 2.759151720965746790e-05 2.803210020065307617e-01 2.211364656686782837e-01 1.513214688748121262e-02 9.778916090726852417e-02 4.077398777008056641e-01 2.759151720965746790e-05 2.803210020065307617e-01 2.211364656686782837e-01
3.000000000000000000e+03 6.321647018194198608e-02 1.412750184535980225e-01 2.467399239540100098e-01 1.127397013078734744e-06 1.713648289442062378e-01 1.248045861721038818e-01 9.127731435000896454e-03 1.412750184535980225e-01 2.467399239540100098e-01 1.127397013078734744e-06 1.713648289442062378e-01 1.248045861721038818e-01
4.000000000000000000e+03 5.884697288274765015e-02 6.832807511091232300e-02 2.091459631919860840e-01 2.165448495361488312e-05 2.062241584062576294e-01 1.320948004722595215e-01 1.859600841999053955e-02 6.832807511091232300e-02 2.091459631919860840e-01 2.165448495361488312e-05 2.062241584062576294e-01 1.320948004722595215e-01
5.000000000000000000e+03 1.769893616437911987e-01 8.396621942520141602e-01 6.424840688705444336e-01 1.960113731911405921e-04 4.206006526947021484e-01 7.008818387985229492e-01 4.934564977884292603e-02 8.396621942520141602e-01 6.424840688705444336e-01 1.960113731911405921e-04 4.206006526947021484e-01 7.008818387985229492e-01
6.000000000000000000e+03 7.777048647403717041e-02 9.737440943717956543e-02 1.881852298974990845e-01 3.087581745830902946e-08 7.753814756870269775e-02 1.235705763101577759e-01 9.149457328021526337e-03 9.737440943717956543e-02 1.881852298974990845e-01 3.087581745830902946e-08 7.753814756870269775e-02 1.235705763101577759e-01
7.000000000000000000e+03 1.179079860448837280e-01 3.065837919712066650e-01 3.764177858829498291e-01 9.532285184832289815e-05 2.479312717914581299e-01 1.601914465427398682e-01 3.936178237199783325e-02 3.065837919712066650e-01 3.764177858829498291e-01 9.532285184832289815e-05 2.479312717914581299e-01 1.601914465427398682e-01
8.000000000000000000e+03 9.773678779602050781e-01 2.741276323795318604e-01 8.078126311302185059e-01 1.648928264330606908e-05 3.263296186923980713e-01 5.074936151504516602e-01 2.240594178438186646e-01 2.741276323795318604e-01 8.078126311302185059e-01 1.648928264330606908e-05 3.263296186923980713e-01 5.074936151504516602e-01
9.000000000000000000e+03 8.963824063539505005e-02 1.209999099373817444e-01 3.210359215736389160e-01 9.115871648646134418e-07 2.745631039142608643e-01 1.386889964342117310e-01 1.670307479798793793e-02 1.209999099373817444e-01 3.210359215736389160e-01 9.115871648646134418e-07 2.745631039142608643e-01 1.386889964342117310e-01
1.000000000000000000e+04 5.267591774463653564e-02 1.703996956348419189e-01 1.129190623760223389e-01 5.448138722385920119e-07 1.946314424276351929e-01 8.625546842813491821e-02 9.228875860571861267e-03 1.703996956348419189e-01 1.129190623760223389e-01 5.448138722385920119e-07 1.946314424276351929e-01 8.625546842813491821e-02
