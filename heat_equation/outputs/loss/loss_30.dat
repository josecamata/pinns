# learning_rate: 0.001
# num_dense_layers: 5
# num_dense_nodes: 50
# activation:tanh 
# batch_size: 32
# final loss: 0.5336183309555054
# Training Time: 74.95048093795776
# Best Step: 10000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 1.395465850830078125e+01 1.149501647949218750e+02 3.896399497985839844e+00 1.731398329138755798e-02 1.676406860351562500e+00 9.715119600296020508e-01 1.395465850830078125e+01 1.149501647949218750e+02 3.896399497985839844e+00 1.731398329138755798e-02 1.676406860351562500e+00 9.715119600296020508e-01
1.000000000000000000e+03 9.381277859210968018e-02 2.403871119022369385e-01 4.545274078845977783e-01 2.288167706865351647e-05 3.130727410316467285e-01 4.216187298297882080e-01 9.381277859210968018e-02 2.403871119022369385e-01 4.545274078845977783e-01 2.288167706865351647e-05 3.130727410316467285e-01 4.216187298297882080e-01
2.000000000000000000e+03 3.880850598216056824e-02 2.737952768802642822e-01 3.558229804039001465e-01 6.587802090507466346e-06 2.610996663570404053e-01 2.193217128515243530e-01 3.880850598216056824e-02 2.737952768802642822e-01 3.558229804039001465e-01 6.587802090507466346e-06 2.610996663570404053e-01 2.193217128515243530e-01
3.000000000000000000e+03 3.705423325300216675e-02 1.263640373945236206e-01 3.880905210971832275e-01 7.713067316217347980e-05 2.858438491821289062e-01 1.960786581039428711e-01 3.705423325300216675e-02 1.263640373945236206e-01 3.880905210971832275e-01 7.713067316217347980e-05 2.858438491821289062e-01 1.960786581039428711e-01
4.000000000000000000e+03 5.176138877868652344e-02 1.060437560081481934e-01 3.650294542312622070e-01 2.374145515204872936e-05 2.734403312206268311e-01 1.487215161323547363e-01 5.176138877868652344e-02 1.060437560081481934e-01 3.650294542312622070e-01 2.374145515204872936e-05 2.734403312206268311e-01 1.487215161323547363e-01
5.000000000000000000e+03 6.379664689302444458e-02 2.178017795085906982e-01 3.012163043022155762e-01 1.645767753188920324e-07 2.211314737796783447e-01 8.930800855159759521e-02 6.379664689302444458e-02 2.178017795085906982e-01 3.012163043022155762e-01 1.645767753188920324e-07 2.211314737796783447e-01 8.930800855159759521e-02
6.000000000000000000e+03 5.556423962116241455e-02 7.933076471090316772e-02 3.590063452720642090e-01 7.854678187868557870e-07 1.831867098808288574e-01 1.124039888381958008e-01 5.556423962116241455e-02 7.933076471090316772e-02 3.590063452720642090e-01 7.854678187868557870e-07 1.831867098808288574e-01 1.124039888381958008e-01
7.000000000000000000e+03 4.174351319670677185e-02 1.911419630050659180e-01 2.919478714466094971e-01 1.070667281055648346e-06 8.707962930202484131e-02 6.751949340105056763e-02 4.174351319670677185e-02 1.911419630050659180e-01 2.919478714466094971e-01 1.070667281055648346e-06 8.707962930202484131e-02 6.751949340105056763e-02
8.000000000000000000e+03 4.406317695975303650e-02 8.605706691741943359e-02 3.185997009277343750e-01 9.002869774121791124e-07 7.208000868558883667e-02 7.901044189929962158e-02 4.406317695975303650e-02 8.605706691741943359e-02 3.185997009277343750e-01 9.002869774121791124e-07 7.208000868558883667e-02 7.901044189929962158e-02
9.000000000000000000e+03 5.515436083078384399e-02 7.645937055349349976e-02 3.247492909431457520e-01 7.511755484301829711e-07 5.988092720508575439e-02 6.784279644489288330e-02 5.515436083078384399e-02 7.645937055349349976e-02 3.247492909431457520e-01 7.511755484301829711e-07 5.988092720508575439e-02 6.784279644489288330e-02
1.000000000000000000e+04 4.460534453392028809e-02 6.631144136190414429e-02 3.110287487506866455e-01 7.432396387230255641e-07 4.720221832394599915e-02 6.446983665227890015e-02 4.460534453392028809e-02 6.631144136190414429e-02 3.110287487506866455e-01 7.432396387230255641e-07 4.720221832394599915e-02 6.446983665227890015e-02
