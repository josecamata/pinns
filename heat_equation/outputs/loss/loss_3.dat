# learning_rate: 0.0005
# num_dense_layers: 7
# num_dense_nodes: 60
# activation:Swish 
# batch_size: 32
# final loss: 0.8578780889511108
# Training Time: 130.2459900379181
# Best Step: 10000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 6.796661909902468324e-05 4.964109802246093750e+01 1.458209299016743898e-04 1.736340351499165990e-07 3.387611650396138430e-05 1.002743010758422315e-04 6.796661909902468324e-05 4.964109802246093750e+01 1.458209299016743898e-04 1.736340351499165990e-07 3.387611650396138430e-05 1.002743010758422315e-04
1.000000000000000000e+03 1.233150139451026917e-01 3.816804885864257812e-01 4.505711495876312256e-01 1.624134747544303536e-04 3.431920409202575684e-01 5.874475240707397461e-01 1.233150139451026917e-01 3.816804885864257812e-01 4.505711495876312256e-01 1.624134747544303536e-04 3.431920409202575684e-01 5.874475240707397461e-01
2.000000000000000000e+03 4.987120628356933594e-02 3.497834205627441406e-01 3.564791083335876465e-01 2.396393483650172129e-06 2.726528942584991455e-01 2.384367883205413818e-01 4.987120628356933594e-02 3.497834205627441406e-01 3.564791083335876465e-01 2.396393483650172129e-06 2.726528942584991455e-01 2.384367883205413818e-01
3.000000000000000000e+03 5.721125751733779907e-02 1.487695276737213135e-01 3.767717182636260986e-01 9.334729838883504272e-06 2.885879278182983398e-01 1.860994994640350342e-01 5.721125751733779907e-02 1.487695276737213135e-01 3.767717182636260986e-01 9.334729838883504272e-06 2.885879278182983398e-01 1.860994994640350342e-01
4.000000000000000000e+03 4.337999969720840454e-02 1.809528172016143799e-01 3.523336648941040039e-01 3.010176783391216304e-07 2.805602550506591797e-01 1.298397481441497803e-01 4.337999969720840454e-02 1.809528172016143799e-01 3.523336648941040039e-01 3.010176783391216304e-07 2.805602550506591797e-01 1.298397481441497803e-01
5.000000000000000000e+03 4.993969947099685669e-02 1.745650023221969604e-01 3.523755073547363281e-01 3.350787665112875402e-07 2.837956845760345459e-01 1.089494451880455017e-01 4.993969947099685669e-02 1.745650023221969604e-01 3.523755073547363281e-01 3.350787665112875402e-07 2.837956845760345459e-01 1.089494451880455017e-01
6.000000000000000000e+03 3.496325388550758362e-02 1.786324083805084229e-01 3.425565063953399658e-01 4.724327595795330126e-07 2.769097089767456055e-01 9.644463658332824707e-02 3.496325388550758362e-02 1.786324083805084229e-01 3.425565063953399658e-01 4.724327595795330126e-07 2.769097089767456055e-01 9.644463658332824707e-02
7.000000000000000000e+03 3.241145983338356018e-02 1.452964544296264648e-01 3.483690321445465088e-01 3.891130404554132838e-07 2.808459699153900146e-01 9.155938774347305298e-02 3.241145983338356018e-02 1.452964544296264648e-01 3.483690321445465088e-01 3.891130404554132838e-07 2.808459699153900146e-01 9.155938774347305298e-02
8.000000000000000000e+03 3.095223195850849152e-02 1.483575999736785889e-01 3.451208174228668213e-01 2.913226069267693674e-07 2.793360352516174316e-01 8.147248625755310059e-02 3.095223195850849152e-02 1.483575999736785889e-01 3.451208174228668213e-01 2.913226069267693674e-07 2.793360352516174316e-01 8.147248625755310059e-02
9.000000000000000000e+03 4.008113965392112732e-02 1.961135268211364746e-01 3.274044394493103027e-01 3.426636396852700273e-07 2.671374380588531494e-01 6.864169239997863770e-02 4.008113965392112732e-02 1.961135268211364746e-01 3.274044394493103027e-01 3.426636396852700273e-07 2.671374380588531494e-01 6.864169239997863770e-02
1.000000000000000000e+04 3.461810201406478882e-02 9.983442723751068115e-02 3.582663536071777344e-01 3.947769471324136248e-07 2.879044115543365479e-01 7.725439220666885376e-02 3.461810201406478882e-02 9.983442723751068115e-02 3.582663536071777344e-01 3.947769471324136248e-07 2.879044115543365479e-01 7.725439220666885376e-02
