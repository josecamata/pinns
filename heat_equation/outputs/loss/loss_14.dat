# learning_rate: 0.0005
# num_dense_layers: 8
# num_dense_nodes: 30
# activation:tanh 
# batch_size: 32
# final loss: 0.7783241271972656
# Training Time: 100.51453995704651
# Best Step: 10000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 1.039789557456970215e+00 4.473488998413085938e+01 4.182872921228408813e-02 8.719072793610394001e-04 3.876453638076782227e-02 1.527197510004043579e-01 1.039789557456970215e+00 4.473488998413085938e+01 4.182872921228408813e-02 8.719072793610394001e-04 3.876453638076782227e-02 1.527197510004043579e-01
1.000000000000000000e+03 6.692666560411453247e-02 2.174439132213592529e-01 4.008107483386993408e-01 1.542488462291657925e-05 3.139740526676177979e-01 3.055165410041809082e-01 6.692666560411453247e-02 2.174439132213592529e-01 4.008107483386993408e-01 1.542488462291657925e-05 3.139740526676177979e-01 3.055165410041809082e-01
2.000000000000000000e+03 4.456249251961708069e-02 5.235321521759033203e-01 3.018236160278320312e-01 1.793225783330854028e-05 2.534757256507873535e-01 1.289812028408050537e-01 4.456249251961708069e-02 5.235321521759033203e-01 3.018236160278320312e-01 1.793225783330854028e-05 2.534757256507873535e-01 1.289812028408050537e-01
3.000000000000000000e+03 3.549017012119293213e-02 1.285903006792068481e-01 3.558870851993560791e-01 2.309673391209798865e-06 2.939296066761016846e-01 1.224398165941238403e-01 3.549017012119293213e-02 1.285903006792068481e-01 3.558870851993560791e-01 2.309673391209798865e-06 2.939296066761016846e-01 1.224398165941238403e-01
4.000000000000000000e+03 3.166583925485610962e-02 1.309099048376083374e-01 3.470714390277862549e-01 5.270488827591179870e-07 2.909165024757385254e-01 8.733216673135757446e-02 3.166583925485610962e-02 1.309099048376083374e-01 3.470714390277862549e-01 5.270488827591179870e-07 2.909165024757385254e-01 8.733216673135757446e-02
5.000000000000000000e+03 2.963924407958984375e-02 1.065703332424163818e-01 3.547933995723724365e-01 3.057128878936055116e-07 2.940419614315032959e-01 7.703398168087005615e-02 2.963924407958984375e-02 1.065703332424163818e-01 3.547933995723724365e-01 3.057128878936055116e-07 2.940419614315032959e-01 7.703398168087005615e-02
6.000000000000000000e+03 3.688596189022064209e-02 1.709921658039093018e-01 3.295333087444305420e-01 2.172886581774946535e-07 2.718874514102935791e-01 5.706978961825370789e-02 3.688596189022064209e-02 1.709921658039093018e-01 3.295333087444305420e-01 2.172886581774946535e-07 2.718874514102935791e-01 5.706978961825370789e-02
7.000000000000000000e+03 3.322829306125640869e-02 1.213929057121276855e-01 3.390316665172576904e-01 1.583552915462860256e-07 2.742763757705688477e-01 5.861603841185569763e-02 3.322829306125640869e-02 1.213929057121276855e-01 3.390316665172576904e-01 1.583552915462860256e-07 2.742763757705688477e-01 5.861603841185569763e-02
8.000000000000000000e+03 3.787260502576828003e-02 1.082856357097625732e-01 3.388901352882385254e-01 1.869916701480178745e-07 2.659413218498229980e-01 5.699790269136428833e-02 3.787260502576828003e-02 1.082856357097625732e-01 3.388901352882385254e-01 1.869916701480178745e-07 2.659413218498229980e-01 5.699790269136428833e-02
9.000000000000000000e+03 4.351932555437088013e-02 8.696454018354415894e-02 3.397290110588073730e-01 3.137986652745894389e-07 2.626150846481323242e-01 5.824648961424827576e-02 4.351932555437088013e-02 8.696454018354415894e-02 3.397290110588073730e-01 3.137986652745894389e-07 2.626150846481323242e-01 5.824648961424827576e-02
1.000000000000000000e+04 6.868572533130645752e-02 1.027996167540550232e-01 3.264538943767547607e-01 5.218554974817379843e-07 2.280173897743225098e-01 5.236697196960449219e-02 6.868572533130645752e-02 1.027996167540550232e-01 3.264538943767547607e-01 5.218554974817379843e-07 2.280173897743225098e-01 5.236697196960449219e-02
