# learning_rate: 0.005
# num_dense_layers: 8
# num_dense_nodes: 60
# activation:Swish 
# batch_size: 32
# final loss: 0.3241846263408661
# Training Time: 145.53689885139465
# Best Step: 5000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 1.216624805238097906e-04 4.997733306884765625e+01 4.773913587996503338e-06 8.319811684032174526e-08 6.285950348683400080e-06 3.241659442210220732e-06 1.216624805238097906e-04 4.997733306884765625e+01 4.773913587996503338e-06 8.319811684032174526e-08 6.285950348683400080e-06 3.241659442210220732e-06
1.000000000000000000e+03 3.804681450128555298e-02 1.327841132879257202e-01 3.839423954486846924e-01 2.439520358166191727e-06 2.881013751029968262e-01 1.947936415672302246e-01 3.804681450128555298e-02 1.327841132879257202e-01 3.839423954486846924e-01 2.439520358166191727e-06 2.881013751029968262e-01 1.947936415672302246e-01
2.000000000000000000e+03 3.888298571109771729e-02 1.540438234806060791e-01 4.060122966766357422e-01 1.703814291431626771e-06 3.090803027153015137e-01 2.053831666707992554e-01 3.888298571109771729e-02 1.540438234806060791e-01 4.060122966766357422e-01 1.703814291431626771e-06 3.090803027153015137e-01 2.053831666707992554e-01
3.000000000000000000e+03 1.114299073815345764e-01 4.832974672317504883e-01 2.787361145019531250e-01 8.111949796330009121e-07 2.375516146421432495e-01 4.888533800840377808e-02 1.114299073815345764e-01 4.832974672317504883e-01 2.787361145019531250e-01 8.111949796330009121e-07 2.375516146421432495e-01 4.888533800840377808e-02
4.000000000000000000e+03 5.323664098978042603e-02 4.314288496971130371e-02 1.299812942743301392e-01 1.740020934448693879e-06 8.767545223236083984e-02 1.090269088745117188e-01 5.323664098978042603e-02 4.314288496971130371e-02 1.299812942743301392e-01 1.740020934448693879e-06 8.767545223236083984e-02 1.090269088745117188e-01
5.000000000000000000e+03 2.866002358496189117e-02 1.697769612073898315e-01 5.916049331426620483e-02 1.164437094303139020e-06 1.621417328715324402e-02 5.037182569503784180e-02 2.866002358496189117e-02 1.697769612073898315e-01 5.916049331426620483e-02 1.164437094303139020e-06 1.621417328715324402e-02 5.037182569503784180e-02
6.000000000000000000e+03 9.409123659133911133e-02 1.201567575335502625e-01 1.083042919635772705e-01 1.388415512337815017e-06 2.910761348903179169e-02 6.004946678876876831e-02 9.409123659133911133e-02 1.201567575335502625e-01 1.083042919635772705e-01 1.388415512337815017e-06 2.910761348903179169e-02 6.004946678876876831e-02
7.000000000000000000e+03 1.838500797748565674e-02 1.287633180618286133e-01 1.078632622957229614e-01 4.875331569564878009e-07 4.255973175168037415e-02 1.001788675785064697e-01 1.838500797748565674e-02 1.287633180618286133e-01 1.078632622957229614e-01 4.875331569564878009e-07 4.255973175168037415e-02 1.001788675785064697e-01
8.000000000000000000e+03 8.458982408046722412e-02 1.908653378486633301e-01 7.423003017902374268e-02 9.441053094860762940e-08 4.303690046072006226e-02 8.212324231863021851e-02 8.458982408046722412e-02 1.908653378486633301e-01 7.423003017902374268e-02 9.441053094860762940e-08 4.303690046072006226e-02 8.212324231863021851e-02
9.000000000000000000e+03 1.701682358980178833e-01 1.439364254474639893e-01 8.117306232452392578e-02 1.571614689055422787e-06 4.815982282161712646e-02 8.137759566307067871e-02 1.701682358980178833e-01 1.439364254474639893e-01 8.117306232452392578e-02 1.571614689055422787e-06 4.815982282161712646e-02 8.137759566307067871e-02
1.000000000000000000e+04 4.514462500810623169e-02 2.774837315082550049e-01 4.761041328310966492e-02 8.074098900578974281e-08 2.284699678421020508e-02 3.971039876341819763e-02 4.514462500810623169e-02 2.774837315082550049e-01 4.761041328310966492e-02 8.074098900578974281e-08 2.284699678421020508e-02 3.971039876341819763e-02
