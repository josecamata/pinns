# learning_rate: 0.0008209101198056497
# num_dense_layers: 10
# num_dense_nodes: 120
# activation:sigmoid 
# batch_size: 32
# final loss: 0.881736159324646
# Training Time: 193.37180042266846
# Best Step: 10000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 5.298383802011807919e-13 1.024925231933593750e+02 2.795859098434448242e+00 1.863905973732471466e-02 1.863906860351562500e+00 4.659767150878906250e+00 5.348504300041467818e-13 1.024925231933593750e+02 2.795859098434448242e+00 1.863905973732471466e-02 1.863906860351562500e+00 4.659767150878906250e+00
1.000000000000000000e+03 1.703688055276870728e-01 2.170464247465133667e-01 6.133437752723693848e-01 2.664142630237620324e-05 4.726479053497314453e-01 5.728558301925659180e-01 1.043256595730781555e-01 2.170464247465133667e-01 6.133437752723693848e-01 2.664142630237620324e-05 4.726479053497314453e-01 5.728558301925659180e-01
2.000000000000000000e+03 1.218929216265678406e-01 1.917791962623596191e-01 5.480539798736572266e-01 4.210968108964152634e-05 4.052239060401916504e-01 3.227280974388122559e-01 1.419505011290311813e-02 1.917791962623596191e-01 5.480539798736572266e-01 4.210968108964152634e-05 4.052239060401916504e-01 3.227280974388122559e-01
3.000000000000000000e+03 4.960529133677482605e-02 1.358867585659027100e-01 4.958797097206115723e-01 2.770472565316595137e-05 3.794935047626495361e-01 1.400403380393981934e-01 3.371264785528182983e-02 1.358867585659027100e-01 4.958797097206115723e-01 2.770472565316595137e-05 3.794935047626495361e-01 1.400403380393981934e-01
4.000000000000000000e+03 3.713505342602729797e-02 1.173344776034355164e-01 4.366675615310668945e-01 1.469363269279710948e-06 3.430405557155609131e-01 1.025494784116744995e-01 4.054314643144607544e-02 1.173344776034355164e-01 4.366675615310668945e-01 1.469363269279710948e-06 3.430405557155609131e-01 1.025494784116744995e-01
5.000000000000000000e+03 3.341148793697357178e-02 7.166069746017456055e-02 4.341570436954498291e-01 1.340730477750184946e-07 3.448641002178192139e-01 9.652781486511230469e-02 2.246568538248538971e-02 7.166069746017456055e-02 4.341570436954498291e-01 1.340730477750184946e-07 3.448641002178192139e-01 9.652781486511230469e-02
6.000000000000000000e+03 2.966262958943843842e-02 5.584392324090003967e-02 4.328874647617340088e-01 2.333946298449518508e-07 3.458456993103027344e-01 1.009446457028388977e-01 1.582038588821887970e-02 5.584392324090003967e-02 4.328874647617340088e-01 2.333946298449518508e-07 3.458456993103027344e-01 1.009446457028388977e-01
7.000000000000000000e+03 2.941356226801872253e-02 6.199875473976135254e-02 4.194396436214447021e-01 6.500139448917252594e-08 3.428370952606201172e-01 8.090031147003173828e-02 1.853488758206367493e-02 6.199875473976135254e-02 4.194396436214447021e-01 6.500139448917252594e-08 3.428370952606201172e-01 8.090031147003173828e-02
8.000000000000000000e+03 2.790426462888717651e-02 3.771540522575378418e-02 4.317216575145721436e-01 1.037190259012277238e-06 3.553518354892730713e-01 7.792355120182037354e-02 2.038036845624446869e-02 3.771540522575378418e-02 4.317216575145721436e-01 1.037190259012277238e-06 3.553518354892730713e-01 7.792355120182037354e-02
9.000000000000000000e+03 2.683227136731147766e-02 5.912606790661811829e-02 4.073736965656280518e-01 1.168079748481432034e-07 3.370986878871917725e-01 7.101792097091674805e-02 2.321146614849567413e-02 5.912606790661811829e-02 4.073736965656280518e-01 1.168079748481432034e-07 3.370986878871917725e-01 7.101792097091674805e-02
1.000000000000000000e+04 2.768559195101261139e-02 6.835721433162689209e-02 3.949272632598876953e-01 2.432612689062807476e-07 3.279812633991241455e-01 6.341363489627838135e-02 2.705659717321395874e-02 6.835721433162689209e-02 3.949272632598876953e-01 2.432612689062807476e-07 3.279812633991241455e-01 6.341363489627838135e-02
