# learning_rate: 0.002278388085457619
# num_dense_layers: 8
# num_dense_nodes: 114
# activation:sin 
# batch_size: 32
# final loss: 0.3490007221698761
# Training Time: 156.5351812839508
# Best Step: 7000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 1.920879960060119629e+00 6.818394470214843750e+01 8.790617436170578003e-02 6.999388569965958595e-04 3.485772013664245605e-01 8.548361808061599731e-02 1.873223543167114258e+00 6.818394470214843750e+01 8.790617436170578003e-02 6.999388569965958595e-04 3.485772013664245605e-01 8.548361808061599731e-02
1.000000000000000000e+03 3.652090206742286682e-02 2.046015411615371704e-01 3.545967340469360352e-01 3.912188276444794610e-06 2.862488031387329102e-01 2.351431250572204590e-01 1.816735230386257172e-02 2.046015411615371704e-01 3.545967340469360352e-01 3.912188276444794610e-06 2.862488031387329102e-01 2.351431250572204590e-01
2.000000000000000000e+03 7.119685411453247070e-02 2.072707265615463257e-01 4.365204870700836182e-01 3.223827297915704548e-05 3.076308071613311768e-01 1.792266219854354858e-01 1.567046344280242920e-02 2.072707265615463257e-01 4.365204870700836182e-01 3.223827297915704548e-05 3.076308071613311768e-01 1.792266219854354858e-01
3.000000000000000000e+03 7.526693493127822876e-02 9.893886744976043701e-02 3.838665187358856201e-01 2.132305417035240680e-05 2.546229660511016846e-01 1.464363485574722290e-01 1.949810050427913666e-02 9.893886744976043701e-02 3.838665187358856201e-01 2.132305417035240680e-05 2.546229660511016846e-01 1.464363485574722290e-01
4.000000000000000000e+03 1.735112518072128296e-01 1.888816952705383301e-01 3.978243172168731689e-01 1.104143939301138744e-05 1.070192158222198486e-01 1.660290509462356567e-01 5.429851636290550232e-02 1.888816952705383301e-01 3.978243172168731689e-01 1.104143939301138744e-05 1.070192158222198486e-01 1.660290509462356567e-01
5.000000000000000000e+03 1.684207916259765625e-01 1.365174651145935059e+00 3.272941708564758301e-01 1.187808629765640944e-05 2.403222322463989258e-01 6.394204497337341309e-01 1.302748620510101318e-01 1.365174651145935059e+00 3.272941708564758301e-01 1.187808629765640944e-05 2.403222322463989258e-01 6.394204497337341309e-01
6.000000000000000000e+03 9.365000575780868530e-02 2.633818387985229492e-01 3.299843668937683105e-01 2.691002691790345125e-06 1.389763355255126953e-01 2.752862572669982910e-01 2.162907831370830536e-02 2.633818387985229492e-01 3.299843668937683105e-01 2.691002691790345125e-06 1.389763355255126953e-01 2.752862572669982910e-01
7.000000000000000000e+03 5.018072575330734253e-02 1.237197667360305786e-01 8.886519819498062134e-02 4.928846919938223436e-06 2.968084998428821564e-02 9.987093508243560791e-02 6.859053391963243484e-03 1.237197667360305786e-01 8.886519819498062134e-02 4.928846919938223436e-06 2.968084998428821564e-02 9.987093508243560791e-02
8.000000000000000000e+03 4.764611646533012390e-02 9.883305430412292480e-02 9.759545326232910156e-02 5.662898274749750271e-06 4.363767057657241821e-02 1.120167449116706848e-01 5.140808410942554474e-03 9.883305430412292480e-02 9.759545326232910156e-02 5.662898274749750271e-06 4.363767057657241821e-02 1.120167449116706848e-01
9.000000000000000000e+03 8.302250504493713379e-02 3.777023851871490479e-01 2.250276356935501099e-01 8.986054126580711454e-06 1.878106445074081421e-01 2.488507032394409180e-01 2.106687240302562714e-02 3.777023851871490479e-01 2.250276356935501099e-01 8.986054126580711454e-06 1.878106445074081421e-01 2.488507032394409180e-01
1.000000000000000000e+04 5.843203887343406677e-02 1.223961934447288513e-01 1.417122781276702881e-01 1.963618706213310361e-05 1.308573484420776367e-01 2.509681880474090576e-01 9.383873082697391510e-03 1.223961934447288513e-01 1.417122781276702881e-01 1.963618706213310361e-05 1.308573484420776367e-01 2.509681880474090576e-01
