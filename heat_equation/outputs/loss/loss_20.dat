# learning_rate: 0.002038949407068606
# num_dense_layers: 10
# num_dense_nodes: 120
# activation:Swish 
# batch_size: 32
# final loss: 0.24766503274440765
# Training Time: 307.4897336959839
# Best Step: 6000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 2.151315584342228249e-06 4.998858642578125000e+01 2.393580587067845045e-07 2.669745757799546482e-09 1.398586846335092559e-07 3.845260891921498114e-07 2.499284164514392614e-06 4.998858642578125000e+01 2.393580587067845045e-07 2.669745757799546482e-09 1.398586846335092559e-07 3.845260891921498114e-07
1.000000000000000000e+03 3.317310661077499390e-02 9.943801164627075195e-02 4.085868597030639648e-01 2.550688577684923075e-06 3.037532269954681396e-01 1.958937644958496094e-01 2.521769143640995026e-02 9.943801164627075195e-02 4.085868597030639648e-01 2.550688577684923075e-06 3.037532269954681396e-01 1.958937644958496094e-01
2.000000000000000000e+03 2.600532583892345428e-02 1.806550174951553345e-01 3.569065928459167480e-01 1.208658318319066893e-06 2.740265429019927979e-01 9.722092747688293457e-02 2.636376023292541504e-02 1.806550174951553345e-01 3.569065928459167480e-01 1.208658318319066893e-06 2.740265429019927979e-01 9.722092747688293457e-02
3.000000000000000000e+03 2.709227614104747772e-02 1.273029446601867676e-01 3.475075364112854004e-01 4.284720489522442222e-07 2.667734920978546143e-01 9.387623518705368042e-02 1.562479324638843536e-02 1.273029446601867676e-01 3.475075364112854004e-01 4.284720489522442222e-07 2.667734920978546143e-01 9.387623518705368042e-02
4.000000000000000000e+03 3.386224061250686646e-02 1.397217214107513428e-01 4.973038434982299805e-01 3.844283128273673356e-06 8.550588041543960571e-02 1.508755385875701904e-01 9.865555912256240845e-03 1.397217214107513428e-01 4.973038434982299805e-01 3.844283128273673356e-06 8.550588041543960571e-02 1.508755385875701904e-01
5.000000000000000000e+03 4.136217013001441956e-02 7.813807576894760132e-02 1.513233035802841187e-01 2.492018893462955020e-06 5.060072615742683411e-02 7.712741196155548096e-02 8.236061781644821167e-03 7.813807576894760132e-02 1.513233035802841187e-01 2.492018893462955020e-06 5.060072615742683411e-02 7.712741196155548096e-02
6.000000000000000000e+03 3.446405380964279175e-02 1.037157699465751648e-01 6.849172711372375488e-02 2.113390792146674357e-06 2.650063112378120422e-02 5.077870562672615051e-02 5.254961084574460983e-03 1.037157699465751648e-01 6.849172711372375488e-02 2.113390792146674357e-06 2.650063112378120422e-02 5.077870562672615051e-02
7.000000000000000000e+03 8.035415410995483398e-02 2.993384003639221191e-01 4.840732738375663757e-02 5.341256382962455973e-06 6.350700277835130692e-03 3.025724180042743683e-02 1.498314901255071163e-03 2.993384003639221191e-01 4.840732738375663757e-02 5.341256382962455973e-06 6.350700277835130692e-03 3.025724180042743683e-02
8.000000000000000000e+03 7.715524733066558838e-02 1.514458954334259033e-01 4.488833621144294739e-02 1.056365249496593606e-06 1.771166175603866577e-02 3.249384462833404541e-02 1.124226721003651619e-03 1.514458954334259033e-01 4.488833621144294739e-02 1.056365249496593606e-06 1.771166175603866577e-02 3.249384462833404541e-02
9.000000000000000000e+03 7.928310334682464600e-02 1.283726841211318970e-01 1.044549867510795593e-01 3.105792600877066434e-08 7.333231717348098755e-02 8.893424272537231445e-02 1.172828720882534981e-03 1.283726841211318970e-01 1.044549867510795593e-01 3.105792600877066434e-08 7.333231717348098755e-02 8.893424272537231445e-02
1.000000000000000000e+04 1.182430535554885864e-01 1.593750268220901489e-01 4.682621732354164124e-02 5.054406528870458715e-07 8.766977116465568542e-03 3.549071401357650757e-02 1.758068916387856007e-03 1.593750268220901489e-01 4.682621732354164124e-02 5.054406528870458715e-07 8.766977116465568542e-03 3.549071401357650757e-02
