# learning_rate: 0.0023431828074545317
# num_dense_layers: 7
# num_dense_nodes: 106
# activation:sin 
# batch_size: 32
# final loss: 0.44975024461746216
# Training Time: 130.4334659576416
# Best Step: 9000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 6.324945688247680664e-01 5.411883163452148438e+01 1.680555343627929688e-01 1.584214041940867901e-03 4.175564274191856384e-02 9.867613017559051514e-02 6.323258876800537109e-01 5.411883163452148438e+01 1.680555343627929688e-01 1.584214041940867901e-03 4.175564274191856384e-02 9.867613017559051514e-02
1.000000000000000000e+03 9.063052386045455933e-02 5.436273813247680664e-01 5.550701618194580078e-01 2.792040504573378712e-06 4.022797644138336182e-01 4.129828512668609619e-01 2.897857129573822021e-02 5.436273813247680664e-01 5.550701618194580078e-01 2.792040504573378712e-06 4.022797644138336182e-01 4.129828512668609619e-01
2.000000000000000000e+03 1.047043800354003906e-01 2.898095548152923584e-01 2.899335920810699463e-01 1.537633761472534388e-05 2.346742153167724609e-01 1.254227757453918457e-01 1.669466868042945862e-02 2.898095548152923584e-01 2.899335920810699463e-01 1.537633761472534388e-05 2.346742153167724609e-01 1.254227757453918457e-01
3.000000000000000000e+03 6.347404420375823975e-02 1.881772130727767944e-01 3.024843335151672363e-01 2.022623448283411562e-05 2.544223368167877197e-01 1.183122172951698303e-01 1.436432637274265289e-02 1.881772130727767944e-01 3.024843335151672363e-01 2.022623448283411562e-05 2.544223368167877197e-01 1.183122172951698303e-01
4.000000000000000000e+03 7.782048732042312622e-02 1.267325729131698608e-01 2.424143105745315552e-01 8.157586535162408836e-07 1.693420410156250000e-01 1.075301766395568848e-01 1.486109849065542221e-02 1.267325729131698608e-01 2.424143105745315552e-01 8.157586535162408836e-07 1.693420410156250000e-01 1.075301766395568848e-01
5.000000000000000000e+03 5.619477108120918274e-02 5.510799288749694824e-01 2.388462126255035400e-01 2.444832898618187755e-05 1.205727905035018921e-01 2.205526977777481079e-01 1.808579638600349426e-02 5.510799288749694824e-01 2.388462126255035400e-01 2.444832898618187755e-05 1.205727905035018921e-01 2.205526977777481079e-01
6.000000000000000000e+03 4.435836151242256165e-02 1.685777604579925537e-01 1.049355268478393555e-01 3.655333557617268525e-06 1.063012257218360901e-01 1.674106419086456299e-01 1.225485466420650482e-02 1.685777604579925537e-01 1.049355268478393555e-01 3.655333557617268525e-06 1.063012257218360901e-01 1.674106419086456299e-01
7.000000000000000000e+03 8.927023410797119141e-02 2.766352295875549316e-01 6.940700113773345947e-02 9.639346671974635683e-07 2.230246737599372864e-02 7.046433538198471069e-02 1.094024721533060074e-02 2.766352295875549316e-01 6.940700113773345947e-02 9.639346671974635683e-07 2.230246737599372864e-02 7.046433538198471069e-02
8.000000000000000000e+03 9.907123446464538574e-02 1.726161986589431763e-01 2.260914295911788940e-01 7.956591616675723344e-06 1.144327223300933838e-01 1.653117090463638306e-01 2.514339238405227661e-02 1.726161986589431763e-01 2.260914295911788940e-01 7.956591616675723344e-06 1.144327223300933838e-01 1.653117090463638306e-01
9.000000000000000000e+03 5.123158916831016541e-02 9.220436960458755493e-02 1.456459462642669678e-01 9.723660696181468666e-06 8.779595792293548584e-02 1.198936700820922852e-01 1.177283097058534622e-02 9.220436960458755493e-02 1.456459462642669678e-01 9.723660696181468666e-06 8.779595792293548584e-02 1.198936700820922852e-01
1.000000000000000000e+04 2.150069177150726318e-01 4.500439763069152832e-01 2.490967512130737305e-01 1.339789196208585054e-05 2.003754824399948120e-01 8.254473656415939331e-02 3.276155516505241394e-02 4.500439763069152832e-01 2.490967512130737305e-01 1.339789196208585054e-05 2.003754824399948120e-01 8.254473656415939331e-02
