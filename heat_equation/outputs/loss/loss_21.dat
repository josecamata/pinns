# learning_rate: 0.0026220762856422634
# num_dense_layers: 10
# num_dense_nodes: 120
# activation:Swish 
# batch_size: 32
# final loss: 0.2346145510673523
# Training Time: 308.5468304157257
# Best Step: 10000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 1.445269845135044307e-06 4.998853683471679688e+01 7.478812591443784186e-08 4.837164557791595598e-10 1.472930506452030386e-07 6.722983059148646134e-09 1.338776314696588088e-06 4.998853683471679688e+01 7.478812591443784186e-08 4.837164557791595598e-10 1.472930506452030386e-07 6.722983059148646134e-09
1.000000000000000000e+03 3.964636847376823425e-02 1.492416560649871826e-01 4.260913133621215820e-01 9.753041467774892226e-07 3.270081877708435059e-01 2.096761018037796021e-01 2.736282534897327423e-02 1.492416560649871826e-01 4.260913133621215820e-01 9.753041467774892226e-07 3.270081877708435059e-01 2.096761018037796021e-01
2.000000000000000000e+03 5.251833423972129822e-02 1.369299441576004028e-01 4.474258422851562500e-01 1.748565296111337375e-06 3.231016993522644043e-01 1.576280444860458374e-01 2.790177240967750549e-03 1.369299441576004028e-01 4.474258422851562500e-01 1.748565296111337375e-06 3.231016993522644043e-01 1.576280444860458374e-01
3.000000000000000000e+03 5.122898891568183899e-02 2.965218722820281982e-01 3.221249580383300781e-01 1.186056010737956967e-06 2.421152442693710327e-01 8.043155819177627563e-02 7.067320402711629868e-03 2.965218722820281982e-01 3.221249580383300781e-01 1.186056010737956967e-06 2.421152442693710327e-01 8.043155819177627563e-02
4.000000000000000000e+03 4.532140865921974182e-02 1.240030601620674133e-01 7.044892013072967529e-02 6.378407988449907862e-07 3.989763930439949036e-02 1.351771652698516846e-01 5.751549731940031052e-03 1.240030601620674133e-01 7.044892013072967529e-02 6.378407988449907862e-07 3.989763930439949036e-02 1.351771652698516846e-01
5.000000000000000000e+03 1.258756518363952637e-01 1.192866042256355286e-01 5.041481554508209229e-02 1.140700867097166338e-08 4.757936671376228333e-02 6.236997991800308228e-02 2.362758852541446686e-03 1.192866042256355286e-01 5.041481554508209229e-02 1.140700867097166338e-08 4.757936671376228333e-02 6.236997991800308228e-02
6.000000000000000000e+03 4.408356547355651855e-02 1.669554561376571655e-01 6.501166522502899170e-02 1.381816758794229827e-07 3.671177476644515991e-02 9.476390480995178223e-02 9.004752151668071747e-03 1.669554561376571655e-01 6.501166522502899170e-02 1.381816758794229827e-07 3.671177476644515991e-02 9.476390480995178223e-02
7.000000000000000000e+03 1.601763367652893066e-01 1.261435002088546753e-01 1.755605041980743408e-01 6.401496079888602253e-07 6.952578574419021606e-02 4.754853993654251099e-02 1.557350507937371731e-03 1.261435002088546753e-01 1.755605041980743408e-01 6.401496079888602253e-07 6.952578574419021606e-02 4.754853993654251099e-02
8.000000000000000000e+03 4.695310071110725403e-02 1.431332379579544067e-01 7.014176994562149048e-02 1.854281435953453183e-06 6.374365836381912231e-02 4.798699170351028442e-02 7.072511943988502026e-04 1.431332379579544067e-01 7.014176994562149048e-02 1.854281435953453183e-06 6.374365836381912231e-02 4.798699170351028442e-02
9.000000000000000000e+03 6.521619856357574463e-02 1.583485007286071777e-01 5.250392854213714600e-02 9.255111166339702322e-08 1.340575050562620163e-02 3.605988994240760803e-02 3.102396382018923759e-03 1.583485007286071777e-01 5.250392854213714600e-02 9.255111166339702322e-08 1.340575050562620163e-02 3.605988994240760803e-02
1.000000000000000000e+04 7.556039839982986450e-02 6.691072136163711548e-02 8.015434443950653076e-02 1.645185321308417770e-08 2.241769991815090179e-02 6.353617459535598755e-02 1.595597132109105587e-03 6.691072136163711548e-02 8.015434443950653076e-02 1.645185321308417770e-08 2.241769991815090179e-02 6.353617459535598755e-02
