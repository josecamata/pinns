# learning_rate: 0.001
# num_dense_layers: 5
# num_dense_nodes: 40
# activation:tanh 
# batch_size: 32
# final loss: 0.5257266163825989
# Training Time: 75.49959397315979
# Best Step: 10000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 9.655787467956542969e+00 3.417176437377929688e+01 1.054672241210937500e+00 1.023401599377393723e-02 5.793679952621459961e-01 5.223204940557479858e-02 9.655787467956542969e+00 3.417176437377929688e+01 1.054672241210937500e+00 1.023401599377393723e-02 5.793679952621459961e-01 5.223204940557479858e-02
1.000000000000000000e+03 4.401786252856254578e-02 1.811981201171875000e-01 4.146129488945007324e-01 3.234614723623963073e-06 3.099030554294586182e-01 3.304873406887054443e-01 4.401786252856254578e-02 1.811981201171875000e-01 4.146129488945007324e-01 3.234614723623963073e-06 3.099030554294586182e-01 3.304873406887054443e-01
2.000000000000000000e+03 3.950490429997444153e-02 1.437671482563018799e-01 3.648946881294250488e-01 4.224253189022419974e-06 2.720847725868225098e-01 1.590494662523269653e-01 3.950490429997444153e-02 1.437671482563018799e-01 3.648946881294250488e-01 4.224253189022419974e-06 2.720847725868225098e-01 1.590494662523269653e-01
3.000000000000000000e+03 3.837886080145835876e-02 1.062899008393287659e-01 3.636809587478637695e-01 4.269458713679341599e-06 2.619176506996154785e-01 1.185718700289726257e-01 3.837886080145835876e-02 1.062899008393287659e-01 3.636809587478637695e-01 4.269458713679341599e-06 2.619176506996154785e-01 1.185718700289726257e-01
4.000000000000000000e+03 5.750197917222976685e-02 1.373603641986846924e-01 3.293806314468383789e-01 9.170365444788330933e-08 2.062890082597732544e-01 8.611968904733657837e-02 5.750197917222976685e-02 1.373603641986846924e-01 3.293806314468383789e-01 9.170365444788330933e-08 2.062890082597732544e-01 8.611968904733657837e-02
5.000000000000000000e+03 4.215338453650474548e-02 9.882833063602447510e-02 3.443274796009063721e-01 4.002501157174265245e-07 1.096585243940353394e-01 8.049453049898147583e-02 4.215338453650474548e-02 9.882833063602447510e-02 3.443274796009063721e-01 4.002501157174265245e-07 1.096585243940353394e-01 8.049453049898147583e-02
6.000000000000000000e+03 4.355485364794731140e-02 1.313179433345794678e-01 3.199346661567687988e-01 1.152900381384824868e-06 7.682723551988601685e-02 6.109604611992835999e-02 4.355485364794731140e-02 1.313179433345794678e-01 3.199346661567687988e-01 1.152900381384824868e-06 7.682723551988601685e-02 6.109604611992835999e-02
7.000000000000000000e+03 3.555154427886009216e-02 9.093110263347625732e-02 3.313634991645812988e-01 6.656455298070795834e-07 6.301293522119522095e-02 6.055610254406929016e-02 3.555154427886009216e-02 9.093110263347625732e-02 3.313634991645812988e-01 6.656455298070795834e-07 6.301293522119522095e-02 6.055610254406929016e-02
8.000000000000000000e+03 5.821102112531661987e-02 1.388050317764282227e-01 3.062964975833892822e-01 3.441778062551748008e-07 4.516286402940750122e-02 4.816127568483352661e-02 5.821102112531661987e-02 1.388050317764282227e-01 3.062964975833892822e-01 3.441778062551748008e-07 4.516286402940750122e-02 4.816127568483352661e-02
9.000000000000000000e+03 7.912884652614593506e-02 1.198512613773345947e-01 3.089846372604370117e-01 3.222449720396980410e-07 3.720740601420402527e-02 6.075347959995269775e-02 7.912884652614593506e-02 1.198512613773345947e-01 3.089846372604370117e-01 3.222449720396980410e-07 3.720740601420402527e-02 6.075347959995269775e-02
1.000000000000000000e+04 3.834002465009689331e-02 6.914036720991134644e-02 3.254142701625823975e-01 1.402979563636108651e-07 3.720394894480705261e-02 5.562786757946014404e-02 3.834002465009689331e-02 6.914036720991134644e-02 3.254142701625823975e-01 1.402979563636108651e-07 3.720394894480705261e-02 5.562786757946014404e-02
