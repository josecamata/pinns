# learning_rate: 0.0024546725218845336
# num_dense_layers: 7
# num_dense_nodes: 120
# activation:sin 
# batch_size: 32
# final loss: 0.43503111600875854
# Training Time: 140.71722221374512
# Best Step: 9000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 4.562785625457763672e+00 4.380631256103515625e+01 1.536214202642440796e-01 2.862598048523068428e-03 1.488775908946990967e-01 4.480375945568084717e-01 4.516083240509033203e+00 4.380631256103515625e+01 1.536214202642440796e-01 2.862598048523068428e-03 1.488775908946990967e-01 4.480375945568084717e-01
1.000000000000000000e+03 8.572285622358322144e-02 2.583516836166381836e-01 4.784038960933685303e-01 1.469062135583953932e-05 3.443895578384399414e-01 3.150127232074737549e-01 3.413791581988334656e-02 2.583516836166381836e-01 4.784038960933685303e-01 1.469062135583953932e-05 3.443895578384399414e-01 3.150127232074737549e-01
2.000000000000000000e+03 1.058171987533569336e-01 1.627713590860366821e-01 3.217739164829254150e-01 4.646518391382414848e-06 2.465094476938247681e-01 1.303022801876068115e-01 2.951876632869243622e-02 1.627713590860366821e-01 3.217739164829254150e-01 4.646518391382414848e-06 2.465094476938247681e-01 1.303022801876068115e-01
3.000000000000000000e+03 1.023680642247200012e-01 2.415293604135513306e-01 3.927990198135375977e-01 1.011183849186636508e-04 2.667947411537170410e-01 2.226479798555374146e-01 1.692484319210052490e-02 2.415293604135513306e-01 3.927990198135375977e-01 1.011183849186636508e-04 2.667947411537170410e-01 2.226479798555374146e-01
4.000000000000000000e+03 5.534849315881729126e-02 1.337440311908721924e-01 1.699984967708587646e-01 9.009822861116845161e-06 1.037677004933357239e-01 1.046315655112266541e-01 1.301552262157201767e-02 1.337440311908721924e-01 1.699984967708587646e-01 9.009822861116845161e-06 1.037677004933357239e-01 1.046315655112266541e-01
5.000000000000000000e+03 8.992755413055419922e-02 3.360694050788879395e-01 3.717239499092102051e-01 1.825178878789301962e-05 1.954434663057327271e-01 4.459652006626129150e-01 3.674755990505218506e-02 3.360694050788879395e-01 3.717239499092102051e-01 1.825178878789301962e-05 1.954434663057327271e-01 4.459652006626129150e-01
6.000000000000000000e+03 5.484818294644355774e-02 3.659016191959381104e-01 1.634044498205184937e-01 4.258466105966363102e-06 4.973286390304565430e-02 6.904403865337371826e-02 6.378013640642166138e-03 3.659016191959381104e-01 1.634044498205184937e-01 4.258466105966363102e-06 4.973286390304565430e-02 6.904403865337371826e-02
7.000000000000000000e+03 5.362394079566001892e-02 2.013319432735443115e-01 1.785131841897964478e-01 1.292931028729071841e-05 1.363730281591415405e-01 9.539280086755752563e-02 7.784290239214897156e-03 2.013319432735443115e-01 1.785131841897964478e-01 1.292931028729071841e-05 1.363730281591415405e-01 9.539280086755752563e-02
8.000000000000000000e+03 9.813962876796722412e-02 1.767440885305404663e-01 1.451041698455810547e-01 9.948204933607485145e-06 1.433477550745010376e-01 7.081110775470733643e-02 1.481153443455696106e-02 1.767440885305404663e-01 1.451041698455810547e-01 9.948204933607485145e-06 1.433477550745010376e-01 7.081110775470733643e-02
9.000000000000000000e+03 1.109046190977096558e-01 1.606822013854980469e-01 7.959741353988647461e-02 5.679950845660641789e-06 6.879842281341552734e-02 1.047591120004653931e-01 2.118828706443309784e-02 1.606822013854980469e-01 7.959741353988647461e-02 5.679950845660641789e-06 6.879842281341552734e-02 1.047591120004653931e-01
1.000000000000000000e+04 6.145314127206802368e-02 1.972126364707946777e-01 1.911947727203369141e-01 1.210315986099885777e-05 1.428405046463012695e-01 2.215345799922943115e-01 1.508264057338237762e-02 1.972126364707946777e-01 1.911947727203369141e-01 1.210315986099885777e-05 1.428405046463012695e-01 2.215345799922943115e-01
