# learning_rate: 0.0024869696877258787
# num_dense_layers: 7
# num_dense_nodes: 10
# activation:tanh 
# batch_size: 32
# final loss: 0.7201741933822632
# Training Time: 98.65987730026245
# Best Step: 10000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 1.777761243283748627e-02 5.378625869750976562e+01 8.111131377518177032e-03 3.531700713210739195e-05 1.513886731117963791e-02 2.064792998135089874e-02 2.374403923749923706e-02 5.378625869750976562e+01 8.111131377518177032e-03 3.531700713210739195e-05 1.513886637985706329e-02 2.064792998135089874e-02
1.000000000000000000e+03 4.761161655187606812e-02 1.631594449281692505e-01 3.965047001838684082e-01 1.930252437887247652e-05 3.092043697834014893e-01 2.149154245853424072e-01 5.589136108756065369e-02 1.631593406200408936e-01 3.965047597885131836e-01 1.930246435222215950e-05 3.092043399810791016e-01 2.149155139923095703e-01
2.000000000000000000e+03 4.024489223957061768e-02 1.559158265590667725e-01 3.604286611080169678e-01 1.641710696276277304e-06 2.811429500579833984e-01 1.185044050216674805e-01 4.284997284412384033e-02 1.559156924486160278e-01 3.604286313056945801e-01 1.641714902689273003e-06 2.811428904533386230e-01 1.185044273734092712e-01
3.000000000000000000e+03 5.099080875515937805e-02 1.073511466383934021e-01 3.907032310962677002e-01 7.459152584488037974e-07 3.034341931343078613e-01 1.042637601494789124e-01 2.867573685944080353e-02 1.073514819145202637e-01 3.907032608985900879e-01 7.459116773134155665e-07 3.034341335296630859e-01 1.042636558413505554e-01
4.000000000000000000e+03 3.949933871626853943e-02 9.751084446907043457e-02 3.673024475574493408e-01 2.556909128870188397e-09 2.881998121738433838e-01 8.811848610639572144e-02 2.472988516092300415e-02 9.751068055629730225e-02 3.673026859760284424e-01 2.556877598536289042e-09 2.881998717784881592e-01 8.811847120523452759e-02
5.000000000000000000e+03 4.209495708346366882e-02 8.569318801164627075e-02 3.691090047359466553e-01 3.824752639047801495e-06 2.934118807315826416e-01 8.479727804660797119e-02 2.387252449989318848e-02 8.569273352622985840e-02 3.691092729568481445e-01 3.824769919447135180e-06 2.934119105339050293e-01 8.479737490415573120e-02
6.000000000000000000e+03 4.665165022015571594e-02 9.194630384445190430e-02 3.426427245140075684e-01 2.182937578254495747e-06 2.739431560039520264e-01 7.777538150548934937e-02 1.885563693940639496e-02 9.194564819335937500e-02 3.426429629325866699e-01 2.182936668759793974e-06 2.739432156085968018e-01 7.777534425258636475e-02
7.000000000000000000e+03 5.325476452708244324e-02 7.285585999488830566e-02 3.444141745567321777e-01 2.320453944548717118e-07 2.785986065864562988e-01 8.051289618015289307e-02 1.638452149927616119e-02 7.285603880882263184e-02 3.444142639636993408e-01 2.320456218285471550e-07 2.785985767841339111e-01 8.051279932260513306e-02
8.000000000000000000e+03 5.122686922550201416e-02 7.675477862358093262e-02 3.299486339092254639e-01 2.024835943359448720e-08 2.683735489845275879e-01 7.523598521947860718e-02 1.804090850055217743e-02 7.675480097532272339e-02 3.299486637115478516e-01 2.024759204743986629e-08 2.683735489845275879e-01 7.523611932992935181e-02
9.000000000000000000e+03 5.605052039027214050e-02 6.422343850135803223e-02 3.244636058807373047e-01 4.727555449335341109e-07 2.696928679943084717e-01 8.332256972789764404e-02 1.937207765877246857e-02 6.422336399555206299e-02 3.244638144969940186e-01 4.727539533178060083e-07 2.696928679943084717e-01 8.332267403602600098e-02
1.000000000000000000e+04 5.748628824949264526e-02 1.010276377201080322e-01 2.894396185874938965e-01 4.457372995148034533e-07 2.407218813896179199e-01 6.407123059034347534e-02 2.491357736289501190e-02 1.010273098945617676e-01 2.894396483898162842e-01 4.457393458778824424e-07 2.407219409942626953e-01 6.407131254673004150e-02
