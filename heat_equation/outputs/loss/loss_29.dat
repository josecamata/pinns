# learning_rate: 0.001
# num_dense_layers: 8
# num_dense_nodes: 50
# activation:tanh 
# batch_size: 32
# final loss: 0.5513957142829895
# Training Time: 101.51778793334961
# Best Step: 9000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 5.184823274612426758e-01 5.615669631958007812e+01 8.965804427862167358e-02 2.275245060445740819e-04 2.201453968882560730e-02 1.857413500547409058e-01 5.184823274612426758e-01 5.615669631958007812e+01 8.965804427862167358e-02 2.275245060445740819e-04 2.201453968882560730e-02 1.857413500547409058e-01
1.000000000000000000e+03 4.180635884404182434e-02 2.132204622030258179e-01 4.814535677433013916e-01 1.886847371679323260e-06 3.282890021800994873e-01 2.956046462059020996e-01 4.180635884404182434e-02 2.132204622030258179e-01 4.814535677433013916e-01 1.886847371679323260e-06 3.282890021800994873e-01 2.956046462059020996e-01
2.000000000000000000e+03 3.749616816639900208e-02 1.336535960435867310e-01 3.477723002433776855e-01 9.806126399780623615e-07 2.649437785148620605e-01 1.196644529700279236e-01 3.749616816639900208e-02 1.336535960435867310e-01 3.477723002433776855e-01 9.806126399780623615e-07 2.649437785148620605e-01 1.196644529700279236e-01
3.000000000000000000e+03 6.320542842149734497e-02 2.153534889221191406e-01 3.100705742835998535e-01 5.417136321739235427e-07 2.306267619132995605e-01 8.262754976749420166e-02 6.320542842149734497e-02 2.153534889221191406e-01 3.100705742835998535e-01 5.417136321739235427e-07 2.306267619132995605e-01 8.262754976749420166e-02
4.000000000000000000e+03 5.328254029154777527e-02 7.476335763931274414e-02 3.660643696784973145e-01 3.931870651285862550e-07 2.493153363466262817e-01 1.086837127804756165e-01 5.328254029154777527e-02 7.476335763931274414e-02 3.660643696784973145e-01 3.931870651285862550e-07 2.493153363466262817e-01 1.086837127804756165e-01
5.000000000000000000e+03 3.489105030894279480e-02 1.033126413822174072e-01 3.429313302040100098e-01 4.453202961940405658e-07 1.435783505439758301e-01 9.053842723369598389e-02 3.489105030894279480e-02 1.033126413822174072e-01 3.429313302040100098e-01 4.453202961940405658e-07 1.435783505439758301e-01 9.053842723369598389e-02
6.000000000000000000e+03 3.324119001626968384e-02 2.184504866600036621e-01 2.959721684455871582e-01 1.596812012394366320e-06 6.742881238460540771e-02 5.661488324403762817e-02 3.324119001626968384e-02 2.184504866600036621e-01 2.959721684455871582e-01 1.596812012394366320e-06 6.742881238460540771e-02 5.661488324403762817e-02
7.000000000000000000e+03 4.323704540729522705e-02 1.195716708898544312e-01 3.754885494709014893e-01 4.221685401262220694e-07 7.066453248262405396e-02 1.132072061300277710e-01 4.323704540729522705e-02 1.195716708898544312e-01 3.754885494709014893e-01 4.221685401262220694e-07 7.066453248262405396e-02 1.132072061300277710e-01
8.000000000000000000e+03 7.900618016719818115e-02 2.738330364227294922e-01 2.800371348857879639e-01 4.371795512270182371e-06 3.918870911002159119e-02 3.756112605333328247e-02 7.900618016719818115e-02 2.738330364227294922e-01 2.800371348857879639e-01 4.371795512270182371e-06 3.918870911002159119e-02 3.756112605333328247e-02
9.000000000000000000e+03 5.384421721100807190e-02 1.313883513212203979e-01 2.783753573894500732e-01 1.504789338468981441e-06 3.507560119032859802e-02 5.271069332957267761e-02 5.384421721100807190e-02 1.313883513212203979e-01 2.783753573894500732e-01 1.504789338468981441e-06 3.507560119032859802e-02 5.271069332957267761e-02
1.000000000000000000e+04 8.953501284122467041e-02 2.968060374259948730e-01 2.484672665596008301e-01 1.489840883550641593e-06 1.967682503163814545e-02 2.820866368710994720e-02 8.953501284122467041e-02 2.968060374259948730e-01 2.484672665596008301e-01 1.489840883550641593e-06 1.967682503163814545e-02 2.820866368710994720e-02
