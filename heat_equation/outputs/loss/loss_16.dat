# learning_rate: 0.001361916743043298
# num_dense_layers: 10
# num_dense_nodes: 10
# activation:tanh 
# batch_size: 32
# final loss: 0.7883715629577637
# Training Time: 128.11196422576904
# Best Step: 10000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 2.713571548461914062e+01 2.952169418334960938e+01 1.197604656219482422e+00 1.418359763920307159e-02 1.448952913284301758e+00 7.361704111099243164e-02 1.812258338928222656e+01 2.952169799804687500e+01 1.197604775428771973e+00 1.418359857052564621e-02 1.448952913284301758e+00 7.361704111099243164e-02
1.000000000000000000e+03 7.392574101686477661e-02 1.645818799734115601e-01 4.855442643165588379e-01 6.182886863825842738e-05 3.420431911945343018e-01 3.612136542797088623e-01 1.461254712194204330e-02 1.645820140838623047e-01 4.855442047119140625e-01 6.182890501804649830e-05 3.420431613922119141e-01 3.612137436866760254e-01
2.000000000000000000e+03 5.849497392773628235e-02 2.473235577344894409e-01 3.551995754241943359e-01 1.504715328337624669e-06 2.614256739616394043e-01 1.881901025772094727e-01 4.429475590586662292e-02 2.473236471414566040e-01 3.551993370056152344e-01 1.504738975199870765e-06 2.614256441593170166e-01 1.881902664899826050e-01
3.000000000000000000e+03 4.190504923462867737e-02 1.765280216932296753e-01 3.574873805046081543e-01 5.654682126987609081e-07 2.714495658874511719e-01 1.281935423612594604e-01 1.993934437632560730e-02 1.765284389257431030e-01 3.574876785278320312e-01 5.654438268720696215e-07 2.714495062828063965e-01 1.281935721635818481e-01
4.000000000000000000e+03 4.264667257666587830e-02 9.817658364772796631e-02 3.783182799816131592e-01 2.766356885786080966e-07 2.883517146110534668e-01 1.086635887622833252e-01 1.894007809460163116e-02 9.817682206630706787e-02 3.783185482025146484e-01 2.766403213172452524e-07 2.883516550064086914e-01 1.086636781692504883e-01
5.000000000000000000e+03 4.717270657420158386e-02 9.652414172887802124e-02 3.811244666576385498e-01 2.473773292877012864e-07 2.959223389625549316e-01 8.115697652101516724e-02 1.398849673569202423e-02 9.652435779571533203e-02 3.811246752738952637e-01 2.473780682521464769e-07 2.959224283695220947e-01 8.115711063146591187e-02
6.000000000000000000e+03 3.403221815824508667e-02 1.250639259815216064e-01 3.527244031429290771e-01 3.120585176930035232e-07 2.785031795501708984e-01 5.924669653177261353e-02 1.826823130249977112e-02 1.250641793012619019e-01 3.527244925498962402e-01 3.120590861271921312e-07 2.785031795501708984e-01 5.924673750996589661e-02
7.000000000000000000e+03 5.487675592303276062e-02 9.393802285194396973e-02 3.694549798965454102e-01 3.549456550899776630e-07 2.856990993022918701e-01 6.527886539697647095e-02 1.433351729065179825e-02 9.393765777349472046e-02 3.694549798965454102e-01 3.549507425759657053e-07 2.856990098953247070e-01 6.527893245220184326e-02
8.000000000000000000e+03 3.951184451580047607e-02 9.154848754405975342e-02 3.706574440002441406e-01 6.403481620509410277e-07 2.883899211883544922e-01 6.606111675500869751e-02 1.431606803089380264e-02 9.154823422431945801e-02 3.706578314304351807e-01 6.403514021258160938e-07 2.883899211883544922e-01 6.606119871139526367e-02
9.000000000000000000e+03 3.605150058865547180e-02 1.586965620517730713e-01 3.298899531364440918e-01 3.862749622385308612e-07 2.567287087440490723e-01 4.637600854039192200e-02 1.815745048224925995e-02 1.586970686912536621e-01 3.298896253108978271e-01 3.862710968860483263e-07 2.567286789417266846e-01 4.637598246335983276e-02
1.000000000000000000e+04 3.919924050569534302e-02 1.354538649320602417e-01 3.306959867477416992e-01 7.231853373923513573e-07 2.579485774040222168e-01 4.645938053727149963e-02 1.781262643635272980e-02 1.354542076587677002e-01 3.306959867477416992e-01 7.231745939861866646e-07 2.579485177993774414e-01 4.645946994423866272e-02
