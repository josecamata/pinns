# learning_rate: 0.001
# num_dense_layers: 8
# num_dense_nodes: 60
# activation:tanh 
# batch_size: 32
# final loss: 0.5199894905090332
# Training Time: 100.81598377227783
# Best Step: 7000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 8.652822971343994141e-01 4.422798156738281250e+01 8.995277434587478638e-02 3.038016438949853182e-04 2.920115739107131958e-02 2.086191177368164062e-01 8.652822971343994141e-01 4.422798156738281250e+01 8.995277434587478638e-02 3.038016438949853182e-04 2.920115739107131958e-02 2.086191177368164062e-01
1.000000000000000000e+03 3.330200538039207458e-02 1.423886418342590332e-01 4.260056316852569580e-01 7.170634489739313722e-06 3.056968450546264648e-01 2.604150772094726562e-01 3.330200538039207458e-02 1.423886418342590332e-01 4.260056316852569580e-01 7.170634489739313722e-06 3.056968450546264648e-01 2.604150772094726562e-01
2.000000000000000000e+03 3.611676394939422607e-02 4.554061591625213623e-01 3.005867600440979004e-01 2.189247652495396324e-06 2.326804101467132568e-01 8.401686698198318481e-02 3.611676394939422607e-02 4.554061591625213623e-01 3.005867600440979004e-01 2.189247652495396324e-06 2.326804101467132568e-01 8.401686698198318481e-02
3.000000000000000000e+03 4.101403430104255676e-02 5.754286646842956543e-01 2.813788056373596191e-01 1.107991920434869826e-06 2.192698717117309570e-01 5.555798858404159546e-02 4.101403430104255676e-02 5.754286646842956543e-01 2.813788056373596191e-01 1.107991920434869826e-06 2.192698717117309570e-01 5.555798858404159546e-02
4.000000000000000000e+03 6.698471307754516602e-02 9.171882271766662598e-02 3.821383118629455566e-01 2.184039686881078524e-07 2.641429007053375244e-01 1.194391250610351562e-01 6.698471307754516602e-02 9.171882271766662598e-02 3.821383118629455566e-01 2.184039686881078524e-07 2.641429007053375244e-01 1.194391250610351562e-01
5.000000000000000000e+03 8.406853675842285156e-02 2.027547210454940796e-01 2.862055897712707520e-01 3.004635971137759043e-07 1.650863140821456909e-01 7.998678833246231079e-02 8.406853675842285156e-02 2.027547210454940796e-01 2.862055897712707520e-01 3.004635971137759043e-07 1.650863140821456909e-01 7.998678833246231079e-02
6.000000000000000000e+03 5.174417048692703247e-02 8.327685296535491943e-02 3.166207373142242432e-01 2.539435115522792330e-07 1.071841642260551453e-01 9.470900148153305054e-02 5.174417048692703247e-02 8.327685296535491943e-02 3.166207373142242432e-01 2.539435115522792330e-07 1.071841642260551453e-01 9.470900148153305054e-02
7.000000000000000000e+03 5.175325646996498108e-02 7.363718748092651367e-02 2.255206257104873657e-01 1.523514470136433374e-06 8.886633813381195068e-02 8.021054416894912720e-02 5.175325646996498108e-02 7.363718748092651367e-02 2.255206257104873657e-01 1.523514470136433374e-06 8.886633813381195068e-02 8.021054416894912720e-02
8.000000000000000000e+03 4.288248345255851746e-02 3.211031556129455566e-01 1.063925623893737793e-01 6.795613444410264492e-06 3.623067587614059448e-02 4.008248075842857361e-02 4.288248345255851746e-02 3.211031556129455566e-01 1.063925623893737793e-01 6.795613444410264492e-06 3.623067587614059448e-02 4.008248075842857361e-02
9.000000000000000000e+03 4.501854255795478821e-02 1.174831762909889221e-01 3.181474804878234863e-01 2.209464582847431302e-06 6.288270652294158936e-02 5.848505347967147827e-02 4.501854255795478821e-02 1.174831762909889221e-01 3.181474804878234863e-01 2.209464582847431302e-06 6.288270652294158936e-02 5.848505347967147827e-02
1.000000000000000000e+04 4.771464318037033081e-02 1.131200715899467468e-01 3.233590424060821533e-01 1.928817027874174528e-06 5.304190889000892639e-02 9.752894937992095947e-02 4.771464318037033081e-02 1.131200715899467468e-01 3.233590424060821533e-01 1.928817027874174528e-06 5.304190889000892639e-02 9.752894937992095947e-02
