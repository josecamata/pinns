# learning_rate: 0.0023558574342577103
# num_dense_layers: 7
# num_dense_nodes: 120
# activation:sin 
# batch_size: 32
# final loss: 0.3164675831794739
# Training Time: 140.59740948677063
# Best Step: 7000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 5.569731444120407104e-02 4.790652465820312500e+01 4.723700508475303650e-02 1.900685456348583102e-04 2.191753312945365906e-02 3.690278530120849609e-02 6.131024658679962158e-02 4.790652465820312500e+01 4.723700508475303650e-02 1.900685456348583102e-04 2.191753312945365906e-02 3.690278530120849609e-02
1.000000000000000000e+03 8.052589744329452515e-02 1.303107589483261108e-01 3.640442490577697754e-01 1.206244451168458909e-05 2.741364240646362305e-01 2.362892478704452515e-01 2.886132895946502686e-02 1.303107589483261108e-01 3.640442490577697754e-01 1.206244451168458909e-05 2.741364240646362305e-01 2.362892478704452515e-01
2.000000000000000000e+03 2.209382802248001099e-01 2.997182309627532959e-01 2.783312797546386719e-01 1.735852856654673815e-05 2.001533806324005127e-01 1.289085447788238525e-01 1.779698953032493591e-02 2.997182309627532959e-01 2.783312797546386719e-01 1.735852856654673815e-05 2.001533806324005127e-01 1.289085447788238525e-01
3.000000000000000000e+03 5.860724300146102905e-02 1.356105208396911621e-01 2.656521201133728027e-01 9.577457603882066905e-06 1.774588972330093384e-01 1.203101575374603271e-01 1.032096613198518753e-02 1.356105208396911621e-01 2.656521201133728027e-01 9.577457603882066905e-06 1.774588972330093384e-01 1.203101575374603271e-01
4.000000000000000000e+03 2.335058301687240601e-01 1.900801807641983032e-01 2.753156423568725586e-01 2.066075103357434273e-05 8.071011304855346680e-02 3.660537302494049072e-01 2.166635729372501373e-02 1.900801807641983032e-01 2.753156423568725586e-01 2.066075103357434273e-05 8.071011304855346680e-02 3.660537302494049072e-01
5.000000000000000000e+03 1.298679709434509277e-01 1.392040699720382690e-01 9.868530929088592529e-02 1.437862351849616971e-06 5.400612577795982361e-02 1.191826686263084412e-01 5.877029616385698318e-03 1.392040699720382690e-01 9.868530929088592529e-02 1.437862351849616971e-06 5.400612577795982361e-02 1.191826686263084412e-01
6.000000000000000000e+03 1.294977664947509766e-01 1.682749688625335693e-01 2.785512208938598633e-01 4.647644345823209733e-06 1.509600728750228882e-01 1.290374547243118286e-01 2.592178620398044586e-02 1.682749688625335693e-01 2.785512208938598633e-01 4.647644345823209733e-06 1.509600728750228882e-01 1.290374547243118286e-01
7.000000000000000000e+03 3.429276496171951294e-02 8.760500699281692505e-02 9.283322840929031372e-02 6.869335038572899066e-07 5.195243656635284424e-02 7.883116602897644043e-02 5.245048087090253830e-03 8.760500699281692505e-02 9.283322840929031372e-02 6.869335038572899066e-07 5.195243656635284424e-02 7.883116602897644043e-02
8.000000000000000000e+03 4.487631842494010925e-02 7.293198257684707642e-02 1.329989433288574219e-01 2.729948619162314571e-06 6.005816534161567688e-02 1.061661615967750549e-01 1.067823730409145355e-02 7.293198257684707642e-02 1.329989433288574219e-01 2.729948619162314571e-06 6.005816534161567688e-02 1.061661615967750549e-01
9.000000000000000000e+03 1.262347698211669922e-01 1.124698296189308167e-01 2.746171653270721436e-01 6.426816412385960575e-07 2.775723636150360107e-01 9.667491167783737183e-02 2.273926883935928345e-02 1.124698296189308167e-01 2.746171653270721436e-01 6.426816412385960575e-07 2.775723636150360107e-01 9.667491167783737183e-02
1.000000000000000000e+04 7.835479080677032471e-02 2.355264425277709961e-01 1.422772109508514404e-01 3.465391046120203100e-06 4.246737062931060791e-02 8.937616646289825439e-02 1.427082065492868423e-02 2.355264425277709961e-01 1.422772109508514404e-01 3.465391046120203100e-06 4.246737062931060791e-02 8.937616646289825439e-02
