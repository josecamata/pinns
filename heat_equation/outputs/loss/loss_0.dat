# learning_rate: 0.001
# num_dense_layers: 5
# num_dense_nodes: 60
# activation:tanh 
# batch_size: 32
# final loss: 0.5519546270370483
# Training Time: 74.26320815086365
# Best Step: 10000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 1.619050621986389160e+00 4.436780166625976562e+01 2.975510954856872559e-01 3.468801965937018394e-03 9.025868773460388184e-02 2.185682356357574463e-01 1.619050621986389160e+00 4.436780166625976562e+01 2.975510954856872559e-01 3.468801965937018394e-03 9.025868773460388184e-02 2.185682356357574463e-01
1.000000000000000000e+03 6.394752860069274902e-02 2.552959024906158447e-01 4.022826552391052246e-01 2.829737495630979538e-04 3.023892939090728760e-01 3.829529881477355957e-01 6.394752860069274902e-02 2.552959024906158447e-01 4.022826552391052246e-01 2.829737495630979538e-04 3.023892939090728760e-01 3.829529881477355957e-01
2.000000000000000000e+03 1.119799241423606873e-01 7.748113274574279785e-01 2.876688838005065918e-01 1.465407985961064696e-04 2.287170290946960449e-01 1.594457030296325684e-01 1.119799241423606873e-01 7.748113274574279785e-01 2.876688838005065918e-01 1.465407985961064696e-04 2.287170290946960449e-01 1.594457030296325684e-01
3.000000000000000000e+03 5.453789606690406799e-02 3.257433474063873291e-01 3.114269971847534180e-01 3.737884253496304154e-05 2.448433488607406616e-01 1.311026364564895630e-01 5.453789606690406799e-02 3.257433474063873291e-01 3.114269971847534180e-01 3.737884253496304154e-05 2.448433488607406616e-01 1.311026364564895630e-01
4.000000000000000000e+03 5.359432101249694824e-02 1.154968142509460449e-01 3.771302103996276855e-01 8.318736036017071456e-06 2.878322899341583252e-01 1.393437534570693970e-01 5.359432101249694824e-02 1.154968142509460449e-01 3.771302103996276855e-01 8.318736036017071456e-06 2.878322899341583252e-01 1.393437534570693970e-01
5.000000000000000000e+03 5.733115971088409424e-02 1.090099662542343140e-01 3.359106183052062988e-01 5.564200819208053872e-06 2.506626844406127930e-01 1.040260195732116699e-01 5.733115971088409424e-02 1.090099662542343140e-01 3.359106183052062988e-01 5.564200819208053872e-06 2.506626844406127930e-01 1.040260195732116699e-01
6.000000000000000000e+03 5.228710174560546875e-02 8.221136033535003662e-02 3.452074527740478516e-01 2.986200570376240648e-06 2.364427149295806885e-01 9.291104972362518311e-02 5.228710174560546875e-02 8.221136033535003662e-02 3.452074527740478516e-01 2.986200570376240648e-06 2.364427149295806885e-01 9.291104972362518311e-02
7.000000000000000000e+03 4.215176776051521301e-02 9.793244302272796631e-02 3.305463194847106934e-01 1.513893380433728453e-06 1.353916376829147339e-01 8.316677063703536987e-02 4.215176776051521301e-02 9.793244302272796631e-02 3.305463194847106934e-01 1.513893380433728453e-06 1.353916376829147339e-01 8.316677063703536987e-02
8.000000000000000000e+03 4.234652593731880188e-02 1.757338345050811768e-01 2.996041774749755859e-01 1.594821583239536267e-06 8.534125983715057373e-02 5.311270803213119507e-02 4.234652593731880188e-02 1.757338345050811768e-01 2.996041774749755859e-01 1.594821583239536267e-06 8.534125983715057373e-02 5.311270803213119507e-02
9.000000000000000000e+03 4.717129468917846680e-02 1.438918113708496094e-01 2.786763906478881836e-01 4.908089294985984452e-07 7.008728384971618652e-02 5.255601182579994202e-02 4.717129468917846680e-02 1.438918113708496094e-01 2.786763906478881836e-01 4.908089294985984452e-07 7.008728384971618652e-02 5.255601182579994202e-02
1.000000000000000000e+04 5.731236189603805542e-02 1.189060509204864502e-01 2.626858949661254883e-01 3.533609458372666268e-07 6.181742995977401733e-02 5.123251304030418396e-02 5.731236189603805542e-02 1.189060509204864502e-01 2.626858949661254883e-01 3.533609458372666268e-07 6.181742995977401733e-02 5.123251304030418396e-02
