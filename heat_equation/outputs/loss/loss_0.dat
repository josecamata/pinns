# learning_rate: 0.001
# num_dense_layers: 5
# num_dense_nodes: 60
# activation:tanh 
# batch_size: 32
# final loss: 0.5061624050140381
# Training Time: 77.26956605911255
# Best Step: 10000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 1.619050621986389160e+00 4.436780166625976562e+01 2.975510954856872559e-01 3.468801965937018394e-03 9.025868773460388184e-02 2.185682356357574463e-01 1.545866489410400391e+00 4.436780166625976562e+01 2.975510954856872559e-01 3.468802198767662048e-03 9.025868773460388184e-02 2.185682505369186401e-01
1.000000000000000000e+03 6.394752860069274902e-02 2.552959024906158447e-01 4.022826552391052246e-01 2.829737495630979538e-04 3.023892939090728760e-01 3.829529881477355957e-01 5.300359800457954407e-02 2.552959024906158447e-01 4.022824168205261230e-01 2.829738368745893240e-04 3.023893237113952637e-01 3.829529881477355957e-01
2.000000000000000000e+03 1.119799241423606873e-01 7.748113274574279785e-01 2.876688838005065918e-01 1.465407985961064696e-04 2.287170290946960449e-01 1.594457030296325684e-01 9.029689431190490723e-02 7.748111486434936523e-01 2.876688838005065918e-01 1.465407840441912413e-04 2.287170588970184326e-01 1.594457626342773438e-01
3.000000000000000000e+03 5.453789606690406799e-02 3.257433474063873291e-01 3.114269971847534180e-01 3.737884253496304154e-05 2.448433488607406616e-01 1.311026364564895630e-01 2.639056555926799774e-02 3.257431089878082275e-01 3.114269375801086426e-01 3.737884617294184864e-05 2.448433488607406616e-01 1.311026811599731445e-01
4.000000000000000000e+03 5.359432101249694824e-02 1.154968142509460449e-01 3.771302103996276855e-01 8.318736036017071456e-06 2.878322899341583252e-01 1.393437534570693970e-01 2.030646987259387970e-02 1.154967099428176880e-01 3.771302700042724609e-01 8.318724212585948408e-06 2.878322899341583252e-01 1.393437832593917847e-01
5.000000000000000000e+03 5.733115971088409424e-02 1.090099662542343140e-01 3.359106183052062988e-01 5.564200819208053872e-06 2.506626844406127930e-01 1.040260195732116699e-01 1.789395324885845184e-02 1.090101301670074463e-01 3.359105587005615234e-01 5.564193997997790575e-06 2.506627440452575684e-01 1.040261089801788330e-01
6.000000000000000000e+03 5.228710174560546875e-02 8.221136033535003662e-02 3.452074527740478516e-01 2.986200570376240648e-06 2.364427149295806885e-01 9.291104972362518311e-02 1.427210215479135513e-02 8.221129328012466431e-02 3.452075123786926270e-01 2.986207846333854832e-06 2.364427745342254639e-01 9.291109442710876465e-02
7.000000000000000000e+03 4.215176776051521301e-02 9.793244302272796631e-02 3.305463194847106934e-01 1.513893380433728453e-06 1.353916376829147339e-01 8.316677063703536987e-02 1.477964688092470169e-02 9.793245792388916016e-02 3.305462598800659180e-01 1.513895426796807442e-06 1.353916376829147339e-01 8.316672593355178833e-02
8.000000000000000000e+03 4.234652593731880188e-02 1.757338345050811768e-01 2.996041774749755859e-01 1.594821583239536267e-06 8.534125983715057373e-02 5.311270803213119507e-02 8.308293297886848450e-03 1.757337003946304321e-01 2.996042370796203613e-01 1.594836248841602355e-06 8.534125238656997681e-02 5.311272665858268738e-02
9.000000000000000000e+03 4.717129468917846680e-02 1.438918113708496094e-01 2.786763906478881836e-01 4.908089294985984452e-07 7.008728384971618652e-02 5.255601182579994202e-02 8.707729168236255646e-03 1.438917517662048340e-01 2.786762714385986328e-01 4.908143864668090828e-07 7.008728384971618652e-02 5.255593731999397278e-02
1.000000000000000000e+04 5.731236189603805542e-02 1.189060509204864502e-01 2.626858949661254883e-01 3.533609458372666268e-07 6.181742995977401733e-02 5.123251304030418396e-02 1.152031496167182922e-02 1.189060509204864502e-01 2.626858353614807129e-01 3.533574499670066871e-07 6.181742250919342041e-02 5.123246088624000549e-02
