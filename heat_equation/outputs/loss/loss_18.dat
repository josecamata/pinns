# learning_rate: 0.05
# num_dense_layers: 7
# num_dense_nodes: 20
# activation:sigmoid 
# batch_size: 32
# final loss: 0.4451504349708557
# Training Time: 96.44851899147034
# Best Step: 10000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 7.596737461312841333e-09 8.724431991577148438e+00 5.086106777191162109e+00 3.390761837363243103e-02 3.390532493591308594e+00 8.476415634155273438e+00 7.596737461312841333e-09 8.724431991577148438e+00 5.086106777191162109e+00 3.390761837363243103e-02 3.390532493591308594e+00 8.476415634155273438e+00
1.000000000000000000e+03 5.020961910486221313e-02 1.678988933563232422e-01 3.748211860656738281e-01 3.403200707907672040e-06 2.077170014381408691e-01 1.145848557353019714e-01 5.020961910486221313e-02 1.678988933563232422e-01 3.748211860656738281e-01 3.403200707907672040e-06 2.077170014381408691e-01 1.145848557353019714e-01
2.000000000000000000e+03 6.496225297451019287e-02 2.127882838249206543e-01 5.064862370491027832e-01 7.276952237589284778e-05 1.257472336292266846e-01 2.593129575252532959e-01 6.496225297451019287e-02 2.127882838249206543e-01 5.064862370491027832e-01 7.276952237589284778e-05 1.257472336292266846e-01 2.593129575252532959e-01
3.000000000000000000e+03 8.896995335817337036e-02 2.002295404672622681e-01 3.394681811332702637e-01 2.034374665527138859e-05 9.906590729951858521e-02 1.075284928083419800e-01 8.896995335817337036e-02 2.002295404672622681e-01 3.394681811332702637e-01 2.034374665527138859e-05 9.906590729951858521e-02 1.075284928083419800e-01
4.000000000000000000e+03 2.330178320407867432e-01 1.413266062736511230e-01 3.213484883308410645e-01 2.567864430602639914e-05 1.399777233600616455e-01 5.956231355667114258e-01 2.330178320407867432e-01 1.413266062736511230e-01 3.213484883308410645e-01 2.567864430602639914e-05 1.399777233600616455e-01 5.956231355667114258e-01
5.000000000000000000e+03 5.009450390934944153e-02 1.168439760804176331e-01 1.808283478021621704e-01 5.414917154666909482e-07 3.502784669399261475e-02 8.620715886354446411e-02 5.009450390934944153e-02 1.168439760804176331e-01 1.808283478021621704e-01 5.414917154666909482e-07 3.502784669399261475e-02 8.620715886354446411e-02
6.000000000000000000e+03 1.598463803529739380e-01 6.725506186485290527e-01 2.708885669708251953e-01 5.292042624205350876e-05 5.290304124355316162e-02 1.320682168006896973e-01 1.598463803529739380e-01 6.725506186485290527e-01 2.708885669708251953e-01 5.292042624205350876e-05 5.290304124355316162e-02 1.320682168006896973e-01
7.000000000000000000e+03 3.670770823955535889e-01 1.189012452960014343e-01 3.010762333869934082e-01 1.575786154717206955e-05 6.095457449555397034e-02 1.098286136984825134e-01 3.670770823955535889e-01 1.189012452960014343e-01 3.010762333869934082e-01 1.575786154717206955e-05 6.095457449555397034e-02 1.098286136984825134e-01
8.000000000000000000e+03 1.890877187252044678e-01 1.394299268722534180e-01 1.527822464704513550e-01 5.106866751702909824e-07 6.388562172651290894e-02 2.000100612640380859e-01 1.890877187252044678e-01 1.394299268722534180e-01 1.527822464704513550e-01 5.106866751702909824e-07 6.388562172651290894e-02 2.000100612640380859e-01
9.000000000000000000e+03 7.415514439344406128e-02 1.182512491941452026e-01 3.343624174594879150e-01 2.335482804483035579e-06 3.159616887569427490e-02 7.094459980726242065e-02 7.415514439344406128e-02 1.182512491941452026e-01 3.343624174594879150e-01 2.335482804483035579e-06 3.159616887569427490e-02 7.094459980726242065e-02
1.000000000000000000e+04 5.221330374479293823e-02 1.517163515090942383e-01 1.166607439517974854e-01 1.155702193500474095e-05 5.160236358642578125e-02 7.294610142707824707e-02 5.221330374479293823e-02 1.517163515090942383e-01 1.166607439517974854e-01 1.155702193500474095e-05 5.160236358642578125e-02 7.294610142707824707e-02
