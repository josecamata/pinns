# learning_rate: 0.006760995326061865
# num_dense_layers: 6
# num_dense_nodes: 10
# activation:Swish 
# batch_size: 32
# final loss: 0.7896790504455566
# Training Time: 121.27874445915222
# Best Step: 9000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 2.747611608356237411e-03 4.976930618286132812e+01 7.672436913708224893e-05 6.024098411216982640e-07 2.545669558458030224e-04 1.050997307174839079e-04 2.627207664772868156e-03 4.976930618286132812e+01 7.672436186112463474e-05 6.024097842782794032e-07 2.545670140534639359e-04 1.050997379934415221e-04
1.000000000000000000e+03 6.699676066637039185e-02 1.484319269657135010e-01 4.207190573215484619e-01 9.980604772863443941e-06 2.997181117534637451e-01 2.969183325767517090e-01 4.350318759679794312e-02 1.484318226575851440e-01 4.207193255424499512e-01 9.980615686799865216e-06 2.997181713581085205e-01 2.969184517860412598e-01
2.000000000000000000e+03 6.609828770160675049e-02 2.332495003938674927e-01 3.433275222778320312e-01 2.860503798274294240e-07 2.600720226764678955e-01 1.253287941217422485e-01 3.464260697364807129e-02 2.332494556903839111e-01 3.433276116847991943e-01 2.860506072011048673e-07 2.600720226764678955e-01 1.253287941217422485e-01
3.000000000000000000e+03 5.647729709744453430e-02 4.666838347911834717e-01 3.041365742683410645e-01 9.264199434255715460e-07 2.395199388265609741e-01 7.863644510507583618e-02 2.607518061995506287e-02 4.666820764541625977e-01 3.041366040706634521e-01 9.264223308491636999e-07 2.395199090242385864e-01 7.863649725914001465e-02
4.000000000000000000e+03 3.754132986068725586e-02 1.107610985636711121e-01 4.011770486831665039e-01 9.220162837664247490e-07 2.921141088008880615e-01 1.307504624128341675e-01 1.774627342820167542e-02 1.107610166072845459e-01 4.011771678924560547e-01 9.220157153322361410e-07 2.921142280101776123e-01 1.307504624128341675e-01
5.000000000000000000e+03 5.118215456604957581e-02 2.881045043468475342e-01 3.126925826072692871e-01 2.928130982127186144e-07 2.451195120811462402e-01 7.048325240612030029e-02 1.985584944486618042e-02 2.881039083003997803e-01 3.126927912235260010e-01 2.928128708390431711e-07 2.451196014881134033e-01 7.048330456018447876e-02
6.000000000000000000e+03 4.047028347849845886e-02 9.971483051776885986e-02 3.570359349250793457e-01 2.189712233757745707e-07 2.730291485786437988e-01 8.735317736864089966e-02 1.490470767021179199e-02 9.971415996551513672e-02 3.570361137390136719e-01 2.189729286783403950e-07 2.730291485786437988e-01 8.735319972038269043e-02
7.000000000000000000e+03 4.524187371134757996e-02 2.658965587615966797e-01 3.105557560920715332e-01 1.949491945651971037e-07 2.394397705793380737e-01 6.217054277658462524e-02 1.823024824261665344e-02 2.658962905406951904e-01 3.105556666851043701e-01 1.949475034734859946e-07 2.394397705793380737e-01 6.217051297426223755e-02
8.000000000000000000e+03 6.130648404359817505e-02 1.558462679386138916e-01 3.263217806816101074e-01 2.272199282060682890e-07 2.413936704397201538e-01 7.511691004037857056e-02 1.783333718776702881e-02 1.558462530374526978e-01 3.263216614723205566e-01 2.272208092790606315e-07 2.413935363292694092e-01 7.511685788631439209e-02
9.000000000000000000e+03 5.103269219398498535e-02 8.760686963796615601e-02 3.510487079620361328e-01 1.851546471698384266e-07 2.479497790336608887e-01 8.574926853179931641e-02 1.732411980628967285e-02 8.760683238506317139e-02 3.510488271713256836e-01 1.851536381991536473e-07 2.479498386383056641e-01 8.574929088354110718e-02
1.000000000000000000e+04 6.552100926637649536e-02 7.561367005109786987e-02 3.625236153602600098e-01 3.593965800519072218e-07 2.394116222858428955e-01 9.692256897687911987e-02 1.959430798888206482e-02 7.561380416154861450e-02 3.625235855579376221e-01 3.593968926907109562e-07 2.394117265939712524e-01 9.692247956991195679e-02
