# learning_rate: 0.0005
# num_dense_layers: 8
# num_dense_nodes: 20
# activation:sigmoid 
# batch_size: 32
# final loss: 0.8937565684318542
# Training Time: 104.54269075393677
# Best Step: 10000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 2.853345115738648019e-09 1.281705017089843750e+02 5.419376850128173828e+00 3.612842038273811340e-02 3.612723112106323242e+00 9.032162666320800781e+00 2.853345115738648019e-09 1.281705017089843750e+02 5.419376850128173828e+00 3.612842038273811340e-02 3.612723112106323242e+00 9.032162666320800781e+00
1.000000000000000000e+03 1.176360638055484742e-05 1.251253223419189453e+01 3.739262104034423828e+00 2.491807192564010620e-02 2.496352672576904297e+00 6.230610370635986328e+00 1.176360638055484742e-05 1.251253223419189453e+01 3.739262104034423828e+00 2.491807192564010620e-02 2.496352672576904297e+00 6.230610370635986328e+00
2.000000000000000000e+03 1.521632373332977295e-01 3.159237504005432129e-01 5.629616975784301758e-01 1.006515012704767287e-04 4.338347613811492920e-01 5.871151089668273926e-01 1.521632373332977295e-01 3.159237504005432129e-01 5.629616975784301758e-01 1.006515012704767287e-04 4.338347613811492920e-01 5.871151089668273926e-01
3.000000000000000000e+03 1.303236037492752075e-01 2.590083181858062744e-01 5.120476484298706055e-01 6.042188033461570740e-05 3.732014298439025879e-01 4.025914371013641357e-01 1.303236037492752075e-01 2.590083181858062744e-01 5.120476484298706055e-01 6.042188033461570740e-05 3.732014298439025879e-01 4.025914371013641357e-01
4.000000000000000000e+03 6.318181008100509644e-02 2.419057935476303101e-01 4.568067789077758789e-01 4.959922080161049962e-05 3.370670974254608154e-01 3.063021004199981689e-01 6.318181008100509644e-02 2.419057935476303101e-01 4.568067789077758789e-01 4.959922080161049962e-05 3.370670974254608154e-01 3.063021004199981689e-01
5.000000000000000000e+03 5.297529324889183044e-02 2.098154723644256592e-01 4.239641129970550537e-01 3.581679266062565148e-05 3.162173628807067871e-01 2.099391520023345947e-01 5.297529324889183044e-02 2.098154723644256592e-01 4.239641129970550537e-01 3.581679266062565148e-05 3.162173628807067871e-01 2.099391520023345947e-01
6.000000000000000000e+03 4.369748383760452271e-02 1.848181635141372681e-01 4.070066213607788086e-01 2.462354677845723927e-05 3.079597949981689453e-01 1.584426462650299072e-01 4.369748383760452271e-02 1.848181635141372681e-01 4.070066213607788086e-01 2.462354677845723927e-05 3.079597949981689453e-01 1.584426462650299072e-01
7.000000000000000000e+03 3.596447780728340149e-02 1.675473004579544067e-01 3.935585021972656250e-01 1.788742520147934556e-05 3.013503849506378174e-01 1.216936036944389343e-01 3.596447780728340149e-02 1.675473004579544067e-01 3.935585021972656250e-01 1.788742520147934556e-05 3.013503849506378174e-01 1.216936036944389343e-01
8.000000000000000000e+03 3.412290662527084351e-02 1.498617380857467651e-01 3.775552511215209961e-01 5.903937562834471464e-06 2.935554981231689453e-01 9.304859489202499390e-02 3.412290662527084351e-02 1.498617380857467651e-01 3.775552511215209961e-01 5.903937562834471464e-06 2.935554981231689453e-01 9.304859489202499390e-02
9.000000000000000000e+03 3.085628524422645569e-02 1.373539566993713379e-01 3.696854412555694580e-01 2.895304987760027871e-06 2.892581224441528320e-01 8.405079692602157593e-02 3.085628524422645569e-02 1.373539566993713379e-01 3.696854412555694580e-01 2.895304987760027871e-06 2.892581224441528320e-01 8.405079692602157593e-02
1.000000000000000000e+04 2.926899492740631104e-02 1.163079291582107544e-01 3.741068840026855469e-01 9.228108979186799843e-07 2.934442758560180664e-01 8.062756061553955078e-02 2.926899492740631104e-02 1.163079291582107544e-01 3.741068840026855469e-01 9.228108979186799843e-07 2.934442758560180664e-01 8.062756061553955078e-02
