# learning_rate: 0.004156039961915411
# num_dense_layers: 10
# num_dense_nodes: 120
# activation:Swish 
# batch_size: 32
# final loss: 0.26823848485946655
# Training Time: 308.40841126441956
# Best Step: 6000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 1.272049871658964548e-06 5.000614547729492188e+01 1.199894938963552704e-07 1.598660981372290735e-09 5.080476128682676062e-08 1.564447558166648378e-07 1.303382305195555091e-06 5.000614547729492188e+01 1.199894938963552704e-07 1.598660981372290735e-09 5.080476128682676062e-08 1.564447558166648378e-07
1.000000000000000000e+03 2.502911351621150970e-02 7.504248619079589844e-01 2.913581132888793945e-01 9.111245162785053253e-07 2.353208363056182861e-01 8.375294506549835205e-02 2.121762558817863464e-02 7.504248619079589844e-01 2.913581132888793945e-01 9.111245162785053253e-07 2.353208363056182861e-01 8.375294506549835205e-02
2.000000000000000000e+03 1.084972321987152100e-01 2.785144746303558350e-01 3.885835111141204834e-01 3.417719653953099623e-07 1.017146483063697815e-01 8.449450880289077759e-02 4.391665570437908173e-03 2.785144746303558350e-01 3.885835111141204834e-01 3.417719653953099623e-07 1.017146483063697815e-01 8.449450880289077759e-02
3.000000000000000000e+03 3.694273903965950012e-02 1.319500207901000977e-01 6.859485805034637451e-02 1.449695901101222262e-05 4.261742904782295227e-02 1.091644838452339172e-01 6.081259343773126602e-03 1.319500207901000977e-01 6.859485805034637451e-02 1.449695901101222262e-05 4.261742904782295227e-02 1.091644838452339172e-01
4.000000000000000000e+03 2.208126485347747803e-01 2.275406122207641602e-01 9.188310056924819946e-02 3.732985192073101643e-07 4.261433333158493042e-02 9.046459943056106567e-02 5.249235779047012329e-03 2.275406122207641602e-01 9.188310056924819946e-02 3.732985192073101643e-07 4.261433333158493042e-02 9.046459943056106567e-02
5.000000000000000000e+03 2.707166075706481934e-01 4.338144361972808838e-01 1.914677172899246216e-01 1.430780002920073457e-06 8.577553927898406982e-02 4.510326385498046875e-01 2.499232441186904907e-02 4.338144361972808838e-01 1.914677172899246216e-01 1.430780002920073457e-06 8.577553927898406982e-02 4.510326385498046875e-01
6.000000000000000000e+03 1.148043666034936905e-02 6.842270493507385254e-02 9.323714673519134521e-02 1.484955987507419195e-06 2.807459793984889984e-02 8.316172659397125244e-02 1.478614052757620811e-03 6.842270493507385254e-02 9.323714673519134521e-02 1.484955987507419195e-06 2.807459793984889984e-02 8.316172659397125244e-02
7.000000000000000000e+03 5.061233043670654297e-02 1.101020947098731995e-01 5.362998694181442261e-02 2.012863433265010826e-06 4.011847823858261108e-02 6.287412345409393311e-02 1.511791138909757137e-03 1.101020947098731995e-01 5.362998694181442261e-02 2.012863433265010826e-06 4.011847823858261108e-02 6.287412345409393311e-02
8.000000000000000000e+03 1.782147288322448730e-01 2.952088832855224609e+00 3.956242203712463379e-01 1.828861713875085115e-04 3.740380704402923584e-01 4.530750215053558350e-01 3.818348795175552368e-02 2.952088832855224609e+00 3.956242203712463379e-01 1.828861713875085115e-04 3.740380704402923584e-01 4.530750215053558350e-01
9.000000000000000000e+03 1.597585678100585938e-01 9.230125546455383301e-01 3.966157734394073486e-01 7.372416348516708240e-06 3.494970798492431641e-01 3.989404439926147461e-01 6.338143348693847656e-02 9.230125546455383301e-01 3.966157734394073486e-01 7.372416348516708240e-06 3.494970798492431641e-01 3.989404439926147461e-01
1.000000000000000000e+04 9.860584884881973267e-02 2.689097821712493896e-01 5.045369863510131836e-01 4.814920885110041127e-06 3.859509825706481934e-01 4.453965127468109131e-01 3.349330648779869080e-02 2.689097821712493896e-01 5.045369863510131836e-01 4.814920885110041127e-06 3.859509825706481934e-01 4.453965127468109131e-01
