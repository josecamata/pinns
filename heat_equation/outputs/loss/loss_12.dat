# learning_rate: 0.005
# num_dense_layers: 8
# num_dense_nodes: 50
# activation:Swish 
# batch_size: 32
# final loss: 0.23237627744674683
# Training Time: 141.53083109855652
# Best Step: 10000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 3.484103217488154769e-06 5.004333114624023438e+01 1.015058205666719005e-05 4.385503515891286952e-08 4.742829332826659083e-06 6.128180757514201105e-06 3.484103217488154769e-06 5.004333114624023438e+01 1.015058205666719005e-05 4.385503515891286952e-08 4.742829332826659083e-06 6.128180757514201105e-06
1.000000000000000000e+03 3.515724465250968933e-02 1.189939230680465698e-01 4.102446436882019043e-01 2.746962195487867575e-07 2.971245348453521729e-01 1.574605107307434082e-01 3.515724465250968933e-02 1.189939230680465698e-01 4.102446436882019043e-01 2.746962195487867575e-07 2.971245348453521729e-01 1.574605107307434082e-01
2.000000000000000000e+03 3.349587321281433105e-02 1.479366719722747803e-01 3.451263010501861572e-01 1.066150389306130819e-06 2.757595181465148926e-01 1.094508096575737000e-01 3.349587321281433105e-02 1.479366719722747803e-01 3.451263010501861572e-01 1.066150389306130819e-06 2.757595181465148926e-01 1.094508096575737000e-01
3.000000000000000000e+03 5.334715172648429871e-02 9.567108750343322754e-02 1.577066183090209961e-01 5.005181265005376190e-07 9.160204231739044189e-02 1.151007860898971558e-01 5.334715172648429871e-02 9.567108750343322754e-02 1.577066183090209961e-01 5.005181265005376190e-07 9.160204231739044189e-02 1.151007860898971558e-01
4.000000000000000000e+03 1.037451773881912231e-01 8.359188586473464966e-02 1.851106882095336914e-01 1.478793183196103200e-05 2.024261802434921265e-01 8.776414394378662109e-02 1.037451773881912231e-01 8.359188586473464966e-02 1.851106882095336914e-01 1.478793183196103200e-05 2.024261802434921265e-01 8.776414394378662109e-02
5.000000000000000000e+03 1.661817170679569244e-02 8.228750824928283691e-01 4.414954036474227905e-02 1.031374381454952527e-06 1.199018117040395737e-02 1.647718250751495361e-02 1.661817170679569244e-02 8.228750824928283691e-01 4.414954036474227905e-02 1.031374381454952527e-06 1.199018117040395737e-02 1.647718250751495361e-02
6.000000000000000000e+03 6.193695589900016785e-02 3.334120661020278931e-02 9.710998833179473877e-02 2.886621608411132911e-08 6.007711589336395264e-02 9.017093479633331299e-02 6.193695589900016785e-02 3.334120661020278931e-02 9.710998833179473877e-02 2.886621608411132911e-08 6.007711589336395264e-02 9.017093479633331299e-02
7.000000000000000000e+03 2.908259071409702301e-02 5.226732417941093445e-02 6.255348026752471924e-02 6.859927736968529643e-08 2.234438434243202209e-02 6.617845594882965088e-02 2.908259071409702301e-02 5.226732417941093445e-02 6.255348026752471924e-02 6.859927736968529643e-08 2.234438434243202209e-02 6.617845594882965088e-02
8.000000000000000000e+03 2.186571210622787476e-01 3.085416853427886963e-01 3.884992375969886780e-02 1.117377360060345381e-05 4.999137669801712036e-02 1.733772158622741699e-01 2.186571210622787476e-01 3.085416853427886963e-01 3.884992375969886780e-02 1.117377360060345381e-05 4.999137669801712036e-02 1.733772158622741699e-01
9.000000000000000000e+03 8.364588022232055664e-02 7.060497999191284180e-02 8.275708556175231934e-02 3.971222781729011331e-07 9.986959397792816162e-03 9.679188579320907593e-02 8.364588022232055664e-02 7.060497999191284180e-02 8.275708556175231934e-02 3.971222781729011331e-07 9.986959397792816162e-03 9.679188579320907593e-02
1.000000000000000000e+04 1.707912981510162354e-02 6.724594533443450928e-02 6.981488317251205444e-02 2.485885261194198392e-06 2.262680046260356903e-02 5.560701340436935425e-02 1.707912981510162354e-02 6.724594533443450928e-02 6.981488317251205444e-02 2.485885261194198392e-06 2.262680046260356903e-02 5.560701340436935425e-02
