# learning_rate: 0.005113651735102013
# num_dense_layers: 5
# num_dense_nodes: 49
# activation:Swish 
# batch_size: 32
# final loss: 0.15722055733203888
# Training Time: 102.75482130050659
# Best Step: 10000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 7.963546668179333210e-04 4.919073486328125000e+01 2.219432964920997620e-03 2.270464165121666156e-06 4.452686334843747318e-05 1.838162308558821678e-03 8.739213808439671993e-04 4.919073486328125000e+01 2.219432732090353966e-03 2.270464619869017042e-06 4.452686334843747318e-05 1.838162308558821678e-03
1.000000000000000000e+03 4.432392120361328125e-02 1.888628751039505005e-01 3.697741627693176270e-01 1.113073267333675176e-06 2.848840355873107910e-01 2.240894883871078491e-01 3.684095293283462524e-02 1.888627558946609497e-01 3.697741031646728516e-01 1.113073494707350619e-06 2.848840355873107910e-01 2.240894585847854614e-01
2.000000000000000000e+03 5.594930797815322876e-02 3.445372879505157471e-01 3.166653215885162354e-01 1.088450858333089855e-06 2.513903677463531494e-01 9.252291917800903320e-02 3.189526125788688660e-02 3.445375561714172363e-01 3.166654109954833984e-01 1.088451995201467071e-06 2.513903677463531494e-01 9.252290427684783936e-02
3.000000000000000000e+03 1.050842255353927612e-01 9.234679490327835083e-02 3.349627256393432617e-01 1.721320018077676650e-06 2.416896522045135498e-01 1.143286377191543579e-01 2.171450108289718628e-02 9.234675765037536621e-02 3.349628448486328125e-01 1.721322064440755639e-06 2.416896522045135498e-01 1.143286600708961487e-01
4.000000000000000000e+03 6.280975788831710815e-02 8.158583939075469971e-02 1.169928461313247681e-01 3.544695346135995351e-07 6.864139437675476074e-02 8.499564975500106812e-02 8.832572959363460541e-03 8.158585429191589355e-02 1.169930025935173035e-01 3.544695346135995351e-07 6.864139437675476074e-02 8.499567955732345581e-02
5.000000000000000000e+03 3.278929367661476135e-02 1.234074234962463379e-01 1.067730113863945007e-01 3.028680737315880833e-07 6.400754302740097046e-02 8.470170199871063232e-02 4.571260418742895126e-03 1.234073042869567871e-01 1.067731007933616638e-01 3.028681874184258049e-07 6.400755047798156738e-02 8.470167964696884155e-02
6.000000000000000000e+03 1.495459116995334625e-02 7.809505611658096313e-02 7.754421234130859375e-02 1.984526392106999992e-07 2.508931607007980347e-02 4.733497649431228638e-02 3.260744037106633186e-03 7.809510827064514160e-02 7.754417508840560913e-02 1.984525823672811384e-07 2.508931234478950500e-02 4.733498767018318176e-02
7.000000000000000000e+03 2.690304256975650787e-02 5.142014846205711365e-02 9.770441800355911255e-02 1.439125156821319251e-07 6.628122180700302124e-02 9.039214998483657837e-02 2.722899196669459343e-03 5.142019316554069519e-02 9.770430624485015869e-02 1.439125867364055011e-07 6.628122180700302124e-02 9.039213508367538452e-02
8.000000000000000000e+03 3.787547722458839417e-02 3.884958475828170776e-02 7.721632719039916992e-02 3.344528920479206135e-07 3.224520385265350342e-02 6.653750687837600708e-02 3.375830361619591713e-03 3.884949907660484314e-02 7.721649110317230225e-02 3.344529488913394744e-07 3.224519640207290649e-02 6.653747707605361938e-02
9.000000000000000000e+03 3.049505501985549927e-02 4.273429885506629944e-02 5.760730803012847900e-02 7.231168552834787988e-09 1.478301919996738434e-02 4.016494005918502808e-02 1.930841011926531792e-03 4.273435100913047791e-02 5.760733783245086670e-02 7.231166332388738738e-09 1.478301919996738434e-02 4.016501083970069885e-02
1.000000000000000000e+04 1.883441023528575897e-02 5.868007242679595947e-02 4.988617449998855591e-02 5.589601528299681377e-07 1.509981323033571243e-02 3.778263553977012634e-02 2.253961982205510139e-03 5.867988243699073792e-02 4.988617449998855591e-02 5.589601528299681377e-07 1.509981323033571243e-02 3.778269886970520020e-02
