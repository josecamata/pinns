# learning_rate: 0.005
# num_dense_layers: 3
# num_dense_nodes: 40
# activation:Swish 
# batch_size: 32
# final loss: 0.3732452690601349
# Training Time: 69.63967061042786
# Best Step: 10000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 3.257434070110321045e-02 5.185342407226562500e+01 2.135770395398139954e-02 3.187943366356194019e-05 1.515825861133635044e-03 2.139317430555820465e-02 3.257434070110321045e-02 5.185342407226562500e+01 2.135770395398139954e-02 3.187943366356194019e-05 1.515825861133635044e-03 2.139317430555820465e-02
1.000000000000000000e+03 9.595168381929397583e-02 2.889425456523895264e-01 3.846129477024078369e-01 7.027511310297995806e-05 3.054689764976501465e-01 4.563094079494476318e-01 9.595168381929397583e-02 2.889425456523895264e-01 3.846129477024078369e-01 7.027511310297995806e-05 3.054689764976501465e-01 4.563094079494476318e-01
2.000000000000000000e+03 7.344164699316024780e-02 1.703027039766311646e-01 4.178011417388916016e-01 6.596595540031557903e-06 3.006618618965148926e-01 3.124150335788726807e-01 7.344164699316024780e-02 1.703027039766311646e-01 4.178011417388916016e-01 6.596595540031557903e-06 3.006618618965148926e-01 3.124150335788726807e-01
3.000000000000000000e+03 3.422001749277114868e-02 1.575858443975448608e-01 3.915036618709564209e-01 1.437745686416747048e-05 2.896006107330322266e-01 2.365683168172836304e-01 3.422001749277114868e-02 1.575858443975448608e-01 3.915036618709564209e-01 1.437745686416747048e-05 2.896006107330322266e-01 2.365683168172836304e-01
4.000000000000000000e+03 3.615638241171836853e-02 1.587449759244918823e-01 3.637807369232177734e-01 1.339074788120342419e-05 2.667783498764038086e-01 1.805905550718307495e-01 3.615638241171836853e-02 1.587449759244918823e-01 3.637807369232177734e-01 1.339074788120342419e-05 2.667783498764038086e-01 1.805905550718307495e-01
5.000000000000000000e+03 4.792017489671707153e-02 1.525514125823974609e-01 3.538369238376617432e-01 1.698915912129450589e-05 2.215966582298278809e-01 1.538978517055511475e-01 4.792017489671707153e-02 1.525514125823974609e-01 3.538369238376617432e-01 1.698915912129450589e-05 2.215966582298278809e-01 1.538978517055511475e-01
6.000000000000000000e+03 1.315286457538604736e-01 1.626842916011810303e-01 3.139417171478271484e-01 1.238172262674197555e-05 9.283322095870971680e-02 1.347297281026840210e-01 1.315286457538604736e-01 1.626842916011810303e-01 3.139417171478271484e-01 1.238172262674197555e-05 9.283322095870971680e-02 1.347297281026840210e-01
7.000000000000000000e+03 5.564132705330848694e-02 1.399014890193939209e-01 2.081077992916107178e-01 2.754624574663466774e-06 6.851007789373397827e-02 1.198222711682319641e-01 5.564132705330848694e-02 1.399014890193939209e-01 2.081077992916107178e-01 2.754624574663466774e-06 6.851007789373397827e-02 1.198222711682319641e-01
8.000000000000000000e+03 1.567652672529220581e-01 1.642144173383712769e-01 1.358143389225006104e-01 1.352804702037246898e-05 5.309698730707168579e-02 1.056531295180320740e-01 1.567652672529220581e-01 1.642144173383712769e-01 1.358143389225006104e-01 1.352804702037246898e-05 5.309698730707168579e-02 1.056531295180320740e-01
9.000000000000000000e+03 4.598091915249824524e-02 1.316594779491424561e-01 1.152832657098770142e-01 1.999409505515359342e-06 4.568367823958396912e-02 9.051339328289031982e-02 4.598091915249824524e-02 1.316594779491424561e-01 1.152832657098770142e-01 1.999409505515359342e-06 4.568367823958396912e-02 9.051339328289031982e-02
1.000000000000000000e+04 2.985686063766479492e-02 1.290053576231002808e-01 9.849942475557327271e-02 6.461027055593149271e-07 3.699348121881484985e-02 7.888948917388916016e-02 2.985686063766479492e-02 1.290053576231002808e-01 9.849942475557327271e-02 6.461027055593149271e-07 3.699348121881484985e-02 7.888948917388916016e-02
