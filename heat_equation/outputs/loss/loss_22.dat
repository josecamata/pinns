# learning_rate: 0.001
# num_dense_layers: 8
# num_dense_nodes: 40
# activation:tanh 
# batch_size: 32
# final loss: 0.5305735468864441
# Training Time: 101.20915818214417
# Best Step: 10000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 2.153886079788208008e+00 7.074230957031250000e+01 2.177627682685852051e-01 7.678339025005698204e-04 1.305499523878097534e-01 9.651702642440795898e-01 2.153886079788208008e+00 7.074230957031250000e+01 2.177627682685852051e-01 7.678339025005698204e-04 1.305499523878097534e-01 9.651702642440795898e-01
1.000000000000000000e+03 3.446830064058303833e-02 1.758406013250350952e-01 3.814295828342437744e-01 1.378203160129487514e-05 2.906594276428222656e-01 2.091772109270095825e-01 3.446830064058303833e-02 1.758406013250350952e-01 3.814295828342437744e-01 1.378203160129487514e-05 2.906594276428222656e-01 2.091772109270095825e-01
2.000000000000000000e+03 2.945685759186744690e-02 1.285663545131683350e-01 3.694533109664916992e-01 5.933336524321930483e-07 2.896924316883087158e-01 1.227830275893211365e-01 2.945685759186744690e-02 1.285663545131683350e-01 3.694533109664916992e-01 5.933336524321930483e-07 2.896924316883087158e-01 1.227830275893211365e-01
3.000000000000000000e+03 2.546584606170654297e-02 1.115242615342140198e-01 3.696094751358032227e-01 6.666591048087866511e-07 2.948791980743408203e-01 9.102790802717208862e-02 2.546584606170654297e-02 1.115242615342140198e-01 3.696094751358032227e-01 6.666591048087866511e-07 2.948791980743408203e-01 9.102790802717208862e-02
4.000000000000000000e+03 3.619947656989097595e-02 1.097224801778793335e-01 3.716712296009063721e-01 1.529877636130549945e-06 2.883424758911132812e-01 9.583503007888793945e-02 3.619947656989097595e-02 1.097224801778793335e-01 3.716712296009063721e-01 1.529877636130549945e-06 2.883424758911132812e-01 9.583503007888793945e-02
5.000000000000000000e+03 4.494038596749305725e-02 8.807193487882614136e-02 3.391844630241394043e-01 2.697539230211987160e-06 2.552362084388732910e-01 7.827488332986831665e-02 4.494038596749305725e-02 8.807193487882614136e-02 3.391844630241394043e-01 2.697539230211987160e-06 2.552362084388732910e-01 7.827488332986831665e-02
6.000000000000000000e+03 4.994735494256019592e-02 7.531636953353881836e-02 3.298765420913696289e-01 6.905302143422886729e-07 2.433067858219146729e-01 7.455592602491378784e-02 4.994735494256019592e-02 7.531636953353881836e-02 3.298765420913696289e-01 6.905302143422886729e-07 2.433067858219146729e-01 7.455592602491378784e-02
7.000000000000000000e+03 4.611875489354133606e-02 8.802127838134765625e-02 3.144735991954803467e-01 1.717746584972701385e-07 2.151239514350891113e-01 7.037995010614395142e-02 4.611875489354133606e-02 8.802127838134765625e-02 3.144735991954803467e-01 1.717746584972701385e-07 2.151239514350891113e-01 7.037995010614395142e-02
8.000000000000000000e+03 5.193302780389785767e-02 1.284138709306716919e-01 2.986980676651000977e-01 1.437687160432687961e-06 1.641982942819595337e-01 5.632298439741134644e-02 5.193302780389785767e-02 1.284138709306716919e-01 2.986980676651000977e-01 1.437687160432687961e-06 1.641982942819595337e-01 5.632298439741134644e-02
9.000000000000000000e+03 5.192732065916061401e-02 4.719045162200927734e-01 2.439360618591308594e-01 3.559356684945669258e-07 8.552655577659606934e-02 2.745544165372848511e-02 5.192732065916061401e-02 4.719045162200927734e-01 2.439360618591308594e-01 3.559356684945669258e-07 8.552655577659606934e-02 2.745544165372848511e-02
1.000000000000000000e+04 4.676497355103492737e-02 8.181792497634887695e-02 2.664880156517028809e-01 4.501074215568223735e-07 7.613555341958999634e-02 5.936665832996368408e-02 4.676497355103492737e-02 8.181792497634887695e-02 2.664880156517028809e-01 4.501074215568223735e-07 7.613555341958999634e-02 5.936665832996368408e-02
