# learning_rate: 0.002396856313349922
# num_dense_layers: 7
# num_dense_nodes: 120
# activation:sin 
# batch_size: 32
# final loss: 0.3097837567329407
# Training Time: 140.63489842414856
# Best Step: 7000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 7.955693006515502930e-01 9.405550384521484375e+01 1.033025979995727539e+00 2.257369487779214978e-04 3.552170991897583008e-01 1.961823225021362305e+00 8.120846152305603027e-01 9.405550384521484375e+01 1.033025979995727539e+00 2.257369487779214978e-04 3.552170991897583008e-01 1.961823225021362305e+00
1.000000000000000000e+03 4.396521300077438354e-02 1.645529121160507202e-01 3.978399932384490967e-01 1.405796956532867625e-05 2.870750427246093750e-01 2.670007050037384033e-01 3.549744188785552979e-02 1.645529121160507202e-01 3.978399932384490967e-01 1.405796956532867625e-05 2.870750427246093750e-01 2.670007050037384033e-01
2.000000000000000000e+03 9.404102712869644165e-02 2.602942883968353271e-01 3.084599971771240234e-01 3.044887307623866946e-05 2.438383996486663818e-01 1.232834309339523315e-01 1.821286790072917938e-02 2.602942883968353271e-01 3.084599971771240234e-01 3.044887307623866946e-05 2.438383996486663818e-01 1.232834309339523315e-01
3.000000000000000000e+03 5.966939404606819153e-02 1.123184934258460999e-01 3.040351271629333496e-01 8.940679254010319710e-05 2.285612523555755615e-01 1.299726366996765137e-01 1.205127127468585968e-02 1.123184934258460999e-01 3.040351271629333496e-01 8.940679254010319710e-05 2.285612523555755615e-01 1.299726366996765137e-01
4.000000000000000000e+03 5.865091085433959961e-01 1.302536249160766602e+00 2.041707336902618408e-01 5.074640284874476492e-06 3.560862243175506592e-01 4.545386135578155518e-02 8.704070001840591431e-02 1.302536249160766602e+00 2.041707336902618408e-01 5.074640284874476492e-06 3.560862243175506592e-01 4.545386135578155518e-02
5.000000000000000000e+03 9.823110699653625488e-02 1.133456587791442871e+00 1.782224476337432861e-01 2.540894456615205854e-05 7.510338723659515381e-02 1.346575021743774414e-01 1.284845080226659775e-02 1.133456587791442871e+00 1.782224476337432861e-01 2.540894456615205854e-05 7.510338723659515381e-02 1.346575021743774414e-01
6.000000000000000000e+03 4.323963820934295654e-02 8.671818673610687256e-02 1.304090321063995361e-01 2.824056537065189332e-05 6.894658505916595459e-02 1.653077453374862671e-01 7.519101258367300034e-03 8.671818673610687256e-02 1.304090321063995361e-01 2.824056537065189332e-05 6.894658505916595459e-02 1.653077453374862671e-01
7.000000000000000000e+03 6.091912463307380676e-02 8.145902305841445923e-02 1.075150743126869202e-01 1.304054194406489842e-06 9.743922203779220581e-02 1.276875883340835571e-01 9.632004424929618835e-03 8.145902305841445923e-02 1.075150743126869202e-01 1.304054194406489842e-06 9.743922203779220581e-02 1.276875883340835571e-01
8.000000000000000000e+03 9.470825642347335815e-02 1.632511317729949951e-01 1.233245506882667542e-01 1.513442725808999967e-06 2.360888011753559113e-02 9.327054023742675781e-02 1.825010590255260468e-02 1.632511317729949951e-01 1.233245506882667542e-01 1.513442725808999967e-06 2.360888011753559113e-02 9.327054023742675781e-02
9.000000000000000000e+03 9.526111930608749390e-02 2.565393447875976562e-01 7.047954201698303223e-02 1.141094571721623652e-06 2.833563089370727539e-02 5.282333493232727051e-02 1.042747963219881058e-02 2.565393447875976562e-01 7.047954201698303223e-02 1.141094571721623652e-06 2.833563089370727539e-02 5.282333493232727051e-02
1.000000000000000000e+04 1.880666613578796387e-01 6.645523011684417725e-02 6.928193569183349609e-02 9.083443615054420661e-07 6.946204602718353271e-02 9.454290568828582764e-02 1.004072092473506927e-02 6.645523011684417725e-02 6.928193569183349609e-02 9.083443615054420661e-07 6.946204602718353271e-02 9.454290568828582764e-02
