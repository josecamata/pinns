# learning_rate: 0.005
# num_dense_layers: 8
# num_dense_nodes: 30
# activation:Swish 
# batch_size: 32
# final loss: 0.3406754732131958
# Training Time: 143.4379665851593
# Best Step: 9000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 4.897704347968101501e-04 4.950580215454101562e+01 1.899188064271584153e-04 3.177559335654223105e-07 1.032668078551068902e-04 9.279102960135787725e-05 4.897704347968101501e-04 4.950580215454101562e+01 1.899188064271584153e-04 3.177559335654223105e-07 1.032668078551068902e-04 9.279102960135787725e-05
1.000000000000000000e+03 4.111804440617561340e-02 1.261967122554779053e-01 4.013745188713073730e-01 1.904089003801345825e-06 3.109115064144134521e-01 2.051018625497817993e-01 4.111804440617561340e-02 1.261967122554779053e-01 4.013745188713073730e-01 1.904089003801345825e-06 3.109115064144134521e-01 2.051018625497817993e-01
2.000000000000000000e+03 1.030738204717636108e-01 7.547631859779357910e-01 2.739169597625732422e-01 1.774629140527395066e-06 2.235258370637893677e-01 3.905925899744033813e-02 1.030738204717636108e-01 7.547631859779357910e-01 2.739169597625732422e-01 1.774629140527395066e-06 2.235258370637893677e-01 3.905925899744033813e-02
3.000000000000000000e+03 1.737351864576339722e-01 1.247881576418876648e-01 3.713946938514709473e-01 5.994072580506326631e-07 2.704032063484191895e-01 1.683463752269744873e-01 1.737351864576339722e-01 1.247881576418876648e-01 3.713946938514709473e-01 5.994072580506326631e-07 2.704032063484191895e-01 1.683463752269744873e-01
4.000000000000000000e+03 6.441927701234817505e-02 8.359898626804351807e-02 3.088045120239257812e-01 1.346436533822270576e-06 1.341370195150375366e-01 1.001559197902679443e-01 6.441927701234817505e-02 8.359898626804351807e-02 3.088045120239257812e-01 1.346436533822270576e-06 1.341370195150375366e-01 1.001559197902679443e-01
5.000000000000000000e+03 8.255891501903533936e-02 2.418491989374160767e-01 2.280439585447311401e-01 7.553373961854958907e-07 6.081243604421615601e-02 3.992233425378799438e-02 8.255891501903533936e-02 2.418491989374160767e-01 2.280439585447311401e-01 7.553373961854958907e-07 6.081243604421615601e-02 3.992233425378799438e-02
6.000000000000000000e+03 3.161186352372169495e-02 5.628599226474761963e-02 1.032916978001594543e-01 5.017013222641253378e-07 5.884267389774322510e-02 9.937073290348052979e-02 3.161186352372169495e-02 5.628599226474761963e-02 1.032916978001594543e-01 5.017013222641253378e-07 5.884267389774322510e-02 9.937073290348052979e-02
7.000000000000000000e+03 1.320562958717346191e-01 5.258686095476150513e-02 5.906673520803451538e-02 5.345058795569457288e-08 2.806340157985687256e-02 6.982207298278808594e-02 1.320562958717346191e-01 5.258686095476150513e-02 5.906673520803451538e-02 5.345058795569457288e-08 2.806340157985687256e-02 6.982207298278808594e-02
8.000000000000000000e+03 9.523887187242507935e-02 3.563651740550994873e-01 3.752369061112403870e-02 1.534241533818203607e-07 9.965860284864902496e-03 2.585447207093238831e-02 9.523887187242507935e-02 3.563651740550994873e-01 3.752369061112403870e-02 1.534241533818203607e-07 9.965860284864902496e-03 2.585447207093238831e-02
9.000000000000000000e+03 6.855441629886627197e-02 1.568748503923416138e-01 6.690306961536407471e-02 1.043772840603196528e-06 6.299505475908517838e-03 4.204257205128669739e-02 6.855441629886627197e-02 1.568748503923416138e-01 6.690306961536407471e-02 1.043772840603196528e-06 6.299505475908517838e-03 4.204257205128669739e-02
1.000000000000000000e+04 2.310529351234436035e-01 1.450910866260528564e-01 6.737989187240600586e-02 1.323605118841442163e-07 6.254589557647705078e-02 3.285484015941619873e-02 2.310529351234436035e-01 1.450910866260528564e-01 6.737989187240600586e-02 1.323605118841442163e-07 6.254589557647705078e-02 3.285484015941619873e-02
