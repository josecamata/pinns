# learning_rate: 0.002317705089405383
# num_dense_layers: 7
# num_dense_nodes: 120
# activation:sin 
# batch_size: 32
# final loss: 0.49517619609832764
# Training Time: 140.56121253967285
# Best Step: 6000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 1.808149367570877075e-01 4.794868087768554688e+01 2.755121886730194092e-01 9.646105463616549969e-04 7.387594133615493774e-02 1.880304664373397827e-01 1.812717318534851074e-01 4.794868087768554688e+01 2.755121886730194092e-01 9.646105463616549969e-04 7.387594133615493774e-02 1.880304664373397827e-01
1.000000000000000000e+03 4.507660493254661560e-02 1.544695049524307251e-01 4.288598299026489258e-01 7.476763130398467183e-06 3.065696358680725098e-01 2.969174981117248535e-01 1.368456427007913589e-02 1.544695049524307251e-01 4.288598299026489258e-01 7.476763130398467183e-06 3.065696358680725098e-01 2.969174981117248535e-01
2.000000000000000000e+03 1.460561603307723999e-01 7.371825575828552246e-01 2.500419914722442627e-01 2.228844277851749212e-05 1.930223405361175537e-01 8.194267004728317261e-02 1.992015354335308075e-02 7.371825575828552246e-01 2.500419914722442627e-01 2.228844277851749212e-05 1.930223405361175537e-01 8.194267004728317261e-02
3.000000000000000000e+03 1.059565246105194092e-01 1.826127469539642334e-01 3.232270181179046631e-01 1.158478607976576313e-05 2.559593021869659424e-01 1.731887906789779663e-01 3.443925082683563232e-02 1.826127469539642334e-01 3.232270181179046631e-01 1.158478607976576313e-05 2.559593021869659424e-01 1.731887906789779663e-01
4.000000000000000000e+03 6.070595607161521912e-02 1.671091020107269287e-01 2.072190642356872559e-01 1.826255902415141463e-05 1.440456807613372803e-01 8.487239480018615723e-02 1.419914327561855316e-02 1.671091020107269287e-01 2.072190642356872559e-01 1.826255902415141463e-05 1.440456807613372803e-01 8.487239480018615723e-02
5.000000000000000000e+03 1.597170084714889526e-01 9.189488738775253296e-02 2.797825038433074951e-01 5.659257567458553240e-06 1.177769824862480164e-01 1.348866671323776245e-01 3.375510126352310181e-02 9.189488738775253296e-02 2.797825038433074951e-01 5.659257567458553240e-06 1.177769824862480164e-01 1.348866671323776245e-01
6.000000000000000000e+03 6.162947416305541992e-02 2.062796652317047119e-01 1.540834903717041016e-01 5.109489848109660670e-06 3.333917260169982910e-02 8.884193748235702515e-02 1.262683328241109848e-02 2.062796652317047119e-01 1.540834903717041016e-01 5.109489848109660670e-06 3.333917260169982910e-02 8.884193748235702515e-02
7.000000000000000000e+03 5.983402207493782043e-02 2.759998738765716553e-01 1.983157098293304443e-01 2.407135070825461298e-05 5.205258354544639587e-02 1.572326123714447021e-01 1.104650646448135376e-02 2.759998738765716553e-01 1.983157098293304443e-01 2.407135070825461298e-05 5.205258354544639587e-02 1.572326123714447021e-01
8.000000000000000000e+03 6.840816140174865723e-02 1.947249323129653931e-01 2.905242443084716797e-01 1.622507079446222633e-05 2.082622945308685303e-01 1.324344128370285034e-01 1.399047020822763443e-02 1.947249323129653931e-01 2.905242443084716797e-01 1.622507079446222633e-05 2.082622945308685303e-01 1.324344128370285034e-01
9.000000000000000000e+03 1.688231080770492554e-01 2.531392872333526611e-01 1.567090302705764771e-01 1.264259663003031164e-05 1.393876820802688599e-01 9.391798824071884155e-02 1.051903702318668365e-02 2.531392872333526611e-01 1.567090302705764771e-01 1.264259663003031164e-05 1.393876820802688599e-01 9.391798824071884155e-02
1.000000000000000000e+04 1.031603068113327026e-01 1.509878188371658325e-01 1.221622601151466370e-01 7.793532859068363905e-06 2.457193732261657715e-01 1.494339853525161743e-01 1.385410316288471222e-02 1.509878188371658325e-01 1.221622601151466370e-01 7.793532859068363905e-06 2.457193732261657715e-01 1.494339853525161743e-01
