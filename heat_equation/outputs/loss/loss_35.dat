# learning_rate: 0.0023336419019821418
# num_dense_layers: 7
# num_dense_nodes: 120
# activation:sin 
# batch_size: 32
# final loss: 0.32030943036079407
# Training Time: 140.74541020393372
# Best Step: 9000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 2.095227956771850586e+00 6.089487075805664062e+01 9.345040470361709595e-02 1.674550003372132778e-03 8.447282761335372925e-02 3.542054593563079834e-01 2.037441968917846680e+00 6.089487075805664062e+01 9.345040470361709595e-02 1.674550003372132778e-03 8.447282761335372925e-02 3.542054593563079834e-01
1.000000000000000000e+03 5.991148576140403748e-02 1.649384796619415283e-01 4.495939910411834717e-01 5.407859589467989281e-06 3.160016536712646484e-01 3.108406066894531250e-01 4.216952621936798096e-02 1.649384796619415283e-01 4.495939910411834717e-01 5.407859589467989281e-06 3.160016536712646484e-01 3.108406066894531250e-01
2.000000000000000000e+03 1.660956144332885742e-01 1.182597279548645020e-01 3.870393335819244385e-01 6.138479420769726858e-06 2.702228426933288574e-01 1.866921633481979370e-01 5.917199701070785522e-02 1.182597279548645020e-01 3.870393335819244385e-01 6.138479420769726858e-06 2.702228426933288574e-01 1.866921633481979370e-01
3.000000000000000000e+03 9.158547967672348022e-02 2.336233407258987427e-01 3.564863502979278564e-01 1.571994630467088427e-06 2.624176144599914551e-01 1.463032066822052002e-01 2.734467573463916779e-02 2.336233407258987427e-01 3.564863502979278564e-01 1.571994630467088427e-06 2.624176144599914551e-01 1.463032066822052002e-01
4.000000000000000000e+03 5.870952829718589783e-02 1.220601350069046021e-01 2.337044030427932739e-01 1.805086685635615140e-05 1.798022538423538208e-01 1.375435441732406616e-01 9.378344751894474030e-03 1.220601350069046021e-01 2.337044030427932739e-01 1.805086685635615140e-05 1.798022538423538208e-01 1.375435441732406616e-01
5.000000000000000000e+03 5.735824257135391235e-02 7.853250205516815186e-02 3.412108719348907471e-01 2.951925353045226075e-06 2.699064016342163086e-01 1.620532423257827759e-01 1.799226179718971252e-02 7.853250205516815186e-02 3.412108719348907471e-01 2.951925353045226075e-06 2.699064016342163086e-01 1.620532423257827759e-01
6.000000000000000000e+03 7.658246159553527832e-02 7.622523605823516846e-02 1.319069266319274902e-01 1.165829962701536715e-05 7.746440917253494263e-02 1.031567454338073730e-01 1.236031670123338699e-02 7.622523605823516846e-02 1.319069266319274902e-01 1.165829962701536715e-05 7.746440917253494263e-02 1.031567454338073730e-01
7.000000000000000000e+03 1.381053179502487183e-01 3.937060534954071045e-01 3.575229048728942871e-01 1.381203492201166227e-05 3.177540749311447144e-02 8.115847408771514893e-02 1.406708639115095139e-02 3.937060534954071045e-01 3.575229048728942871e-01 1.381203492201166227e-05 3.177540749311447144e-02 8.115847408771514893e-02
8.000000000000000000e+03 5.674527585506439209e-02 2.692863345146179199e-01 9.350161254405975342e-02 1.336994273515301757e-06 3.427748382091522217e-02 4.671642556786537170e-02 2.152504958212375641e-02 2.692863345146179199e-01 9.350161254405975342e-02 1.336994273515301757e-06 3.427748382091522217e-02 4.671642556786537170e-02
9.000000000000000000e+03 2.355424501001834869e-02 1.194451227784156799e-01 5.970266833901405334e-02 1.607595550012774765e-06 5.032734945416450500e-02 8.731820434331893921e-02 3.514471929520368576e-03 1.194451227784156799e-01 5.970266833901405334e-02 1.607595550012774765e-06 5.032734945416450500e-02 8.731820434331893921e-02
1.000000000000000000e+04 8.096936345100402832e-02 8.555772155523300171e-02 3.256927728652954102e-01 6.766101705579785630e-07 1.105071678757667542e-01 6.448165327310562134e-02 8.667082525789737701e-03 8.555772155523300171e-02 3.256927728652954102e-01 6.766101705579785630e-07 1.105071678757667542e-01 6.448165327310562134e-02
