# learning_rate: 0.01
# num_dense_layers: 5
# num_dense_nodes: 50
# activation:sin 
# batch_size: 32
# final loss: 0.5504599213600159
# Training Time: 75.1223464012146
# Best Step: 3000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 3.437995910644531250e+00 4.489665603637695312e+01 3.732241988182067871e-01 3.822549013420939445e-03 1.248344406485557556e-01 5.300933122634887695e-02 3.437995910644531250e+00 4.489665603637695312e+01 3.732241988182067871e-01 3.822549013420939445e-03 1.248344406485557556e-01 5.300933122634887695e-02
1.000000000000000000e+03 7.164555788040161133e-02 7.480187416076660156e-01 2.791536450386047363e-01 6.826218304922804236e-05 2.180844247341156006e-01 1.814213395118713379e-01 7.164555788040161133e-02 7.480187416076660156e-01 2.791536450386047363e-01 6.826218304922804236e-05 2.180844247341156006e-01 1.814213395118713379e-01
2.000000000000000000e+03 7.832703739404678345e-02 3.560625612735748291e-01 2.503288090229034424e-01 2.402372592769097537e-05 1.991809755563735962e-01 1.113656312227249146e-01 7.832703739404678345e-02 3.560625612735748291e-01 2.503288090229034424e-01 2.402372592769097537e-05 1.991809755563735962e-01 1.113656312227249146e-01
3.000000000000000000e+03 5.126165226101875305e-02 1.089165955781936646e-01 1.335208117961883545e-01 8.474270543956663460e-06 1.144359409809112549e-01 1.423164457082748413e-01 5.126165226101875305e-02 1.089165955781936646e-01 1.335208117961883545e-01 8.474270543956663460e-06 1.144359409809112549e-01 1.423164457082748413e-01
4.000000000000000000e+03 1.019837483763694763e-01 1.284645050764083862e-01 2.620970010757446289e-01 5.929732196818804368e-06 8.289915323257446289e-02 1.418888419866561890e-01 1.019837483763694763e-01 1.284645050764083862e-01 2.620970010757446289e-01 5.929732196818804368e-06 8.289915323257446289e-02 1.418888419866561890e-01
5.000000000000000000e+03 1.742738127708435059e+00 5.254526138305664062e+00 1.533413767814636230e+00 9.470297954976558685e-04 1.411786198616027832e+00 3.844187498092651367e+00 1.742738127708435059e+00 5.254526138305664062e+00 1.533413767814636230e+00 9.470297954976558685e-04 1.411786198616027832e+00 3.844187498092651367e+00
6.000000000000000000e+03 1.380416601896286011e-01 1.572661846876144409e-01 1.477590203285217285e-01 1.514248724561184645e-04 2.103392928838729858e-01 2.903511822223663330e-01 1.380416601896286011e-01 1.572661846876144409e-01 1.477590203285217285e-01 1.514248724561184645e-04 2.103392928838729858e-01 2.903511822223663330e-01
7.000000000000000000e+03 1.530384123325347900e-01 1.190846800804138184e+00 2.057570070028305054e-01 5.783732194686308503e-05 3.401659727096557617e-01 9.045431762933731079e-02 1.530384123325347900e-01 1.190846800804138184e+00 2.057570070028305054e-01 5.783732194686308503e-05 3.401659727096557617e-01 9.045431762933731079e-02
8.000000000000000000e+03 6.448747217655181885e-02 1.483854651451110840e-01 3.035566210746765137e-01 4.659477326640626416e-06 1.857267469167709351e-01 3.555654585361480713e-01 6.448747217655181885e-02 1.483854651451110840e-01 3.035566210746765137e-01 4.659477326640626416e-06 1.857267469167709351e-01 3.555654585361480713e-01
9.000000000000000000e+03 4.422679916024208069e-02 3.115945458412170410e-01 9.924440085887908936e-02 2.041636616922914982e-05 5.839925631880760193e-02 1.383395642042160034e-01 4.422679916024208069e-02 3.115945458412170410e-01 9.924440085887908936e-02 2.041636616922914982e-05 5.839925631880760193e-02 1.383395642042160034e-01
1.000000000000000000e+04 8.218035846948623657e-02 4.108051657676696777e-01 2.493559122085571289e-01 1.168257804238237441e-04 2.161571085453033447e-01 2.279538363218307495e-01 8.218035846948623657e-02 4.108051657676696777e-01 2.493559122085571289e-01 1.168257804238237441e-04 2.161571085453033447e-01 2.279538363218307495e-01
