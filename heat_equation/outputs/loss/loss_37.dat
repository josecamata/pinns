# learning_rate: 0.001
# num_dense_layers: 3
# num_dense_nodes: 50
# activation:sin 
# batch_size: 32
# final loss: 0.9683777689933777
# Training Time: 56.83586359024048
# Best Step: 10000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 2.339281797409057617e+00 3.372329711914062500e+01 2.458554208278656006e-01 1.137112616561353207e-03 1.148827448487281799e-01 8.041328787803649902e-01 2.339281797409057617e+00 3.372329711914062500e+01 2.458554208278656006e-01 1.137112616561353207e-03 1.148827448487281799e-01 8.041328787803649902e-01
1.000000000000000000e+03 1.079827696084976196e-01 3.405337333679199219e-01 4.482825696468353271e-01 2.898096317949239165e-05 3.165141046047210693e-01 5.893179774284362793e-01 1.079827696084976196e-01 3.405337333679199219e-01 4.482825696468353271e-01 2.898096317949239165e-05 3.165141046047210693e-01 5.893179774284362793e-01
2.000000000000000000e+03 9.117864817380905151e-02 2.265319228172302246e-01 3.993020951747894287e-01 3.487244248390197754e-05 2.896630764007568359e-01 3.952391445636749268e-01 9.117864817380905151e-02 2.265319228172302246e-01 3.993020951747894287e-01 3.487244248390197754e-05 2.896630764007568359e-01 3.952391445636749268e-01
3.000000000000000000e+03 6.408014148473739624e-02 2.441060990095138550e-01 3.766259253025054932e-01 2.030709038081113249e-05 2.707130908966064453e-01 3.310510218143463135e-01 6.408014148473739624e-02 2.441060990095138550e-01 3.766259253025054932e-01 2.030709038081113249e-05 2.707130908966064453e-01 3.310510218143463135e-01
4.000000000000000000e+03 5.541421845555305481e-02 1.984137296676635742e-01 3.779054880142211914e-01 2.117531766998581588e-05 2.759026288986206055e-01 2.776286900043487549e-01 5.541421845555305481e-02 1.984137296676635742e-01 3.779054880142211914e-01 2.117531766998581588e-05 2.759026288986206055e-01 2.776286900043487549e-01
5.000000000000000000e+03 4.744663462042808533e-02 1.843803972005844116e-01 3.727538883686065674e-01 3.355040826136246324e-05 2.752563655376434326e-01 2.475553601980209351e-01 4.744663462042808533e-02 1.843803972005844116e-01 3.727538883686065674e-01 3.355040826136246324e-05 2.752563655376434326e-01 2.475553601980209351e-01
6.000000000000000000e+03 4.475246369838714600e-02 1.747024059295654297e-01 3.707107305526733398e-01 2.092151989927515388e-04 2.716272771358489990e-01 2.192086726427078247e-01 4.475246369838714600e-02 1.747024059295654297e-01 3.707107305526733398e-01 2.092151989927515388e-04 2.716272771358489990e-01 2.192086726427078247e-01
7.000000000000000000e+03 4.560709372162818909e-02 1.673961579799652100e-01 3.674381673336029053e-01 2.605251211207360029e-04 2.671347558498382568e-01 2.018801420927047729e-01 4.560709372162818909e-02 1.673961579799652100e-01 3.674381673336029053e-01 2.605251211207360029e-04 2.671347558498382568e-01 2.018801420927047729e-01
8.000000000000000000e+03 4.739668965339660645e-02 1.566424667835235596e-01 3.643652796745300293e-01 1.876060705399140716e-04 2.655530273914337158e-01 1.923989206552505493e-01 4.739668965339660645e-02 1.566424667835235596e-01 3.643652796745300293e-01 1.876060705399140716e-04 2.655530273914337158e-01 1.923989206552505493e-01
9.000000000000000000e+03 4.899565875530242920e-02 1.540828496217727661e-01 3.549223542213439941e-01 8.439461089437827468e-05 2.609418034553527832e-01 1.806584596633911133e-01 4.899565875530242920e-02 1.540828496217727661e-01 3.549223542213439941e-01 8.439461089437827468e-05 2.609418034553527832e-01 1.806584596633911133e-01
1.000000000000000000e+04 5.010798946022987366e-02 1.428695321083068848e-01 3.450813293457031250e-01 4.545799674815498292e-05 2.572560608386993408e-01 1.730173230171203613e-01 5.010798946022987366e-02 1.428695321083068848e-01 3.450813293457031250e-01 4.545799674815498292e-05 2.572560608386993408e-01 1.730173230171203613e-01
