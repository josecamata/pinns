# learning_rate: 0.002394588129610979
# num_dense_layers: 7
# num_dense_nodes: 120
# activation:sin 
# batch_size: 32
# final loss: 0.4722669720649719
# Training Time: 140.67971229553223
# Best Step: 10000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 9.510955810546875000e-01 2.224255752563476562e+01 3.209152460098266602e+00 3.941219765692949295e-03 6.677599251270294189e-02 3.000581741333007812e+00 1.007753610610961914e+00 2.224255752563476562e+01 3.209152460098266602e+00 3.941219765692949295e-03 6.677599251270294189e-02 3.000581741333007812e+00
1.000000000000000000e+03 1.115110814571380615e-01 5.393306016921997070e-01 3.719064891338348389e-01 5.780841456726193428e-05 2.954941093921661377e-01 4.162854552268981934e-01 5.054038390517234802e-02 5.393306016921997070e-01 3.719064891338348389e-01 5.780841456726193428e-05 2.954941093921661377e-01 4.162854552268981934e-01
2.000000000000000000e+03 5.511830747127532959e-02 1.214288324117660522e-01 3.520256578922271729e-01 1.171820372292131651e-06 2.618614733219146729e-01 1.584004014730453491e-01 1.496155466884374619e-02 1.214288324117660522e-01 3.520256578922271729e-01 1.171820372292131651e-06 2.618614733219146729e-01 1.584004014730453491e-01
3.000000000000000000e+03 8.267036825418472290e-02 1.104524135589599609e-01 3.080955743789672852e-01 9.306540391662565526e-07 2.278139889240264893e-01 1.335332095623016357e-01 1.469774451106786728e-02 1.104524135589599609e-01 3.080955743789672852e-01 9.306540391662565526e-07 2.278139889240264893e-01 1.335332095623016357e-01
4.000000000000000000e+03 7.911192625761032104e-02 6.851269006729125977e-01 4.420419633388519287e-01 5.780536866950569674e-07 1.609097719192504883e-01 2.247932106256484985e-01 2.900285273790359497e-02 6.851269006729125977e-01 4.420419633388519287e-01 5.780536866950569674e-07 1.609097719192504883e-01 2.247932106256484985e-01
5.000000000000000000e+03 5.948331579566001892e-02 1.120682433247566223e-01 3.779537975788116455e-01 6.017294708726694807e-06 2.467073351144790649e-01 1.888937950134277344e-01 1.574714109301567078e-02 1.120682433247566223e-01 3.779537975788116455e-01 6.017294708726694807e-06 2.467073351144790649e-01 1.888937950134277344e-01
6.000000000000000000e+03 6.548801809549331665e-02 3.014063835144042969e-01 1.458985805511474609e-01 9.732692660691100173e-07 8.526583015918731689e-02 7.622642815113067627e-02 1.177738979458808899e-02 3.014063835144042969e-01 1.458985805511474609e-01 9.732692660691100173e-07 8.526583015918731689e-02 7.622642815113067627e-02
7.000000000000000000e+03 3.466595113277435303e-01 5.818682909011840820e-01 1.254512518644332886e-01 2.630771814438048750e-05 8.869774639606475830e-02 9.773803502321243286e-02 1.915897801518440247e-02 5.818682909011840820e-01 1.254512518644332886e-01 2.630771814438048750e-05 8.869774639606475830e-02 9.773803502321243286e-02
8.000000000000000000e+03 1.573043763637542725e-01 6.959011554718017578e-01 7.719922810792922974e-02 1.088259887183085084e-05 2.075394392013549805e-01 4.796454682946205139e-02 1.809765025973320007e-02 6.959011554718017578e-01 7.719922810792922974e-02 1.088259887183085084e-05 2.075394392013549805e-01 4.796454682946205139e-02
9.000000000000000000e+03 4.378598630428314209e-01 7.380757927894592285e-01 2.350553274154663086e-01 1.994418880713055842e-06 2.560372948646545410e-01 1.145209521055221558e-01 7.008261978626251221e-02 7.380757927894592285e-01 2.350553274154663086e-01 1.994418880713055842e-06 2.560372948646545410e-01 1.145209521055221558e-01
1.000000000000000000e+04 8.572104573249816895e-02 2.105714678764343262e-01 9.717939049005508423e-02 6.102174211264355108e-06 6.597484648227691650e-02 8.337257802486419678e-02 1.516258530318737030e-02 2.105714678764343262e-01 9.717939049005508423e-02 6.102174211264355108e-06 6.597484648227691650e-02 8.337257802486419678e-02
