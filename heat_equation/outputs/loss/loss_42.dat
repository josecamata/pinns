# learning_rate: 0.0023777313858194945
# num_dense_layers: 7
# num_dense_nodes: 120
# activation:sin 
# batch_size: 32
# final loss: 0.4820745885372162
# Training Time: 140.68507623672485
# Best Step: 7000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 7.712679356336593628e-02 3.873430633544921875e+01 6.069220229983329773e-02 9.128233796218410134e-05 5.204212665557861328e-02 1.676519960165023804e-01 7.204424589872360229e-02 3.873430633544921875e+01 6.069220229983329773e-02 9.128233796218410134e-05 5.204212665557861328e-02 1.676519960165023804e-01
1.000000000000000000e+03 6.121068820357322693e-02 5.946760177612304688e-01 3.139398097991943359e-01 8.544297088519670069e-06 2.280798405408859253e-01 1.886863261461257935e-01 4.023276269435882568e-02 5.946760177612304688e-01 3.139398097991943359e-01 8.544297088519670069e-06 2.280798405408859253e-01 1.886863261461257935e-01
2.000000000000000000e+03 7.605974376201629639e-02 4.676492810249328613e-01 2.654018104076385498e-01 5.628718554362421855e-06 2.141690403223037720e-01 7.863615453243255615e-02 1.173237338662147522e-02 4.676492810249328613e-01 2.654018104076385498e-01 5.628718554362421855e-06 2.141690403223037720e-01 7.863615453243255615e-02
3.000000000000000000e+03 9.961832314729690552e-02 1.906677335500717163e-01 2.514035999774932861e-01 2.592477540019899607e-05 1.637797057628631592e-01 9.934024512767791748e-02 1.567283645272254944e-02 1.906677335500717163e-01 2.514035999774932861e-01 2.592477540019899607e-05 1.637797057628631592e-01 9.934024512767791748e-02
4.000000000000000000e+03 9.560938924551010132e-02 1.191157698631286621e-01 1.387533694505691528e-01 6.336283149721566588e-06 8.764877915382385254e-02 1.165685579180717468e-01 1.998175866901874542e-02 1.191157698631286621e-01 1.387533694505691528e-01 6.336283149721566588e-06 8.764877915382385254e-02 1.165685579180717468e-01
5.000000000000000000e+03 1.384494900703430176e-01 4.358113706111907959e-01 4.711834713816642761e-02 1.756399115038220771e-06 3.625505045056343079e-02 8.968817442655563354e-02 5.456223618239164352e-03 4.358113706111907959e-01 4.711834713816642761e-02 1.756399115038220771e-06 3.625505045056343079e-02 8.968817442655563354e-02
6.000000000000000000e+03 1.378721147775650024e-01 2.444504350423812866e-01 1.259513646364212036e-01 7.760394510114565492e-06 9.697802364826202393e-02 8.031192421913146973e-02 1.867753826081752777e-02 2.444504350423812866e-01 1.259513646364212036e-01 7.760394510114565492e-06 9.697802364826202393e-02 8.031192421913146973e-02
7.000000000000000000e+03 6.432575732469558716e-02 1.821969449520111084e-01 8.650062978267669678e-02 3.804669177043251693e-06 1.173833757638931274e-01 9.137801080942153931e-02 1.517375744879245758e-02 1.821969449520111084e-01 8.650062978267669678e-02 3.804669177043251693e-06 1.173833757638931274e-01 9.137801080942153931e-02
8.000000000000000000e+03 8.152990788221359253e-02 9.856644272804260254e-02 2.127763926982879639e-01 2.102949423488098546e-07 1.697257459163665771e-01 1.124828904867172241e-01 2.069222740828990936e-02 9.856644272804260254e-02 2.127763926982879639e-01 2.102949423488098546e-07 1.697257459163665771e-01 1.124828904867172241e-01
9.000000000000000000e+03 1.470271795988082886e-01 2.588400244712829590e-01 9.378472715616226196e-02 6.351509455271298066e-06 6.481157988309860229e-02 8.488480001688003540e-02 1.921047829091548920e-02 2.588400244712829590e-01 9.378472715616226196e-02 6.351509455271298066e-06 6.481157988309860229e-02 8.488480001688003540e-02
1.000000000000000000e+04 1.852439790964126587e-01 2.121788710355758667e-01 1.102820858359336853e-01 1.150686057371785864e-05 1.136397644877433777e-01 1.451246142387390137e-01 1.847484894096851349e-02 2.121788710355758667e-01 1.102820858359336853e-01 1.150686057371785864e-05 1.136397644877433777e-01 1.451246142387390137e-01
