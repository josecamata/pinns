# learning_rate: 0.0001
# num_dense_layers: 3
# num_dense_nodes: 20
# activation:tanh 
# batch_size: 32
# final loss: 1.1438848972320557
# Training Time: 55.124664545059204
# Best Step: 10000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 1.232714533805847168e+00 2.822847366333007812e+01 3.587021231651306152e-01 2.423569327220320702e-03 7.458097934722900391e-01 6.709457635879516602e-01 1.232714533805847168e+00 2.822847366333007812e+01 3.587021231651306152e-01 2.423569327220320702e-03 7.458097934722900391e-01 6.709457635879516602e-01
1.000000000000000000e+03 1.990360468626022339e-01 2.218514204025268555e+00 1.970952868461608887e+00 1.202394347637891769e-02 1.609579920768737793e+00 3.752197265625000000e+00 1.990360468626022339e-01 2.218514204025268555e+00 1.970952868461608887e+00 1.202394347637891769e-02 1.609579920768737793e+00 3.752197265625000000e+00
2.000000000000000000e+03 4.017765522003173828e-01 1.619305253028869629e+00 1.021172404289245605e+00 5.494433920830488205e-03 1.236861824989318848e+00 2.953536272048950195e+00 4.017765522003173828e-01 1.619305253028869629e+00 1.021172404289245605e+00 5.494433920830488205e-03 1.236861824989318848e+00 2.953536272048950195e+00
3.000000000000000000e+03 2.655356824398040771e-01 1.043498158454895020e+00 7.022015452384948730e-01 9.829386835917830467e-04 7.109537124633789062e-01 2.175492525100708008e+00 2.655356824398040771e-01 1.043498158454895020e+00 7.022015452384948730e-01 9.829386835917830467e-04 7.109537124633789062e-01 2.175492525100708008e+00
4.000000000000000000e+03 1.618812978267669678e-01 6.349939107894897461e-01 5.862808227539062500e-01 3.481525694951415062e-03 5.320364832878112793e-01 1.569086909294128418e+00 1.618812978267669678e-01 6.349939107894897461e-01 5.862808227539062500e-01 3.481525694951415062e-03 5.320364832878112793e-01 1.569086909294128418e+00
5.000000000000000000e+03 1.193492114543914795e-01 4.462684392929077148e-01 4.964523017406463623e-01 1.490136724896728992e-03 4.084334969520568848e-01 1.044866442680358887e+00 1.193492114543914795e-01 4.462684392929077148e-01 4.964523017406463623e-01 1.490136724896728992e-03 4.084334969520568848e-01 1.044866442680358887e+00
6.000000000000000000e+03 1.016401648521423340e-01 3.742021322250366211e-01 4.222333431243896484e-01 3.784271248150616884e-04 3.355829417705535889e-01 6.636268496513366699e-01 1.016401648521423340e-01 3.742021322250366211e-01 4.222333431243896484e-01 3.784271248150616884e-04 3.355829417705535889e-01 6.636268496513366699e-01
7.000000000000000000e+03 1.265404224395751953e-01 3.002680242061614990e-01 4.074673056602478027e-01 6.992760609136894345e-05 3.205755352973937988e-01 5.056840777397155762e-01 1.265404224395751953e-01 3.002680242061614990e-01 4.074673056602478027e-01 6.992760609136894345e-05 3.205755352973937988e-01 5.056840777397155762e-01
8.000000000000000000e+03 6.808368861675262451e-02 2.425029426813125610e-01 3.995359838008880615e-01 5.015862552681937814e-05 3.029557168483734131e-01 3.902449309825897217e-01 6.808368861675262451e-02 2.425029426813125610e-01 3.995359838008880615e-01 5.015862552681937814e-05 3.029557168483734131e-01 3.902449309825897217e-01
9.000000000000000000e+03 3.997873514890670776e-02 2.141071557998657227e-01 3.870955109596252441e-01 1.624928336241282523e-05 2.891820371150970459e-01 3.012610077857971191e-01 3.997873514890670776e-02 2.141071557998657227e-01 3.870955109596252441e-01 1.624928336241282523e-05 2.891820371150970459e-01 3.012610077857971191e-01
1.000000000000000000e+04 3.954373300075531006e-02 1.918205469846725464e-01 3.718840181827545166e-01 1.220082049258053303e-05 2.853736281394958496e-01 2.552507817745208740e-01 3.954373300075531006e-02 1.918205469846725464e-01 3.718840181827545166e-01 1.220082049258053303e-05 2.853736281394958496e-01 2.552507817745208740e-01
