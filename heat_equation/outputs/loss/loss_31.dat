# learning_rate: 0.001
# num_dense_layers: 4
# num_dense_nodes: 20
# activation:tanh 
# batch_size: 32
# final loss: 0.6576278805732727
# Training Time: 64.85300397872925
# Best Step: 10000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 1.191085815429687500e+00 8.582340240478515625e+01 1.733053565025329590e+00 5.496334284543991089e-03 3.275930881500244141e-01 1.121031999588012695e+00 1.191085815429687500e+00 8.582340240478515625e+01 1.733053565025329590e+00 5.496334284543991089e-03 3.275930881500244141e-01 1.121031999588012695e+00
1.000000000000000000e+03 1.641541570425033569e-01 4.040930271148681641e-01 4.875046312808990479e-01 3.388526092749089003e-04 3.450148105621337891e-01 6.486738324165344238e-01 1.641541570425033569e-01 4.040930271148681641e-01 4.875046312808990479e-01 3.388526092749089003e-04 3.450148105621337891e-01 6.486738324165344238e-01
2.000000000000000000e+03 7.672583311796188354e-02 2.244246453046798706e-01 3.942723274230957031e-01 2.671391666808631271e-05 2.776585221290588379e-01 2.845939099788665771e-01 7.672583311796188354e-02 2.244246453046798706e-01 3.942723274230957031e-01 2.671391666808631271e-05 2.776585221290588379e-01 2.845939099788665771e-01
3.000000000000000000e+03 5.102807655930519104e-02 1.836488395929336548e-01 3.684253990650177002e-01 6.673033112747361884e-06 2.682839334011077881e-01 1.997300386428833008e-01 5.102807655930519104e-02 1.836488395929336548e-01 3.684253990650177002e-01 6.673033112747361884e-06 2.682839334011077881e-01 1.997300386428833008e-01
4.000000000000000000e+03 4.520392790436744690e-02 1.587785929441452026e-01 3.670630753040313721e-01 3.502327672322280705e-06 2.627163827419281006e-01 1.620920896530151367e-01 4.520392790436744690e-02 1.587785929441452026e-01 3.670630753040313721e-01 3.502327672322280705e-06 2.627163827419281006e-01 1.620920896530151367e-01
5.000000000000000000e+03 4.297894611954689026e-02 1.477296352386474609e-01 3.627884387969970703e-01 2.461972599121509120e-06 2.511759400367736816e-01 1.352991908788681030e-01 4.297894611954689026e-02 1.477296352386474609e-01 3.627884387969970703e-01 2.461972599121509120e-06 2.511759400367736816e-01 1.352991908788681030e-01
6.000000000000000000e+03 4.546630010008811951e-02 1.378850936889648438e-01 3.609554767608642578e-01 1.526277287666744087e-06 2.269817888736724854e-01 1.162270680069923401e-01 4.546630010008811951e-02 1.378850936889648438e-01 3.609554767608642578e-01 1.526277287666744087e-06 2.269817888736724854e-01 1.162270680069923401e-01
7.000000000000000000e+03 5.404398590326309204e-02 1.297820657491683960e-01 3.597957491874694824e-01 9.012987334244826343e-07 1.800312697887420654e-01 1.044773831963539124e-01 5.404398590326309204e-02 1.297820657491683960e-01 3.597957491874694824e-01 9.012987334244826343e-07 1.800312697887420654e-01 1.044773831963539124e-01
8.000000000000000000e+03 6.989377737045288086e-02 2.121326327323913574e-01 3.178297281265258789e-01 2.060471842924016528e-06 1.105732768774032593e-01 8.658516407012939453e-02 6.989377737045288086e-02 2.121326327323913574e-01 3.178297281265258789e-01 2.060471842924016528e-06 1.105732768774032593e-01 8.658516407012939453e-02
9.000000000000000000e+03 4.968509823083877563e-02 1.151628941297531128e-01 3.376035988330841064e-01 2.642884453507576836e-07 1.006777435541152954e-01 9.057602286338806152e-02 4.968509823083877563e-02 1.151628941297531128e-01 3.376035988330841064e-01 2.642884453507576836e-07 1.006777435541152954e-01 9.057602286338806152e-02
1.000000000000000000e+04 4.824727401137351990e-02 1.084599271416664124e-01 3.306507766246795654e-01 2.707306805405096384e-07 8.610292524099349976e-02 8.416672050952911377e-02 4.824727401137351990e-02 1.084599271416664124e-01 3.306507766246795654e-01 2.707306805405096384e-07 8.610292524099349976e-02 8.416672050952911377e-02
