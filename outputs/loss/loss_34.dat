# learning_rate: 0.05
# num_dense_layers: 8
# num_dense_nodes: 50
# activation:tanh 
# batch_size: 32
# final loss: 0.27671992778778076
# Training Time: 112.6284749507904
# Best Step: 2000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 2.882120132446289062e+00 1.714304089546203613e-03 7.952463929541409016e-04 1.096417312510311604e-03 5.967334844172000885e-03 8.844124674797058105e-01 2.882120132446289062e+00 1.714304089546203613e-03 7.952463929541409016e-04 1.096417312510311604e-03 5.967334844172000885e-03 8.844124674797058105e-01
1.000000000000000000e+03 1.590045251020910655e-08 2.877241349779069424e-04 2.878481463994830847e-04 2.878232335206121206e-04 2.877441584132611752e-04 2.760635614395141602e-01 1.590045251020910655e-08 2.877241349779069424e-04 2.878481463994830847e-04 2.878232335206121206e-04 2.877441584132611752e-04 2.760635614395141602e-01
2.000000000000000000e+03 2.500868276911205612e-07 3.611269639804959297e-04 3.608281549531966448e-04 3.604776575230062008e-04 3.609780396800488234e-04 2.752762734889984131e-01 2.500868276911205612e-07 3.611269639804959297e-04 3.608281549531966448e-04 3.604776575230062008e-04 3.609780396800488234e-04 2.752762734889984131e-01
3.000000000000000000e+03 2.266057758104622621e-10 3.608276310842484236e-04 3.608308616094291210e-04 3.608257684390991926e-04 3.608276601880788803e-04 2.753376364707946777e-01 2.266057758104622621e-10 3.608276310842484236e-04 3.608308616094291210e-04 3.608257684390991926e-04 3.608276601880788803e-04 2.753376364707946777e-01
4.000000000000000000e+03 7.585713673419029746e-15 3.608248371165245771e-04 3.608248371165245771e-04 3.608248371165245771e-04 3.608248371165245771e-04 2.753378152847290039e-01 7.585713673419029746e-15 3.608248371165245771e-04 3.608248371165245771e-04 3.608248371165245771e-04 3.608248371165245771e-04 2.753378152847290039e-01
5.000000000000000000e+03 5.911593816631491739e-17 3.031661501154303551e-03 3.031661501154303551e-03 3.031661501154303551e-03 3.031661501154303551e-03 8.350198268890380859e-01 5.911593816631491739e-17 3.031661501154303551e-03 3.031661501154303551e-03 3.031661501154303551e-03 3.031661501154303551e-03 8.350198268890380859e-01
6.000000000000000000e+03 1.671621506639831846e-16 1.495982985943555832e-03 1.495982985943555832e-03 1.495982985943555832e-03 1.495982985943555832e-03 3.110870420932769775e-01 1.671621506639831846e-16 1.495982985943555832e-03 1.495982985943555832e-03 1.495982985943555832e-03 1.495982985943555832e-03 3.110870420932769775e-01
7.000000000000000000e+03 2.408815375033339241e-20 6.553579005412757397e-04 6.553579005412757397e-04 6.553579005412757397e-04 6.553579005412757397e-04 2.786961793899536133e-01 2.408815375033339241e-20 6.553579005412757397e-04 6.553579005412757397e-04 6.553579005412757397e-04 6.553579005412757397e-04 2.786961793899536133e-01
8.000000000000000000e+03 1.255576045587199368e-17 3.609075502026826143e-04 3.609075502026826143e-04 3.609075502026826143e-04 3.609075793065130711e-04 2.753374874591827393e-01 1.255576045587199368e-17 3.609075502026826143e-04 3.609075502026826143e-04 3.609075502026826143e-04 3.609075793065130711e-04 2.753374874591827393e-01
9.000000000000000000e+03 5.412633590773891382e-18 3.601164498832076788e-04 3.601164498832076788e-04 3.601164498832076788e-04 3.601164789870381355e-04 2.753407061100006104e-01 5.412633590773891382e-18 3.601164498832076788e-04 3.601164498832076788e-04 3.601164498832076788e-04 3.601164789870381355e-04 2.753407061100006104e-01
1.000000000000000000e+04 2.973372469739996952e-18 3.608969855122268200e-04 3.608969855122268200e-04 3.608969855122268200e-04 3.608969855122268200e-04 2.753375172615051270e-01 2.973372469739996952e-18 3.608969855122268200e-04 3.608969855122268200e-04 3.608969855122268200e-04 3.608969855122268200e-04 2.753375172615051270e-01
