# learning_rate: 0.05
# num_dense_layers: 7
# num_dense_nodes: 70
# activation:tanh 
# batch_size: 32
# final loss: 0.25583335757255554
# Training Time: 101.55010938644409
# Best Step: 1000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 7.450073242187500000e+00 4.723240435123443604e-02 4.700596258044242859e-02 1.751547330059111118e-03 1.252843160182237625e-02 2.291882276535034180e+00 7.450073242187500000e+00 4.723240435123443604e-02 4.700596258044242859e-02 1.751547330059111118e-03 1.252843160182237625e-02 2.291882276535034180e+00
1.000000000000000000e+03 1.485608983784914017e-02 1.386656076647341251e-04 6.545420183101668954e-05 6.090730312280356884e-05 9.067032078746706247e-05 2.406215816736221313e-01 1.485608983784914017e-02 1.386656076647341251e-04 6.545420183101668954e-05 6.090730312280356884e-05 9.067032078746706247e-05 2.406215816736221313e-01
2.000000000000000000e+03 6.761120374676465872e-08 3.610680578276515007e-04 3.610085404943674803e-04 3.610065032262355089e-04 3.609289415180683136e-04 2.753122150897979736e-01 6.761120374676465872e-08 3.610680578276515007e-04 3.610085404943674803e-04 3.610065032262355089e-04 3.609289415180683136e-04 2.753122150897979736e-01
3.000000000000000000e+03 3.716373042639276036e-10 6.036568083800375462e-04 6.036660633981227875e-04 6.036726990714669228e-04 6.036536069586873055e-04 2.775997221469879150e-01 3.716373042639276036e-10 6.036568083800375462e-04 6.036660633981227875e-04 6.036726990714669228e-04 6.036536069586873055e-04 2.775997221469879150e-01
4.000000000000000000e+03 1.048785711055266745e-10 1.396378618665039539e-03 1.396370353177189827e-03 1.396363019011914730e-03 1.396378851495683193e-03 3.063001036643981934e-01 1.048785711055266745e-10 1.396378618665039539e-03 1.396370353177189827e-03 1.396363019011914730e-03 1.396378851495683193e-03 3.063001036643981934e-01
5.000000000000000000e+03 2.865791381978510799e-09 4.449549596756696701e-04 4.449265252333134413e-04 4.448907566256821156e-04 4.449368570931255817e-04 2.754535675048828125e-01 2.865791381978510799e-09 4.449549596756696701e-04 4.449265252333134413e-04 4.448907566256821156e-04 4.449368570931255817e-04 2.754535675048828125e-01
6.000000000000000000e+03 2.981453625650054562e-12 3.608314145822077990e-04 3.608315018936991692e-04 3.608313563745468855e-04 3.608317347243428230e-04 2.753378152847290039e-01 2.981453625650054562e-12 3.608314145822077990e-04 3.608315018936991692e-04 3.608313563745468855e-04 3.608317347243428230e-04 2.753378152847290039e-01
7.000000000000000000e+03 2.526455607221311794e-12 3.374530642759054899e-04 3.374533262103796005e-04 3.374534135218709707e-04 3.374534135218709707e-04 2.754720151424407959e-01 2.526455607221311794e-12 3.374530642759054899e-04 3.374533262103796005e-04 3.374534135218709707e-04 3.374534135218709707e-04 2.754720151424407959e-01
8.000000000000000000e+03 2.776600130371953412e-12 5.258914898149669170e-04 5.258921883068978786e-04 5.258935270830988884e-04 5.258931196294724941e-04 2.762895226478576660e-01 2.776600130371953412e-12 5.258914898149669170e-04 5.258921883068978786e-04 5.258935270830988884e-04 5.258931196294724941e-04 2.762895226478576660e-01
9.000000000000000000e+03 1.656479987899306394e-11 1.370500012853881344e-05 1.370490826957393438e-05 1.370491281704744324e-05 1.370514382870169356e-05 3.010504841804504395e-01 1.656479987899306394e-11 1.370500012853881344e-05 1.370490826957393438e-05 1.370491281704744324e-05 1.370514382870169356e-05 3.010504841804504395e-01
1.000000000000000000e+04 9.482577917330203832e-12 3.608767001423984766e-04 3.608758270274847746e-04 3.608750412240624428e-04 3.608769911807030439e-04 2.753375172615051270e-01 9.482577917330203832e-12 3.608767001423984766e-04 3.608758270274847746e-04 3.608750412240624428e-04 3.608769911807030439e-04 2.753375172615051270e-01
