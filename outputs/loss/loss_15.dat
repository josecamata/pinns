# learning_rate: 0.005
# num_dense_layers: 8
# num_dense_nodes: 30
# activation:Swish 
# batch_size: 32
# final loss: 0.00013891467824578285
# Training Time: 218.56251430511475
# Best Step: 6000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 1.033661738038063049e-01 5.059204413555562496e-04 1.895762252388522029e-04 1.987992254726123065e-05 3.020007352461107075e-05 3.771858811378479004e-01 1.033661738038063049e-01 5.059204413555562496e-04 1.895762252388522029e-04 1.987992254726123065e-05 3.020007352461107075e-05 3.771858811378479004e-01
1.000000000000000000e+03 2.739968476817011833e-03 6.102137376728933305e-06 6.760928954463452101e-06 7.743517016933765262e-06 4.382903625810286030e-06 1.289269886910915375e-03 2.739968476817011833e-03 6.102137376728933305e-06 6.760928954463452101e-06 7.743517016933765262e-06 4.382903625810286030e-06 1.289269886910915375e-03
2.000000000000000000e+03 2.082110382616519928e-03 5.530956968868849799e-06 6.852947990410029888e-06 5.175150818104157224e-06 2.387078893661964685e-06 2.043504500761628151e-04 2.082110382616519928e-03 5.530956968868849799e-06 6.852947990410029888e-06 5.175150818104157224e-06 2.387078893661964685e-06 2.043504500761628151e-04
3.000000000000000000e+03 1.445434871129691601e-03 4.444786554813617840e-06 5.769364179286640137e-06 4.892209290119353682e-06 2.164056695619365200e-06 2.248936070827767253e-04 1.445434871129691601e-03 4.444786554813617840e-06 5.769364179286640137e-06 4.892209290119353682e-06 2.164056695619365200e-06 2.248936070827767253e-04
4.000000000000000000e+03 7.693230290897190571e-04 3.855158411170123145e-06 3.580394832169986330e-06 3.871160970447817817e-06 1.992401166717172600e-06 4.751489541376940906e-05 7.693230290897190571e-04 3.855158411170123145e-06 3.580394832169986330e-06 3.871160970447817817e-06 1.992401166717172600e-06 4.751489541376940906e-05
5.000000000000000000e+03 5.318695912137627602e-04 3.732934146682964638e-06 3.798816351263667457e-06 3.686207492137327790e-06 1.905742806229682174e-06 3.935075801564380527e-05 5.318695912137627602e-04 3.732934146682964638e-06 3.798816351263667457e-06 3.686207492137327790e-06 1.905742806229682174e-06 3.935075801564380527e-05
6.000000000000000000e+03 1.098318753065541387e-04 2.884341711251181550e-06 3.287384970462881029e-06 3.693157850648276508e-06 1.655245682741224300e-06 1.756267192831728607e-05 1.098318753065541387e-04 2.884341711251181550e-06 3.287384970462881029e-06 3.693157850648276508e-06 1.655245682741224300e-06 1.756267192831728607e-05
7.000000000000000000e+03 3.226030094083398581e-04 3.347939809827948920e-06 3.458542096268502064e-06 3.520886821206659079e-06 1.664025944592140149e-06 3.154220030410215259e-05 3.226030094083398581e-04 3.347939809827948920e-06 3.458542096268502064e-06 3.520886821206659079e-06 1.664025944592140149e-06 3.154220030410215259e-05
8.000000000000000000e+03 1.880609081126749516e-03 4.106955202587414533e-06 4.809049187315395102e-06 3.760002527997130528e-06 1.844211510615423322e-06 2.009620802709832788e-04 1.880609081126749516e-03 4.106955202587414533e-06 4.809049187315395102e-06 3.760002527997130528e-06 1.844211510615423322e-06 2.009620802709832788e-04
9.000000000000000000e+03 6.238074274733662605e-04 2.782832098091603257e-06 2.934117674158187583e-06 3.675103016576031223e-06 1.708637114461453166e-06 5.114022860652767122e-05 6.238074274733662605e-04 2.782832098091603257e-06 2.934117674158187583e-06 3.675103016576031223e-06 1.708637114461453166e-06 5.114022860652767122e-05
1.000000000000000000e+04 7.200060063041746616e-04 3.369321348145604134e-06 3.529998821250046603e-06 3.825175099336775020e-06 1.658405267335183453e-06 9.530416718916967511e-05 7.200060063041746616e-04 3.369321348145604134e-06 3.529998821250046603e-06 3.825175099336775020e-06 1.658405267335183453e-06 9.530416718916967511e-05
