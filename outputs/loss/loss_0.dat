# learning_rate: 0.001
# num_dense_layers: 5
# num_dense_nodes: 60
# activation:tanh 
# batch_size: 32
# final loss: 0.010614296421408653
# Training Time: 110.95750856399536
# Best Step: 10000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 1.719900512695312500e+01 1.394497603178024292e-02 7.296544965356588364e-03 1.206388603895902634e-02 1.535215531475841999e-03 4.679152071475982666e-01 1.719900512695312500e+01 1.394497603178024292e-02 7.296544965356588364e-03 1.206388603895902634e-02 1.535215531475841999e-03 4.679152071475982666e-01
1.000000000000000000e+03 1.407553814351558685e-02 1.369247183902189136e-04 8.614354737801477313e-05 1.286577171413227916e-04 1.543906691949814558e-04 2.043962329626083374e-01 1.407553814351558685e-02 1.369247183902189136e-04 8.614354737801477313e-05 1.286577171413227916e-04 1.543906691949814558e-04 2.043962329626083374e-01
2.000000000000000000e+03 2.480888180434703827e-02 2.711468259803950787e-04 1.646235323278233409e-04 8.771812281338497996e-05 1.588942250236868858e-04 1.241315454244613647e-01 2.480888180434703827e-02 2.711468259803950787e-04 1.646235323278233409e-04 8.771812281338497996e-05 1.588942250236868858e-04 1.241315454244613647e-01
3.000000000000000000e+03 3.654042258858680725e-02 9.539301390759646893e-05 8.073809294728562236e-05 9.019213030114769936e-05 9.295286145061254501e-05 2.599142864346504211e-02 3.654042258858680725e-02 9.539301390759646893e-05 8.073809294728562236e-05 9.019213030114769936e-05 9.295286145061254501e-05 2.599142864346504211e-02
4.000000000000000000e+03 3.305158391594886780e-02 6.302616384346038103e-05 1.078455825336277485e-04 7.001957419561222196e-05 5.470680116559378803e-05 1.043920498341321945e-02 3.305158391594886780e-02 6.302616384346038103e-05 1.078455825336277485e-04 7.001957419561222196e-05 5.470680116559378803e-05 1.043920498341321945e-02
5.000000000000000000e+03 2.990825660526752472e-02 3.561458288459107280e-05 1.061179136740975082e-04 8.305531082442030311e-05 5.594486719928681850e-05 7.602203637361526489e-03 2.990825660526752472e-02 3.561458288459107280e-05 1.061179136740975082e-04 8.305531082442030311e-05 5.594486719928681850e-05 7.602203637361526489e-03
6.000000000000000000e+03 2.477404475212097168e-02 2.461205258441623300e-05 9.079933079192414880e-05 5.781043364549987018e-05 3.022378950845450163e-05 4.917699377983808517e-03 2.477404475212097168e-02 2.461205258441623300e-05 9.079933079192414880e-05 5.781043364549987018e-05 3.022378950845450163e-05 4.917699377983808517e-03
7.000000000000000000e+03 3.207604587078094482e-02 3.662176823127083480e-05 9.640423377277329564e-05 5.634044646285474300e-05 3.258162541897036135e-05 7.669218815863132477e-03 3.207604587078094482e-02 3.662176823127083480e-05 9.640423377277329564e-05 5.634044646285474300e-05 3.258162541897036135e-05 7.669218815863132477e-03
8.000000000000000000e+03 1.931672357022762299e-02 2.240397407149430364e-05 6.402402505045756698e-05 6.425883475458249450e-05 3.090253085247240961e-05 2.581270411610603333e-03 1.931672357022762299e-02 2.240397407149430364e-05 6.402402505045756698e-05 6.425883475458249450e-05 3.090253085247240961e-05 2.581270411610603333e-03
9.000000000000000000e+03 1.322103012353181839e-02 2.338022568437736481e-05 4.387552326079457998e-05 7.055585592752322555e-05 2.555452556407544762e-05 2.187330042943358421e-03 1.322103012353181839e-02 2.338022568437736481e-05 4.387552326079457998e-05 7.055585592752322555e-05 2.555452556407544762e-05 2.187330042943358421e-03
1.000000000000000000e+04 8.988385088741779327e-03 2.462484189891256392e-05 4.152141991653479636e-05 7.982263196026906371e-05 2.281557681271806359e-05 1.457126578316092491e-03 8.988385088741779327e-03 2.462484189891256392e-05 4.152141991653479636e-05 7.982263196026906371e-05 2.281557681271806359e-05 1.457126578316092491e-03
