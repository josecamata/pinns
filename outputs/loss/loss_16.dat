# learning_rate: 0.0005
# num_dense_layers: 8
# num_dense_nodes: 60
# activation:sigmoid 
# batch_size: 32
# final loss: 0.041740644723176956
# Training Time: 173.226891040802
# Best Step: 10000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 5.061336905143321019e-10 5.143322423100471497e-02 5.143364891409873962e-02 5.143373832106590271e-02 5.143312737345695496e-02 4.561579227447509766e+00 5.061336905143321019e-10 5.143322423100471497e-02 5.143364891409873962e-02 5.143373832106590271e-02 5.143312737345695496e-02 4.561579227447509766e+00
1.000000000000000000e+03 3.293609619140625000e-02 8.373628224944695830e-05 5.567139669437892735e-05 6.523307820316404104e-05 9.232878073817119002e-05 1.140701472759246826e-01 3.293609619140625000e-02 8.373628224944695830e-05 5.567139669437892735e-05 6.523307820316404104e-05 9.232878073817119002e-05 1.140701472759246826e-01
2.000000000000000000e+03 4.454482719302177429e-02 2.838498585333582014e-05 2.907220368797425181e-05 2.878263148886617273e-05 3.323613054817542434e-05 1.820782572031021118e-02 4.454482719302177429e-02 2.838498585333582014e-05 2.907220368797425181e-05 2.878263148886617273e-05 3.323613054817542434e-05 1.820782572031021118e-02
3.000000000000000000e+03 4.537172615528106689e-02 2.880317697417922318e-05 3.750171163119375706e-05 3.691724486998282373e-05 3.267537613282911479e-05 1.089963223785161972e-02 4.537172615528106689e-02 2.880317697417922318e-05 3.750171163119375706e-05 3.691724486998282373e-05 3.267537613282911479e-05 1.089963223785161972e-02
4.000000000000000000e+03 3.886064887046813965e-02 4.974042531102895737e-05 6.680795922875404358e-05 7.524691318394616246e-05 7.351222302531823516e-05 1.188084483146667480e-02 3.886064887046813965e-02 4.974042531102895737e-05 6.680795922875404358e-05 7.524691318394616246e-05 7.351222302531823516e-05 1.188084483146667480e-02
5.000000000000000000e+03 3.408416360616683960e-02 3.280141754657961428e-05 6.254537584027275443e-05 6.476465205196291208e-05 5.181087180972099304e-05 1.505880150943994522e-02 3.408416360616683960e-02 3.280141754657961428e-05 6.254537584027275443e-05 6.476465205196291208e-05 5.181087180972099304e-05 1.505880150943994522e-02
6.000000000000000000e+03 3.639812394976615906e-02 3.813875810010358691e-05 7.655739318579435349e-05 7.245039887493476272e-05 5.315223461366258562e-05 9.815188124775886536e-03 3.639812394976615906e-02 3.813875810010358691e-05 7.655739318579435349e-05 7.245039887493476272e-05 5.315223461366258562e-05 9.815188124775886536e-03
7.000000000000000000e+03 3.532358258962631226e-02 3.650829603429883718e-05 7.822910993127152324e-05 6.996803131187334657e-05 4.855394945479929447e-05 9.428672492504119873e-03 3.532358258962631226e-02 3.650829603429883718e-05 7.822910993127152324e-05 6.996803131187334657e-05 4.855394945479929447e-05 9.428672492504119873e-03
8.000000000000000000e+03 3.608417510986328125e-02 4.245683157932944596e-05 8.833233732730150223e-05 7.670875493204221129e-05 5.164939284441061318e-05 7.323685567826032639e-03 3.608417510986328125e-02 4.245683157932944596e-05 8.833233732730150223e-05 7.670875493204221129e-05 5.164939284441061318e-05 7.323685567826032639e-03
9.000000000000000000e+03 3.400304540991783142e-02 3.641117291408590972e-05 8.243196498369798064e-05 6.768328603357076645e-05 4.127199281356297433e-05 8.413483388721942902e-03 3.400304540991783142e-02 3.641117291408590972e-05 8.243196498369798064e-05 6.768328603357076645e-05 4.127199281356297433e-05 8.413483388721942902e-03
1.000000000000000000e+04 3.549860045313835144e-02 4.360351522336713970e-05 9.522346954327076674e-05 7.716233812971040606e-05 4.581747271004132926e-05 5.980239249765872955e-03 3.549860045313835144e-02 4.360351522336713970e-05 9.522346954327076674e-05 7.716233812971040606e-05 4.581747271004132926e-05 5.980239249765872955e-03
