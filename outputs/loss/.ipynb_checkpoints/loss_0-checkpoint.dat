# learning_rate: 0.001
# num_dense_layers: 5
# num_dense_nodes: 60
# activation:tanh 
# batch_size: 32
# final loss: 0.0057873534969985485
# Training Time: 82.47667098045349
# Best Step: 10000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 5.355630397796630859e+00 3.883769363164901733e-02 3.146022930741310120e-02 1.961763203144073486e-02 3.437904268503189087e-02 1.931413531303405762e+00 5.355630397796630859e+00 3.883769363164901733e-02 3.146022930741310120e-02 1.961763203144073486e-02 3.437904268503189087e-02 1.931413531303405762e+00
1.000000000000000000e+03 2.348475344479084015e-02 1.983098482014611363e-04 1.200233964482322335e-04 9.317896183347329497e-05 1.585680001880973577e-04 1.463315039873123169e-01 2.348475344479084015e-02 1.983098482014611363e-04 1.200233964482322335e-04 9.317896183347329497e-05 1.585680001880973577e-04 1.463315039873123169e-01
2.000000000000000000e+03 3.706741705536842346e-02 6.682972161797806621e-05 8.385866385651752353e-05 4.897861072095111012e-05 6.910581578267738223e-05 1.865044981241226196e-02 3.706741705536842346e-02 6.682972161797806621e-05 8.385866385651752353e-05 4.897861072095111012e-05 6.910581578267738223e-05 1.865044981241226196e-02
3.000000000000000000e+03 3.156021609902381897e-02 2.263609167130198330e-05 9.395546658197417855e-05 5.460879765450954437e-05 3.761213883990421891e-05 7.541358470916748047e-03 3.156021609902381897e-02 2.263609167130198330e-05 9.395546658197417855e-05 5.460879765450954437e-05 3.761213883990421891e-05 7.541358470916748047e-03
4.000000000000000000e+03 2.845005318522453308e-02 2.169923573092091829e-05 1.036891699186526239e-04 5.703378701582551003e-05 3.455119076534174383e-05 5.680473521351814270e-03 2.845005318522453308e-02 2.169923573092091829e-05 1.036891699186526239e-04 5.703378701582551003e-05 3.455119076534174383e-05 5.680473521351814270e-03
5.000000000000000000e+03 2.769276127219200134e-02 3.186681351508013904e-05 1.432105636922642589e-04 4.714415626949630678e-05 3.388972982065752149e-05 5.124681163579225540e-03 2.769276127219200134e-02 3.186681351508013904e-05 1.432105636922642589e-04 4.714415626949630678e-05 3.388972982065752149e-05 5.124681163579225540e-03
6.000000000000000000e+03 2.082878164947032928e-02 2.245081850560382009e-05 1.111210003728047013e-04 5.844125917064957321e-05 4.153546251473017037e-05 3.765410510823130608e-03 2.082878164947032928e-02 2.245081850560382009e-05 1.111210003728047013e-04 5.844125917064957321e-05 4.153546251473017037e-05 3.765410510823130608e-03
7.000000000000000000e+03 1.886345818638801575e-02 2.267650233989115804e-05 1.420600456185638905e-04 5.967973993392661214e-05 3.484289845800958574e-05 2.665102481842041016e-03 1.886345818638801575e-02 2.267650233989115804e-05 1.420600456185638905e-04 5.967973993392661214e-05 3.484289845800958574e-05 2.665102481842041016e-03
8.000000000000000000e+03 1.381358411163091660e-02 9.259051694243680686e-06 7.968995487317442894e-05 5.039988900534808636e-05 2.680783472897019237e-05 2.276953775435686111e-03 1.381358411163091660e-02 9.259051694243680686e-06 7.968995487317442894e-05 5.039988900534808636e-05 2.680783472897019237e-05 2.276953775435686111e-03
9.000000000000000000e+03 8.643090724945068359e-03 1.098749544325983152e-05 9.388606849825009704e-05 4.001759589300490916e-05 2.628936454129870981e-05 1.305643469095230103e-03 8.643090724945068359e-03 1.098749544325983152e-05 9.388606849825009704e-05 4.001759589300490916e-05 2.628936454129870981e-05 1.305643469095230103e-03
1.000000000000000000e+04 4.913316108286380768e-03 1.290380077989539132e-05 1.188093447126448154e-04 3.560207187547348440e-05 2.379582110734190792e-05 6.829262711107730865e-04 4.913316108286380768e-03 1.290380077989539132e-05 1.188093447126448154e-04 3.560207187547348440e-05 2.379582110734190792e-05 6.829262711107730865e-04
