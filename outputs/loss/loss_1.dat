# learning_rate: 0.005
# num_dense_layers: 6
# num_dense_nodes: 40
# activation:ReLU 
# batch_size: 32
# final loss: 0.2527056038379669
# Training Time: 89.08357644081116
# Best Step: 1000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 2.464167833328247070e+00 3.016522619873285294e-03 6.488914135843515396e-03 8.941420237533748150e-04 7.712931837886571884e-04 4.651839137077331543e-01 2.464167833328247070e+00 3.016522619873285294e-03 6.488914135843515396e-03 8.941420237533748150e-04 7.712931837886571884e-04 4.651839137077331543e-01
1.000000000000000000e+03 1.629699207842350006e-02 1.965711417142301798e-04 1.188173773698508739e-04 1.393664715578779578e-04 2.315080782864242792e-04 2.357223480939865112e-01 1.629699207842350006e-02 1.965711417142301798e-04 1.188173773698508739e-04 1.393664715578779578e-04 2.315080782864242792e-04 2.357223480939865112e-01
2.000000000000000000e+03 7.447255309671163559e-03 2.677015145309269428e-04 1.890821731649339199e-04 1.688549818936735392e-04 2.728362742345780134e-04 2.569583058357238770e-01 7.447255309671163559e-03 2.677015145309269428e-04 1.890821731649339199e-04 1.688549818936735392e-04 2.728362742345780134e-04 2.569583058357238770e-01
3.000000000000000000e+03 1.101118046790361404e-02 2.929985639639198780e-04 2.275775477755814791e-04 1.823126076487824321e-04 3.366885648574680090e-04 2.438644915819168091e-01 1.101118046790361404e-02 2.929985639639198780e-04 2.275775477755814791e-04 1.823126076487824321e-04 3.366885648574680090e-04 2.438644915819168091e-01
4.000000000000000000e+03 8.606696501374244690e-03 3.609701234381645918e-04 2.668578526936471462e-04 1.944833056768402457e-04 3.436394908931106329e-04 2.556816041469573975e-01 8.606696501374244690e-03 3.609701234381645918e-04 2.668578526936471462e-04 1.944833056768402457e-04 3.436394908931106329e-04 2.556816041469573975e-01
5.000000000000000000e+03 1.549085695296525955e-02 3.134587605018168688e-04 1.751005329424515367e-04 1.762343745213001966e-04 3.228807763662189245e-04 2.403839677572250366e-01 1.549085695296525955e-02 3.134587605018168688e-04 1.751005329424515367e-04 1.762343745213001966e-04 3.228807763662189245e-04 2.403839677572250366e-01
6.000000000000000000e+03 1.000811439007520676e-02 3.593505534809082747e-04 2.422561956336721778e-04 2.166466147173196077e-04 3.456053964328020811e-04 2.529611289501190186e-01 1.000811439007520676e-02 3.593505534809082747e-04 2.422561956336721778e-04 2.166466147173196077e-04 3.456053964328020811e-04 2.529611289501190186e-01
7.000000000000000000e+03 8.194256573915481567e-03 3.466675698291510344e-04 2.694028371479362249e-04 2.320199710084125400e-04 3.330049803480505943e-04 2.583747804164886475e-01 8.194256573915481567e-03 3.466675698291510344e-04 2.694028371479362249e-04 2.320199710084125400e-04 3.330049803480505943e-04 2.583747804164886475e-01
8.000000000000000000e+03 7.626031525433063507e-03 3.467242349870502949e-04 2.537808322813361883e-04 1.725129550322890282e-04 3.504482738208025694e-04 2.591039836406707764e-01 7.626031525433063507e-03 3.467242349870502949e-04 2.537808322813361883e-04 1.725129550322890282e-04 3.504482738208025694e-04 2.591039836406707764e-01
9.000000000000000000e+03 7.605770137161016464e-03 3.705580020323395729e-04 2.622793545015156269e-04 1.777908910298720002e-04 3.555328585207462311e-04 2.592388987541198730e-01 7.605770137161016464e-03 3.705580020323395729e-04 2.622793545015156269e-04 1.777908910298720002e-04 3.555328585207462311e-04 2.592388987541198730e-01
1.000000000000000000e+04 7.599352858960628510e-03 3.773195203393697739e-04 2.883473352994769812e-04 2.197648136643692851e-04 3.668251156341284513e-04 2.591721117496490479e-01 7.599352858960628510e-03 3.773195203393697739e-04 2.883473352994769812e-04 2.197648136643692851e-04 3.668251156341284513e-04 2.591721117496490479e-01
