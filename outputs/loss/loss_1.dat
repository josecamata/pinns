# learning_rate: 0.005
# num_dense_layers: 6
# num_dense_nodes: 40
# activation:ReLU 
# batch_size: 32
# final loss: 0.2510899007320404
# Training Time: 73.03874778747559
# Best Step: 1000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 1.532407045364379883e+00 1.736806146800518036e-02 1.633223518729209900e-02 5.388754419982433319e-03 6.587935145944356918e-03 4.372512996196746826e-01 1.532407045364379883e+00 1.736806146800518036e-02 1.633223518729209900e-02 5.388754419982433319e-03 6.587935145944356918e-03 4.372512996196746826e-01
1.000000000000000000e+03 1.930968649685382843e-02 2.423264813842251897e-04 1.485803368268534541e-04 2.073396753985434771e-04 2.342585066799074411e-04 2.309477180242538452e-01 1.930968649685382843e-02 2.423264813842251897e-04 1.485803368268534541e-04 2.073396753985434771e-04 2.342585066799074411e-04 2.309477180242538452e-01
2.000000000000000000e+03 7.401231210678815842e-03 3.504806081764400005e-04 2.735753660090267658e-04 2.280532935401424766e-04 3.546062798704952002e-04 2.600049078464508057e-01 7.401231210678815842e-03 3.504806081764400005e-04 2.735753660090267658e-04 2.280532935401424766e-04 3.546062798704952002e-04 2.600049078464508057e-01
3.000000000000000000e+03 2.011225186288356781e-02 3.038108698092401028e-04 1.808681699912995100e-04 2.028426679316908121e-04 3.275038616266101599e-04 2.386251091957092285e-01 2.011225186288356781e-02 3.038108698092401028e-04 1.808681699912995100e-04 2.028426679316908121e-04 3.275038616266101599e-04 2.386251091957092285e-01
4.000000000000000000e+03 1.597372628748416901e-02 2.577318809926509857e-04 1.324217737419530749e-04 1.432959543308243155e-04 2.595830883365124464e-04 2.485317885875701904e-01 1.597372628748416901e-02 2.577318809926509857e-04 1.324217737419530749e-04 1.432959543308243155e-04 2.595830883365124464e-04 2.485317885875701904e-01
5.000000000000000000e+03 1.314311195164918900e-02 2.789225254673510790e-04 1.486242545070126653e-04 1.621417904971167445e-04 3.057305875699967146e-04 2.464885711669921875e-01 1.314311195164918900e-02 2.789225254673510790e-04 1.486242545070126653e-04 1.621417904971167445e-04 3.057305875699967146e-04 2.464885711669921875e-01
6.000000000000000000e+03 1.281134318560361862e-02 3.923457115888595581e-04 2.109581837430596352e-04 1.931949227582663298e-04 3.744255809579044580e-04 2.432076483964920044e-01 1.281134318560361862e-02 3.923457115888595581e-04 2.109581837430596352e-04 1.931949227582663298e-04 3.744255809579044580e-04 2.432076483964920044e-01
7.000000000000000000e+03 1.110483612865209579e-02 3.604214289225637913e-04 2.113607333740219474e-04 2.018106169998645782e-04 3.362487186677753925e-04 2.510856688022613525e-01 1.110483612865209579e-02 3.604214289225637913e-04 2.113607333740219474e-04 2.018106169998645782e-04 3.362487186677753925e-04 2.510856688022613525e-01
8.000000000000000000e+03 6.888765376061201096e-03 3.908009384758770466e-04 2.266897790832445025e-04 2.141446311725303531e-04 3.910784726031124592e-04 2.599813342094421387e-01 6.888765376061201096e-03 3.908009384758770466e-04 2.266897790832445025e-04 2.141446311725303531e-04 3.910784726031124592e-04 2.599813342094421387e-01
9.000000000000000000e+03 9.481111541390419006e-03 3.482340543996542692e-04 2.165371988667175174e-04 1.694141246844083071e-04 3.228270215913653374e-04 2.548916935920715332e-01 9.481111541390419006e-03 3.482340543996542692e-04 2.165371988667175174e-04 1.694141246844083071e-04 3.228270215913653374e-04 2.548916935920715332e-01
1.000000000000000000e+04 8.534019812941551208e-03 3.845566825475543737e-04 2.467191661708056927e-04 1.767063949955627322e-04 3.455025143921375275e-04 2.566440105438232422e-01 8.534019812941551208e-03 3.845566825475543737e-04 2.467191661708056927e-04 1.767063949955627322e-04 3.455025143921375275e-04 2.566440105438232422e-01
