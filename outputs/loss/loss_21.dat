# learning_rate: 0.05
# num_dense_layers: 4
# num_dense_nodes: 70
# activation:sigmoid 
# batch_size: 32
# final loss: 0.1745661497116089
# Training Time: 75.20097756385803
# Best Step: 1000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 6.061638705432415009e-04 1.440515089780092239e-02 1.418137550354003906e-02 1.386227738112211227e-02 1.408627070486545563e-02 1.268780231475830078e+00 6.061638705432415009e-04 1.440515089780092239e-02 1.418137550354003906e-02 1.386227738112211227e-02 1.408627070486545563e-02 1.268780231475830078e+00
1.000000000000000000e+03 3.722786903381347656e-02 2.799631329253315926e-04 2.441773540340363979e-04 2.407968277111649513e-04 2.642183389980345964e-04 1.363091319799423218e-01 3.722786903381347656e-02 2.799631329253315926e-04 2.441773540340363979e-04 2.407968277111649513e-04 2.642183389980345964e-04 1.363091319799423218e-01
2.000000000000000000e+03 5.458255181167714909e-09 3.609650302678346634e-04 3.609888663049787283e-04 3.609936393331736326e-04 3.609797859098762274e-04 2.753382325172424316e-01 5.458255181167714909e-09 3.609650302678346634e-04 3.609888663049787283e-04 3.609936393331736326e-04 3.609797859098762274e-04 2.753382325172424316e-01
3.000000000000000000e+03 2.692064793308190929e-09 3.609251871239393950e-04 3.609378181863576174e-04 3.609361301641911268e-04 3.609340928960591555e-04 2.753379642963409424e-01 2.692064793308190929e-09 3.609251871239393950e-04 3.609378181863576174e-04 3.609361301641911268e-04 3.609340928960591555e-04 2.753379642963409424e-01
4.000000000000000000e+03 1.586739406533865804e-09 3.609039995353668928e-04 3.609106352087110281e-04 3.609052218962460756e-04 3.609088889788836241e-04 2.753377556800842285e-01 1.586739406533865804e-09 3.609039995353668928e-04 3.609106352087110281e-04 3.609052218962460756e-04 3.609088889788836241e-04 2.753377556800842285e-01
5.000000000000000000e+03 1.201228227998285547e-09 3.608963743317872286e-04 3.608983824960887432e-04 3.608886327128857374e-04 3.608969564083963633e-04 2.753374874591827393e-01 1.201228227998285547e-09 3.608963743317872286e-04 3.608983824960887432e-04 3.608886327128857374e-04 3.608969564083963633e-04 2.753374874591827393e-01
6.000000000000000000e+03 5.606051800555178488e-08 3.584104997571557760e-04 3.582585777621716261e-04 3.581439377740025520e-04 3.584172809496521950e-04 2.753296196460723877e-01 5.606051800555178488e-08 3.584104997571557760e-04 3.582585777621716261e-04 3.581439377740025520e-04 3.584172809496521950e-04 2.753296196460723877e-01
7.000000000000000000e+03 8.219367903952539117e-16 3.608258848544210196e-04 3.608258848544210196e-04 3.608258557505905628e-04 3.608258848544210196e-04 2.753378152847290039e-01 8.219367903952539117e-16 3.608258848544210196e-04 3.608258848544210196e-04 3.608258557505905628e-04 3.608258848544210196e-04 2.753378152847290039e-01
8.000000000000000000e+03 8.541510945056702588e-16 3.608259721659123898e-04 3.608260303735733032e-04 3.608259721659123898e-04 3.608260303735733032e-04 2.753378152847290039e-01 8.541510945056702588e-16 3.608259721659123898e-04 3.608260303735733032e-04 3.608259721659123898e-04 3.608260303735733032e-04 2.753378152847290039e-01
9.000000000000000000e+03 9.159050903164290929e-16 3.608257684390991926e-04 3.608257684390991926e-04 3.608257975429296494e-04 3.608257975429296494e-04 2.753378152847290039e-01 9.159050903164290929e-16 3.608257684390991926e-04 3.608257684390991926e-04 3.608257975429296494e-04 3.608257975429296494e-04 2.753378152847290039e-01
1.000000000000000000e+04 8.763863446458060834e-16 3.609088016673922539e-04 3.609088016673922539e-04 3.609088016673922539e-04 3.609088016673922539e-04 2.753374874591827393e-01 8.763863446458060834e-16 3.609088016673922539e-04 3.609088016673922539e-04 3.609088016673922539e-04 3.609088016673922539e-04 2.753374874591827393e-01
