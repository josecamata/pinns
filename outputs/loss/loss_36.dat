# learning_rate: 0.0001
# num_dense_layers: 3
# num_dense_nodes: 30
# activation:Swish 
# batch_size: 32
# final loss: 0.11097276210784912
# Training Time: 100.61838293075562
# Best Step: 10000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 5.225717544555664062e+01 2.752626538276672363e-01 5.684904456138610840e-01 1.842586100101470947e-01 9.652159176766872406e-03 1.145311737060546875e+01 5.225717544555664062e+01 2.752626538276672363e-01 5.684904456138610840e-01 1.842586100101470947e-01 9.652159176766872406e-03 1.145311737060546875e+01
1.000000000000000000e+03 6.634286791086196899e-02 9.194621816277503967e-05 1.231800852110609412e-04 2.054141659755259752e-04 1.368787052342668176e-04 2.494095861911773682e-01 6.634286791086196899e-02 9.194621816277503967e-05 1.231800852110609412e-04 2.054141659755259752e-04 1.368787052342668176e-04 2.494095861911773682e-01
2.000000000000000000e+03 2.401386387646198273e-02 8.642429020255804062e-05 8.156956027960404754e-05 7.224030559882521629e-05 4.794152846443466842e-05 2.265216112136840820e-01 2.401386387646198273e-02 8.642429020255804062e-05 8.156956027960404754e-05 7.224030559882521629e-05 4.794152846443466842e-05 2.265216112136840820e-01
3.000000000000000000e+03 1.736473478376865387e-02 1.371845282847061753e-04 9.371371561428532004e-05 2.412099638604559004e-05 4.318174251238815486e-05 2.094156146049499512e-01 1.736473478376865387e-02 1.371845282847061753e-04 9.371371561428532004e-05 2.412099638604559004e-05 4.318174251238815486e-05 2.094156146049499512e-01
4.000000000000000000e+03 1.660445332527160645e-02 2.226197830168530345e-04 1.302088348893448710e-04 2.579385727585759014e-05 8.848958532325923443e-05 1.986376196146011353e-01 1.660445332527160645e-02 2.226197830168530345e-04 1.302088348893448710e-04 2.579385727585759014e-05 8.848958532325923443e-05 1.986376196146011353e-01
5.000000000000000000e+03 1.719253696501255035e-02 2.872815530281513929e-04 1.589965977473184466e-04 4.198852911940775812e-05 1.344835764029994607e-04 1.889489293098449707e-01 1.719253696501255035e-02 2.872815530281513929e-04 1.589965977473184466e-04 4.198852911940775812e-05 1.344835764029994607e-04 1.889489293098449707e-01
6.000000000000000000e+03 1.811712048947811127e-02 3.148199466522783041e-04 1.824108767323195934e-04 6.866795592941343784e-05 1.662388531258329749e-04 1.778027266263961792e-01 1.811712048947811127e-02 3.148199466522783041e-04 1.824108767323195934e-04 6.866795592941343784e-05 1.662388531258329749e-04 1.778027266263961792e-01
7.000000000000000000e+03 1.901305466890335083e-02 3.163567744195461273e-04 2.033064811257645488e-04 1.075516556738875806e-04 1.955851039383560419e-04 1.637539267539978027e-01 1.901305466890335083e-02 3.163567744195461273e-04 2.033064811257645488e-04 1.075516556738875806e-04 1.955851039383560419e-04 1.637539267539978027e-01
8.000000000000000000e+03 1.993951201438903809e-02 3.656471963040530682e-04 2.397641364950686693e-04 1.600042014615610242e-04 2.741740318015217781e-04 1.449391096830368042e-01 1.993951201438903809e-02 3.656471963040530682e-04 2.397641364950686693e-04 1.600042014615610242e-04 2.741740318015217781e-04 1.449391096830368042e-01
9.000000000000000000e+03 2.289703860878944397e-02 3.409555356483906507e-04 2.279739564983174205e-04 1.671326899668201804e-04 2.746598620433360338e-04 1.195633113384246826e-01 2.289703860878944397e-02 3.409555356483906507e-04 2.279739564983174205e-04 1.671326899668201804e-04 2.746598620433360338e-04 1.195633113384246826e-01
1.000000000000000000e+04 2.596752531826496124e-02 2.155303081963211298e-04 1.227846660185605288e-04 1.147314687841571867e-04 1.969136064872145653e-04 8.435527980327606201e-02 2.596752531826496124e-02 2.155303081963211298e-04 1.227846660185605288e-04 1.147314687841571867e-04 1.969136064872145653e-04 8.435527980327606201e-02
