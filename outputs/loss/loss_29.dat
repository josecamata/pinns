# learning_rate: 0.001
# num_dense_layers: 3
# num_dense_nodes: 60
# activation:sigmoid 
# batch_size: 32
# final loss: 0.04363071918487549
# Training Time: 84.88125705718994
# Best Step: 10000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 9.328658692538738251e-03 1.011907402426004410e-02 9.228092618286609650e-03 9.798089973628520966e-03 1.095664221793413162e-02 1.711921453475952148e+00 9.328658692538738251e-03 1.011907402426004410e-02 9.228092618286609650e-03 9.798089973628520966e-03 1.095664221793413162e-02 1.711921453475952148e+00
1.000000000000000000e+03 1.277103554457426071e-02 1.628893078304827213e-04 1.159943421953357756e-04 1.637014211155474186e-04 1.932310842676088214e-04 2.097329199314117432e-01 1.277103554457426071e-02 1.628893078304827213e-04 1.159943421953357756e-04 1.637014211155474186e-04 1.932310842676088214e-04 2.097329199314117432e-01
2.000000000000000000e+03 3.034895658493041992e-02 1.992132602026686072e-04 1.319184957537800074e-04 1.216816599480807781e-04 1.717223203741014004e-04 9.570230543613433838e-02 3.034895658493041992e-02 1.992132602026686072e-04 1.319184957537800074e-04 1.216816599480807781e-04 1.717223203741014004e-04 9.570230543613433838e-02
3.000000000000000000e+03 3.690217062830924988e-02 1.726674818200990558e-04 9.859958663582801819e-05 1.369849051116034389e-04 2.058552781818434596e-04 4.257704317569732666e-02 3.690217062830924988e-02 1.726674818200990558e-04 9.859958663582801819e-05 1.369849051116034389e-04 2.058552781818434596e-04 4.257704317569732666e-02
4.000000000000000000e+03 3.643060475587844849e-02 1.236194220837205648e-04 9.251479059457778931e-05 1.279953721677884459e-04 1.651677885092794895e-04 3.002945519983768463e-02 3.643060475587844849e-02 1.236194220837205648e-04 9.251479059457778931e-05 1.279953721677884459e-04 1.651677885092794895e-04 3.002945519983768463e-02
5.000000000000000000e+03 3.478395193815231323e-02 9.594512084731832147e-05 8.849149890011176467e-05 1.172422926174476743e-04 1.389993412885814905e-04 2.401760779321193695e-02 3.478395193815231323e-02 9.594512084731832147e-05 8.849149890011176467e-05 1.172422926174476743e-04 1.389993412885814905e-04 2.401760779321193695e-02
6.000000000000000000e+03 3.422275930643081665e-02 8.044572314247488976e-05 1.011737185763195157e-04 1.100401059375144541e-04 1.030438579618930817e-04 1.937953755259513855e-02 3.422275930643081665e-02 8.044572314247488976e-05 1.011737185763195157e-04 1.100401059375144541e-04 1.030438579618930817e-04 1.937953755259513855e-02
7.000000000000000000e+03 3.308696672320365906e-02 7.541191735072061419e-05 1.051344588631764054e-04 1.055429675034247339e-04 9.085831698030233383e-05 1.701033115386962891e-02 3.308696672320365906e-02 7.541191735072061419e-05 1.051344588631764054e-04 1.055429675034247339e-04 9.085831698030233383e-05 1.701033115386962891e-02
8.000000000000000000e+03 3.195241838693618774e-02 7.198665844043716788e-05 1.111166566261090338e-04 1.057592962752096355e-04 8.395614713663235307e-05 1.533752400428056717e-02 3.195241838693618774e-02 7.198665844043716788e-05 1.111166566261090338e-04 1.057592962752096355e-04 8.395614713663235307e-05 1.533752400428056717e-02
9.000000000000000000e+03 3.110034205019474030e-02 6.902452878421172500e-05 1.152064432972110808e-04 1.067017365130595863e-04 7.874302536947652698e-05 1.397736277431249619e-02 3.110034205019474030e-02 6.902452878421172500e-05 1.152064432972110808e-04 1.067017365130595863e-04 7.874302536947652698e-05 1.397736277431249619e-02
1.000000000000000000e+04 3.042094781994819641e-02 6.439805292757228017e-05 1.176152727566659451e-04 1.081330628949217498e-04 7.368955994024872780e-05 1.284593623131513596e-02 3.042094781994819641e-02 6.439805292757228017e-05 1.176152727566659451e-04 1.081330628949217498e-04 7.368955994024872780e-05 1.284593623131513596e-02
