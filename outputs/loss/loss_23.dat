# learning_rate: 0.01
# num_dense_layers: 4
# num_dense_nodes: 20
# activation:ReLU 
# batch_size: 32
# final loss: 0.2561989724636078
# Training Time: 59.79937720298767
# Best Step: 1000

# step, loss_train, loss_test, metrics_test
0.000000000000000000e+00 1.299304103851318359e+01 1.202889308333396912e-01 1.567522734403610229e-01 4.871358722448348999e-02 2.350969426333904266e-02 8.785806655883789062e+00 1.299304103851318359e+01 1.202889308333396912e-01 1.567522734403610229e-01 4.871358722448348999e-02 2.350969426333904266e-02 8.785806655883789062e+00
1.000000000000000000e+03 1.311264932155609131e-02 3.160261258017271757e-04 1.398107124259695411e-04 1.317899295827373862e-04 2.292143472004681826e-04 2.422694861888885498e-01 1.311264932155609131e-02 3.160261258017271757e-04 1.398107124259695411e-04 1.317899295827373862e-04 2.292143472004681826e-04 2.422694861888885498e-01
2.000000000000000000e+03 1.106718089431524277e-02 3.241789818275719881e-04 1.881296775536611676e-04 1.506910048192366958e-04 3.215681936126202345e-04 2.504439949989318848e-01 1.106718089431524277e-02 3.241789818275719881e-04 1.881296775536611676e-04 1.506910048192366958e-04 3.215681936126202345e-04 2.504439949989318848e-01
3.000000000000000000e+03 6.192184984683990479e-03 3.483131877146661282e-04 2.741866337601095438e-04 2.293658471899107099e-04 3.363411233294755220e-04 2.618045508861541748e-01 6.192184984683990479e-03 3.483131877146661282e-04 2.741866337601095438e-04 2.293658471899107099e-04 3.363411233294755220e-04 2.618045508861541748e-01
4.000000000000000000e+03 4.785584285855293274e-03 3.751984913833439350e-04 2.939899568445980549e-04 2.363282255828380585e-04 3.638817870523780584e-04 2.650851309299468994e-01 4.785584285855293274e-03 3.751984913833439350e-04 2.939899568445980549e-04 2.363282255828380585e-04 3.638817870523780584e-04 2.650851309299468994e-01
5.000000000000000000e+03 1.141629926860332489e-02 3.156850580126047134e-04 2.268783719046041369e-04 2.330980933038517833e-04 3.701740351971238852e-04 2.535467147827148438e-01 1.141629926860332489e-02 3.156850580126047134e-04 2.268783719046041369e-04 2.330980933038517833e-04 3.701740351971238852e-04 2.535467147827148438e-01
6.000000000000000000e+03 1.056779455393552780e-02 3.611011779867112637e-04 2.032323100138455629e-04 1.599304960109293461e-04 3.460155858192592859e-04 2.529442310333251953e-01 1.056779455393552780e-02 3.611011779867112637e-04 2.032323100138455629e-04 1.599304960109293461e-04 3.460155858192592859e-04 2.529442310333251953e-01
7.000000000000000000e+03 6.529794540256261826e-03 3.956012078560888767e-04 2.834186889231204987e-04 2.174313704017549753e-04 3.596860915422439575e-04 2.616730034351348877e-01 6.529794540256261826e-03 3.956012078560888767e-04 2.834186889231204987e-04 2.174313704017549753e-04 3.596860915422439575e-04 2.616730034351348877e-01
8.000000000000000000e+03 3.679568646475672722e-03 3.549672546796500683e-04 2.972764486912637949e-04 2.760914794635027647e-04 3.693504841066896915e-04 2.672753334045410156e-01 3.679568646475672722e-03 3.549672546796500683e-04 2.972764486912637949e-04 2.760914794635027647e-04 3.693504841066896915e-04 2.672753334045410156e-01
9.000000000000000000e+03 6.592781748622655869e-03 3.463964094407856464e-04 2.799647336360067129e-04 2.443283156026154757e-04 3.548077947925776243e-04 2.614534497261047363e-01 6.592781748622655869e-03 3.463964094407856464e-04 2.799647336360067129e-04 2.443283156026154757e-04 3.548077947925776243e-04 2.614534497261047363e-01
1.000000000000000000e+04 4.136500880122184753e-03 3.865099279209971428e-04 3.027512866538017988e-04 2.469035098329186440e-04 3.671198792289942503e-04 2.666119039058685303e-01 4.136500880122184753e-03 3.865099279209971428e-04 3.027512866538017988e-04 2.469035098329186440e-04 3.671198792289942503e-04 2.666119039058685303e-01
